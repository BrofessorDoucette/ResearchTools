{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# caution: path[0] is reserved for script path (or '' in REPL).\n",
    "sys.path.insert(1, os.path.abspath(\"./../src\"))\n",
    "\n",
    "\n",
    "import datetime\n",
    "import importlib\n",
    "\n",
    "import astropy.time\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "from cdflib.epochs_astropy import CDFAstropy as cdfepoch\n",
    "from dateutil import rrule\n",
    "from scipy.stats import vonmises\n",
    "\n",
    "import data_loader\n",
    "import rbsp_chorus_tool\n",
    "\n",
    "importlib.reload(data_loader)\n",
    "importlib.reload(rbsp_chorus_tool)\n",
    "\n",
    "pdata_folder = os.path.abspath(r\"./../processed_data/chorus_neural_network/\")\n",
    "\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Dev\\Research\\Research_Tools\\ResearchPy\\Lib\\site-packages\\ipykernel\\eventloops.py:145: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  el.exec() if hasattr(el, \"exec\") else el.exec_()\n"
     ]
    }
   ],
   "source": [
    "# STAGE 0 DATA VERIFICATION FOR POES LSTAR CALCULATIONS\n",
    "\n",
    "mpe_folder = os.path.join(pdata_folder, \"STAGE_0\", \"MPE_DATA_PREPROCESSED_WITH_LSTAR\")\n",
    "\n",
    "year = 2012\n",
    "SATID = \"m02\"\n",
    "\n",
    "refs = np.load(\n",
    "    file=os.path.join(\n",
    "        mpe_folder,\n",
    "        rf\"MPE_PREPROCESSED_DATA_T89_{year}.npz\",\n",
    "    ),\n",
    "    allow_pickle=True,\n",
    ")\n",
    "\n",
    "DATA = refs[\"DATA\"].flatten()[0]\n",
    "SAT = DATA[SATID]\n",
    "\n",
    "dt_for_all = np.array([datetime.datetime.fromtimestamp(t) for t in SAT[\"UNIX_TIME\"]])\n",
    "\n",
    "plt.plot(dt_for_all, SAT[\"Lstar\"], label=\"L*\", color=\"red\", marker=\"*\")\n",
    "plt.plot(dt_for_all, SAT[\"L\"], label=\"IGRF Lm\", color=\"black\", marker=\"*\")\n",
    "plt.ylabel(\"|L|\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.title(f\"Some Orbits for {SATID} in {year}\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA VERIFICATION RBSP L-STAR DATA CALCULATIONS\n",
    "\n",
    "lstar_folder = os.path.join(pdata_folder, \"STAGE_1\", \"Lstar\")\n",
    "\n",
    "year = 2012\n",
    "sat = \"a\"\n",
    "refs = np.load(\n",
    "    file=os.path.join(lstar_folder, rf\"RBSP_{sat.upper()}_T89_{year}.npz\"),\n",
    "    allow_pickle=True,\n",
    ")\n",
    "\n",
    "\n",
    "dates = np.array([datetime.datetime.fromtimestamp(t) for t in refs[\"UNIX_TIME\"]])\n",
    "\n",
    "\n",
    "#plt.plot(dates, refs[\"Lstar\"], label=\"L* at EQ\")\n",
    "#plt.plot(dates, refs[\"LSTAR_LOCAL\"], label=\"L* Local\")\n",
    "#plt.xlabel(\"Time (UTC)\")\n",
    "#plt.ylabel(\"L*\")\n",
    "#plt.legend()\n",
    "\n",
    "plt.plot(dates, refs[\"MLAT\"], label=\"MLAT\")\n",
    "plt.xlabel(\"Time (UTC)\")\n",
    "plt.ylabel(\"MLAT\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolate POES data cause I forgot to interpolate it before with the nans included\n",
    "\n",
    "for _year in range(2012, 2021):\n",
    "\n",
    "    POES = {}\n",
    "\n",
    "    refs = np.load(\n",
    "        rf\"./../processed_data/chorus_neural_network/STAGE_0/MPE_DATA_PREPROCESSED_WITH_LSTAR/MPE_PREPROCESSED_DATA_T89_{_year}.npz\",\n",
    "        allow_pickle=True,\n",
    "    )\n",
    "    POES_DATA = refs[\"DATA\"].flatten()[0]\n",
    "\n",
    "    for SATID in POES_DATA:\n",
    "\n",
    "        SAT = POES_DATA[SATID]\n",
    "\n",
    "        UNIX_TIME = []\n",
    "        LSTAR = []\n",
    "        MLT = []\n",
    "        BLC_FLUX_0 = []\n",
    "        BLC_FLUX_1 = []\n",
    "        BLC_FLUX_2 = []\n",
    "        BLC_FLUX_3 = []\n",
    "        BLC_FLUX_4 = []\n",
    "        BLC_FLUX_5 = []\n",
    "        BLC_FLUX_6 = []\n",
    "        BLC_FLUX_7 = []\n",
    "\n",
    "        for p in range(len(SAT[\"UNIX_TIME\"]) - 1):\n",
    "\n",
    "            t1 = SAT[\"UNIX_TIME\"][p]\n",
    "            t2 = SAT[\"UNIX_TIME\"][p + 1]\n",
    "\n",
    "            if t2 - t1 < 30.0:\n",
    "\n",
    "                t_points = np.arange(t1, t2 + 1, step=1, dtype=np.float64)\n",
    "\n",
    "                UNIX_TIME.append(t_points)\n",
    "                LSTAR.append(\n",
    "                    np.interp(\n",
    "                        x=t_points,\n",
    "                        xp=[t1, t2],\n",
    "                        fp=[SAT[\"Lstar\"][p], SAT[\"Lstar\"][p + 1]],\n",
    "                        left=np.nan,\n",
    "                        right=np.nan,\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                X_INTERPOLATED = np.interp(\n",
    "                    t_points,\n",
    "                    xp=[t1, t2],\n",
    "                    fp=[\n",
    "                        np.cos(SAT[\"MLT\"][p] * 2 * np.pi / 24.0),\n",
    "                        np.cos(SAT[\"MLT\"][p + 1] * 2 * np.pi / 24.0),\n",
    "                    ],\n",
    "                    left=np.nan,\n",
    "                    right=np.nan,\n",
    "                )\n",
    "                Y_INTERPOLATED = np.interp(\n",
    "                    t_points,\n",
    "                    xp=[t1, t2],\n",
    "                    fp=[\n",
    "                        np.sin(SAT[\"MLT\"][p] * 2 * np.pi / 24.0),\n",
    "                        np.sin(SAT[\"MLT\"][p + 1] * 2 * np.pi / 24.0),\n",
    "                    ],\n",
    "                    left=np.nan,\n",
    "                    right=np.nan,\n",
    "                )\n",
    "                ANGLE_IN_RADIANS = np.mod(\n",
    "                    np.arctan2(Y_INTERPOLATED, X_INTERPOLATED) + 2 * np.pi, 2 * np.pi\n",
    "                )\n",
    "\n",
    "                MLT.append((ANGLE_IN_RADIANS * 24.0) / (2 * np.pi))\n",
    "\n",
    "                BLC_FLUX_0.append(\n",
    "                    np.interp(\n",
    "                        x=t_points,\n",
    "                        xp=[t1, t2],\n",
    "                        fp=[SAT[\"BLC_Flux\"][p, 0], SAT[\"BLC_Flux\"][p + 1, 0]],\n",
    "                        left=np.nan,\n",
    "                        right=np.nan,\n",
    "                    )\n",
    "                )\n",
    "                BLC_FLUX_1.append(\n",
    "                    np.interp(\n",
    "                        x=t_points,\n",
    "                        xp=[t1, t2],\n",
    "                        fp=[SAT[\"BLC_Flux\"][p, 1], SAT[\"BLC_Flux\"][p + 1, 1]],\n",
    "                        left=np.nan,\n",
    "                        right=np.nan,\n",
    "                    )\n",
    "                )\n",
    "                BLC_FLUX_2.append(\n",
    "                    np.interp(\n",
    "                        x=t_points,\n",
    "                        xp=[t1, t2],\n",
    "                        fp=[SAT[\"BLC_Flux\"][p, 2], SAT[\"BLC_Flux\"][p + 1, 2]],\n",
    "                        left=np.nan,\n",
    "                        right=np.nan,\n",
    "                    )\n",
    "                )\n",
    "                BLC_FLUX_3.append(\n",
    "                    np.interp(\n",
    "                        x=t_points,\n",
    "                        xp=[t1, t2],\n",
    "                        fp=[SAT[\"BLC_Flux\"][p, 3], SAT[\"BLC_Flux\"][p + 1, 3]],\n",
    "                        left=np.nan,\n",
    "                        right=np.nan,\n",
    "                    )\n",
    "                )\n",
    "                BLC_FLUX_4.append(\n",
    "                    np.interp(\n",
    "                        x=t_points,\n",
    "                        xp=[t1, t2],\n",
    "                        fp=[SAT[\"BLC_Flux\"][p, 4], SAT[\"BLC_Flux\"][p + 1, 4]],\n",
    "                        left=np.nan,\n",
    "                        right=np.nan,\n",
    "                    )\n",
    "                )\n",
    "                BLC_FLUX_5.append(\n",
    "                    np.interp(\n",
    "                        x=t_points,\n",
    "                        xp=[t1, t2],\n",
    "                        fp=[SAT[\"BLC_Flux\"][p, 5], SAT[\"BLC_Flux\"][p + 1, 5]],\n",
    "                        left=np.nan,\n",
    "                        right=np.nan,\n",
    "                    )\n",
    "                )\n",
    "                BLC_FLUX_6.append(\n",
    "                    np.interp(\n",
    "                        x=t_points,\n",
    "                        xp=[t1, t2],\n",
    "                        fp=[SAT[\"BLC_Flux\"][p, 6], SAT[\"BLC_Flux\"][p + 1, 6]],\n",
    "                        left=np.nan,\n",
    "                        right=np.nan,\n",
    "                    )\n",
    "                )\n",
    "                BLC_FLUX_7.append(\n",
    "                    np.interp(\n",
    "                        x=t_points,\n",
    "                        xp=[t1, t2],\n",
    "                        fp=[SAT[\"BLC_Flux\"][p, 7], SAT[\"BLC_Flux\"][p + 1, 7]],\n",
    "                        left=np.nan,\n",
    "                        right=np.nan,\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        UNIX_TIME = np.hstack(UNIX_TIME)\n",
    "        LSTAR = np.hstack(LSTAR)\n",
    "        MLT = np.hstack(MLT)\n",
    "        BLC_FLUX_0 = np.hstack(BLC_FLUX_0)\n",
    "        BLC_FLUX_1 = np.hstack(BLC_FLUX_1)\n",
    "        BLC_FLUX_2 = np.hstack(BLC_FLUX_2)\n",
    "        BLC_FLUX_3 = np.hstack(BLC_FLUX_3)\n",
    "        BLC_FLUX_4 = np.hstack(BLC_FLUX_4)\n",
    "        BLC_FLUX_5 = np.hstack(BLC_FLUX_5)\n",
    "        BLC_FLUX_6 = np.hstack(BLC_FLUX_6)\n",
    "        BLC_FLUX_7 = np.hstack(BLC_FLUX_7)\n",
    "        BLC_FLUX = np.hstack(\n",
    "            [\n",
    "                np.expand_dims(BLC_FLUX_0, axis=1),\n",
    "                np.expand_dims(BLC_FLUX_1, axis=1),\n",
    "                np.expand_dims(BLC_FLUX_2, axis=1),\n",
    "                np.expand_dims(BLC_FLUX_3, axis=1),\n",
    "                np.expand_dims(BLC_FLUX_4, axis=1),\n",
    "                np.expand_dims(BLC_FLUX_5, axis=1),\n",
    "                np.expand_dims(BLC_FLUX_6, axis=1),\n",
    "                np.expand_dims(BLC_FLUX_7, axis=1),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        POES[SATID] = {\n",
    "            \"UNIX_TIME\": UNIX_TIME,\n",
    "            \"MLT\": MLT,\n",
    "            \"BLC_Flux\": BLC_FLUX,\n",
    "            \"LSTAR\": LSTAR,\n",
    "        }\n",
    "\n",
    "    if not POES:\n",
    "        print(f\"No POES satellite coverage found for year : {_year}\")\n",
    "        print(f\"SKIPPING YEAR : {_year}\")\n",
    "        continue\n",
    "\n",
    "    refs.close()\n",
    "\n",
    "    np.savez(\n",
    "        file=os.path.abspath(\n",
    "            f\"./../processed_data/chorus_neural_network/STAGE_0/MPE_DATA_PREPROCESSED_WITH_LSTAR/MPE_PREPROCESSED_DATA_T89_{_year}_interpolated.npz\"\n",
    "        ),\n",
    "        DATA=POES,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 1276658/1276658 [02:43<00:00, 7819.38it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1303952/1303952 [02:38<00:00, 8206.64it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1288167/1288167 [02:35<00:00, 8258.03it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1339197/1339197 [02:44<00:00, 8151.31it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1335969/1335969 [02:42<00:00, 8233.21it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1172862/1172862 [02:22<00:00, 8251.84it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1169676/1169676 [02:21<00:00, 8241.44it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 195510/195510 [00:23<00:00, 8293.33it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1198978/1198978 [02:24<00:00, 8309.59it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1196615/1196615 [02:25<00:00, 8221.17it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1189771/1189771 [02:23<00:00, 8272.36it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1204803/1204803 [02:26<00:00, 8233.65it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1207262/1207262 [02:25<00:00, 8310.09it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 527881/527881 [01:03<00:00, 8319.46it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1242865/1242865 [02:28<00:00, 8364.16it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1243673/1243673 [02:30<00:00, 8271.12it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1161587/1161587 [02:20<00:00, 8283.08it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1162498/1162498 [02:20<00:00, 8292.48it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1159423/1159423 [02:21<00:00, 8192.25it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1192245/1192245 [02:23<00:00, 8281.19it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1208904/1208904 [02:26<00:00, 8227.59it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1190502/1190502 [02:25<00:00, 8173.36it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1195342/1195342 [02:25<00:00, 8204.15it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1220691/1220691 [02:28<00:00, 8246.11it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1245500/1245500 [02:29<00:00, 8316.40it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1193726/1193726 [02:22<00:00, 8383.08it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1193577/1193577 [02:16<00:00, 8722.61it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1187759/1187759 [02:16<00:00, 8733.33it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1211667/1211667 [02:22<00:00, 8473.82it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1241062/1241062 [02:25<00:00, 8512.54it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1169242/1169242 [02:16<00:00, 8556.47it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1194667/1194667 [02:21<00:00, 8455.93it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1187327/1187327 [02:21<00:00, 8399.24it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1220694/1220694 [02:24<00:00, 8474.40it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1239656/1239656 [02:25<00:00, 8535.95it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1147110/1147110 [02:17<00:00, 8316.43it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1037675/1037675 [02:02<00:00, 8455.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1153577/1153577 [02:15<00:00, 8491.89it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1187694/1187694 [02:21<00:00, 8413.37it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1200551/1200551 [02:23<00:00, 8370.57it/s]\n",
      "  3%|██▏                                                                     | 36897/1187099 [00:04<02:24, 7943.88it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 29\u001b[39m\n\u001b[32m     25\u001b[39m BLC_FLUX_7 = []\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m tqdm.tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(SAT[\u001b[33m\"\u001b[39m\u001b[33mUNIX_TIME\u001b[39m\u001b[33m\"\u001b[39m]))):\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m     t_range = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43msearchsorted\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m        \u001b[49m\u001b[43ma\u001b[49m\u001b[43m=\u001b[49m\u001b[43mSAT\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mUNIX_TIME\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m        \u001b[49m\u001b[43mv\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mSAT\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mUNIX_TIME\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mp\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSAT\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mUNIX_TIME\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mp\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m     UNIX_TIME.append(SAT[\u001b[33m\"\u001b[39m\u001b[33mUNIX_TIME\u001b[39m\u001b[33m\"\u001b[39m][p])\n\u001b[32m     35\u001b[39m     LSTAR.append(np.nanmean(SAT[\u001b[33m\"\u001b[39m\u001b[33mLstar\u001b[39m\u001b[33m\"\u001b[39m][t_range[\u001b[32m0\u001b[39m] : t_range[\u001b[32m1\u001b[39m]]))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Dev\\Research\\Research_Tools\\ResearchPy\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:1527\u001b[39m, in \u001b[36msearchsorted\u001b[39m\u001b[34m(a, v, side, sorter)\u001b[39m\n\u001b[32m   1447\u001b[39m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_searchsorted_dispatcher)\n\u001b[32m   1448\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msearchsorted\u001b[39m(a, v, side=\u001b[33m'\u001b[39m\u001b[33mleft\u001b[39m\u001b[33m'\u001b[39m, sorter=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m   1449\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1450\u001b[39m \u001b[33;03m    Find indices where elements should be inserted to maintain order.\u001b[39;00m\n\u001b[32m   1451\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1525\u001b[39m \u001b[33;03m    30  # The element at index 2 of the sorted array is 30.\u001b[39;00m\n\u001b[32m   1526\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1527\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msearchsorted\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mside\u001b[49m\u001b[43m=\u001b[49m\u001b[43mside\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msorter\u001b[49m\u001b[43m=\u001b[49m\u001b[43msorter\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Dev\\Research\\Research_Tools\\ResearchPy\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:57\u001b[39m, in \u001b[36m_wrapfunc\u001b[39m\u001b[34m(obj, method, *args, **kwds)\u001b[39m\n\u001b[32m     54\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, *args, **kwds)\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m     59\u001b[39m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[32m     60\u001b[39m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     64\u001b[39m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[32m     65\u001b[39m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[32m     66\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, *args, **kwds)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for _year in range(2012, 2021):\n",
    "\n",
    "    POES = {}\n",
    "\n",
    "    refs = np.load(\n",
    "        rf\"./../processed_data/chorus_neural_network/STAGE_0/MPE_DATA_PREPROCESSED_WITH_LSTAR/MPE_PREPROCESSED_DATA_T89_{_year}.npz\",\n",
    "        allow_pickle=True,\n",
    "    )\n",
    "    POES_DATA = refs[\"DATA\"].flatten()[0]\n",
    "\n",
    "    for SATID in POES_DATA:\n",
    "\n",
    "        SAT = POES_DATA[SATID]\n",
    "\n",
    "        UNIX_TIME = []\n",
    "        LSTAR = []\n",
    "        MLT = []\n",
    "        BLC_FLUX_0 = []\n",
    "        BLC_FLUX_1 = []\n",
    "        BLC_FLUX_2 = []\n",
    "        BLC_FLUX_3 = []\n",
    "        BLC_FLUX_4 = []\n",
    "        BLC_FLUX_5 = []\n",
    "        BLC_FLUX_6 = []\n",
    "        BLC_FLUX_7 = []\n",
    "\n",
    "        for p in tqdm.tqdm(range(len(SAT[\"UNIX_TIME\"]))):\n",
    "\n",
    "            t_range = np.searchsorted(\n",
    "                a=SAT[\"UNIX_TIME\"],\n",
    "                v=[SAT[\"UNIX_TIME\"][p] - 30, SAT[\"UNIX_TIME\"][p] + 30],\n",
    "            )\n",
    "\n",
    "            UNIX_TIME.append(SAT[\"UNIX_TIME\"][p])\n",
    "            LSTAR.append(np.nanmean(SAT[\"Lstar\"][t_range[0] : t_range[1]]))\n",
    "\n",
    "            X_POINT = np.nanmean(np.cos(SAT[\"MLT\"][t_range[0] : t_range[1]] * 2 * np.pi / 24.0))\n",
    "            Y_POINT = np.nanmean(np.sin(SAT[\"MLT\"][t_range[0] : t_range[1]] * 2 * np.pi / 24.0))\n",
    "            ANGLE_IN_RADIANS = np.mod(np.arctan2(Y_POINT, X_POINT) + 2 * np.pi, 2 * np.pi)\n",
    "            MLT.append((ANGLE_IN_RADIANS * 24.0) / (2 * np.pi))\n",
    "\n",
    "            BLC_FLUX_0.append(SAT[\"BLC_Flux\"][t_range[0] : t_range[1], 0])\n",
    "            BLC_FLUX_1.append(SAT[\"BLC_Flux\"][t_range[0] : t_range[1], 1])\n",
    "            BLC_FLUX_2.append(SAT[\"BLC_Flux\"][t_range[0] : t_range[1], 2])\n",
    "            BLC_FLUX_3.append(SAT[\"BLC_Flux\"][t_range[0] : t_range[1], 3])\n",
    "            BLC_FLUX_4.append(SAT[\"BLC_Flux\"][t_range[0] : t_range[1], 4])\n",
    "            BLC_FLUX_5.append(SAT[\"BLC_Flux\"][t_range[0] : t_range[1], 5])\n",
    "            BLC_FLUX_6.append(SAT[\"BLC_Flux\"][t_range[0] : t_range[1], 6])\n",
    "            BLC_FLUX_7.append(SAT[\"BLC_Flux\"][t_range[0] : t_range[1], 7])\n",
    "\n",
    "        UNIX_TIME = np.hstack(UNIX_TIME)\n",
    "        LSTAR = np.hstack(LSTAR)\n",
    "        MLT = np.hstack(MLT)\n",
    "        BLC_FLUX_0 = np.hstack(BLC_FLUX_0)\n",
    "        BLC_FLUX_1 = np.hstack(BLC_FLUX_1)\n",
    "        BLC_FLUX_2 = np.hstack(BLC_FLUX_2)\n",
    "        BLC_FLUX_3 = np.hstack(BLC_FLUX_3)\n",
    "        BLC_FLUX_4 = np.hstack(BLC_FLUX_4)\n",
    "        BLC_FLUX_5 = np.hstack(BLC_FLUX_5)\n",
    "        BLC_FLUX_6 = np.hstack(BLC_FLUX_6)\n",
    "        BLC_FLUX_7 = np.hstack(BLC_FLUX_7)\n",
    "        BLC_FLUX = np.hstack(\n",
    "            [\n",
    "                np.expand_dims(BLC_FLUX_0, axis=1),\n",
    "                np.expand_dims(BLC_FLUX_1, axis=1),\n",
    "                np.expand_dims(BLC_FLUX_2, axis=1),\n",
    "                np.expand_dims(BLC_FLUX_3, axis=1),\n",
    "                np.expand_dims(BLC_FLUX_4, axis=1),\n",
    "                np.expand_dims(BLC_FLUX_5, axis=1),\n",
    "                np.expand_dims(BLC_FLUX_6, axis=1),\n",
    "                np.expand_dims(BLC_FLUX_7, axis=1),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        POES[SATID] = {\n",
    "            \"UNIX_TIME\": UNIX_TIME,\n",
    "            \"MLT\": MLT,\n",
    "            \"BLC_Flux\": BLC_FLUX,\n",
    "            \"LSTAR\": LSTAR,\n",
    "        }\n",
    "\n",
    "    if not POES:\n",
    "        print(f\"No POES satellite coverage found for year : {_year}\")\n",
    "        print(f\"SKIPPING YEAR : {_year}\")\n",
    "        continue\n",
    "\n",
    "    refs.close()\n",
    "\n",
    "    np.savez(\n",
    "        file=os.path.abspath(\n",
    "            f\"./../processed_data/chorus_neural_network/STAGE_0/MPE_DATA_PREPROCESSED_WITH_LSTAR/MPE_PREPROCESSED_DATA_T89_{_year}_smoothed.npz\"\n",
    "        ),\n",
    "        DATA=POES,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files loaded: (286, 197, 286, 197)\n",
      "CPU times: user 9.66 s, sys: 13.4 s, total: 23 s\n",
      "Wall time: 2min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Stage 1 RBSP Chorus Preprocessing, Obtains clean chorus amplitudes\n",
    "\n",
    "year = 2019\n",
    "\n",
    "start = datetime.datetime(year=year, month=1, day=1)\n",
    "end = datetime.datetime(year=year, month=10, day=13, hour=23, minute=59, second=59)\n",
    "\n",
    "evenly_spaced_seconds = np.arange(start.timestamp(), end.timestamp() + 1, step=1)\n",
    "\n",
    "\n",
    "WNA_a = data_loader.load_raw_data_from_config(\n",
    "    id=[\"RBSP\", \"EMFISIS\", \"L4\", \"WNA_SURVEY\"],\n",
    "    start=start,\n",
    "    end=end,\n",
    "    satellite=\"a\",\n",
    "    root_data_dir=\"/project/rbsp/data/\",\n",
    "    use_config_keys_in_subdir=False,\n",
    ")\n",
    "\n",
    "WNA_b = data_loader.load_raw_data_from_config(\n",
    "    id=[\"RBSP\", \"EMFISIS\", \"L4\", \"WNA_SURVEY\"],\n",
    "    start=start,\n",
    "    end=end,\n",
    "    satellite=\"b\",\n",
    "    root_data_dir=\"/project/rbsp/data/\",\n",
    "    use_config_keys_in_subdir=False,\n",
    ")\n",
    "\n",
    "WFR_a = data_loader.load_raw_data_from_config(\n",
    "    id=[\"RBSP\", \"EMFISIS\", \"L2\", \"WFR_SPECTRAL_MATRIX_DIAGONAL\"],\n",
    "    start=start,\n",
    "    end=end,\n",
    "    satellite=\"a\",\n",
    "    root_data_dir=\"/project/rbsp/data/\",\n",
    "    use_config_keys_in_subdir=False,\n",
    ")\n",
    "\n",
    "WFR_b = data_loader.load_raw_data_from_config(\n",
    "    id=[\"RBSP\", \"EMFISIS\", \"L2\", \"WFR_SPECTRAL_MATRIX_DIAGONAL\"],\n",
    "    start=start,\n",
    "    end=end,\n",
    "    satellite=\"b\",\n",
    "    root_data_dir=\"/project/rbsp/data/\",\n",
    "    use_config_keys_in_subdir=False,\n",
    ")\n",
    "\n",
    "num_wna_files_A = len(WNA_a[\"timestamps_per_file\"])\n",
    "num_wna_files_B = len(WNA_b[\"timestamps_per_file\"])\n",
    "num_wfr_files_A = WFR_a[\"WFR_bandwidth\"].shape[0]\n",
    "num_wfr_files_B = WFR_b[\"WFR_bandwidth\"].shape[0]\n",
    "\n",
    "print(\n",
    "    f\"Number of files loaded: {num_wna_files_A, num_wna_files_B, num_wfr_files_A, num_wfr_files_B}\"\n",
    ")\n",
    "\n",
    "if len({num_wna_files_A, num_wfr_files_A}) != 1:\n",
    "    raise Exception(\"The same number of days wasn't loaded for RBSP-A!\")\n",
    "\n",
    "if len({num_wna_files_B, num_wfr_files_B}) != 1:\n",
    "    raise Exception(\"The same number of days wasn't loaded for RBSP-B!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes for A:\n",
      "(17660469,)\n",
      "(17660469,)\n",
      "(17660469,)\n",
      "(17660469,)\n",
      "\n",
      "\n",
      "Shapes for B:\n",
      "(12247254,)\n",
      "(12247254,)\n",
      "(12247254,)\n",
      "(12247254,)\n",
      "CPU times: user 2min 48s, sys: 5.39 s, total: 2min 54s\n",
      "Wall time: 2min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "MLT_A = WNA_a[\"MLT\"]\n",
    "L_A = WNA_a[\"L\"]\n",
    "EPOCH_A = WNA_a[\"Epoch\"]\n",
    "\n",
    "TIME_A = astropy.time.Time(cdfepoch.to_datetime(EPOCH_A), format=\"datetime\").unix\n",
    "\n",
    "CHORUS_A = rbsp_chorus_tool.iterate_through_days_and_calculate_chorus_amplitudes(\n",
    "    WNA_survey=WNA_a, WFR_spectral_matrix=WFR_a\n",
    ")\n",
    "\n",
    "LOWER_CHORUS_A = CHORUS_A[\"Lower_Band\"]\n",
    "UPPER_CHORUS_A = CHORUS_A[\"Upper_Band\"]\n",
    "\n",
    "within_epoch_range_A = (start.timestamp() < TIME_A) & (TIME_A < end.timestamp())\n",
    "finite_chorus_A = np.isfinite(LOWER_CHORUS_A) & np.isfinite(UPPER_CHORUS_A)\n",
    "all_valid_coordinates_A = (EPOCH_A > 0) & (0 <= MLT_A) & (MLT_A <= 24) & (0 < L_A) & (L_A < 10)\n",
    "\n",
    "L_A[~(within_epoch_range_A & finite_chorus_A & all_valid_coordinates_A)] = np.nan\n",
    "MLT_A[~(within_epoch_range_A & finite_chorus_A & all_valid_coordinates_A)] = np.nan\n",
    "LOWER_CHORUS_A[~(within_epoch_range_A & finite_chorus_A & all_valid_coordinates_A)] = np.nan\n",
    "UPPER_CHORUS_A[~(within_epoch_range_A & finite_chorus_A & all_valid_coordinates_A)] = np.nan\n",
    "\n",
    "L_A = np.interp(x=evenly_spaced_seconds, xp=TIME_A, fp=L_A)\n",
    "x_int_A = np.interp(\n",
    "    evenly_spaced_seconds,\n",
    "    xp=TIME_A,\n",
    "    fp=np.cos(MLT_A * 2 * np.pi / 24.0),\n",
    "    left=np.nan,\n",
    "    right=np.nan,\n",
    ")\n",
    "y_int_A = np.interp(\n",
    "    evenly_spaced_seconds,\n",
    "    xp=TIME_A,\n",
    "    fp=np.sin(MLT_A * 2 * np.pi / 24.0),\n",
    "    left=np.nan,\n",
    "    right=np.nan,\n",
    ")\n",
    "angle_A = np.mod(np.arctan2(y_int_A, x_int_A) + 2 * np.pi, 2 * np.pi)\n",
    "MLT_A = (angle_A * 24) / (2 * np.pi)\n",
    "\n",
    "LOWER_CHORUS_A = np.interp(x=evenly_spaced_seconds, xp=TIME_A, fp=LOWER_CHORUS_A)\n",
    "UPPER_CHORUS_A = np.interp(x=evenly_spaced_seconds, xp=TIME_A, fp=UPPER_CHORUS_A)\n",
    "\n",
    "NOT_NAN_A = (\n",
    "    np.isfinite(L_A)\n",
    "    & np.isfinite(MLT_A)\n",
    "    & np.isfinite(LOWER_CHORUS_A)\n",
    "    & np.isfinite(UPPER_CHORUS_A)\n",
    ")\n",
    "\n",
    "L_A = L_A[NOT_NAN_A]\n",
    "MLT_A = MLT_A[NOT_NAN_A]\n",
    "LOWER_CHORUS_A = LOWER_CHORUS_A[NOT_NAN_A]\n",
    "UPPER_CHORUS_A = UPPER_CHORUS_A[NOT_NAN_A]\n",
    "\n",
    "TIME_A = evenly_spaced_seconds[NOT_NAN_A]\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "MLT_B = WNA_b[\"MLT\"]\n",
    "L_B = WNA_b[\"L\"]\n",
    "EPOCH_B = WNA_b[\"Epoch\"]\n",
    "TIME_B = astropy.time.Time(cdfepoch.to_datetime(EPOCH_B), format=\"datetime\").unix\n",
    "\n",
    "CHORUS_B = rbsp_chorus_tool.iterate_through_days_and_calculate_chorus_amplitudes(\n",
    "    WNA_survey=WNA_b, WFR_spectral_matrix=WFR_b\n",
    ")\n",
    "\n",
    "LOWER_CHORUS_B = CHORUS_B[\"Lower_Band\"]\n",
    "UPPER_CHORUS_B = CHORUS_B[\"Upper_Band\"]\n",
    "\n",
    "within_epoch_range_B = (start.timestamp() < TIME_B) & (TIME_B < end.timestamp())\n",
    "finite_chorus_B = np.isfinite(LOWER_CHORUS_B) & np.isfinite(UPPER_CHORUS_B)\n",
    "all_valid_coordinates_B = (EPOCH_B > 0) & (0 <= MLT_B) & (MLT_B <= 24) & (0 < L_B) & (L_B < 10)\n",
    "\n",
    "L_B[~(within_epoch_range_B & finite_chorus_B & all_valid_coordinates_B)] = np.nan\n",
    "MLT_B[~(within_epoch_range_B & finite_chorus_B & all_valid_coordinates_B)] = np.nan\n",
    "LOWER_CHORUS_B[~(within_epoch_range_B & finite_chorus_B & all_valid_coordinates_B)] = np.nan\n",
    "UPPER_CHORUS_B[~(within_epoch_range_B & finite_chorus_B & all_valid_coordinates_B)] = np.nan\n",
    "\n",
    "L_B = np.interp(x=evenly_spaced_seconds, xp=TIME_B, fp=L_B)\n",
    "\n",
    "X_INTERPOLATED_B = np.interp(\n",
    "    evenly_spaced_seconds,\n",
    "    xp=TIME_B,\n",
    "    fp=np.cos(MLT_B * 2 * np.pi / 24.0),\n",
    "    left=np.nan,\n",
    "    right=np.nan,\n",
    ")\n",
    "Y_INTERPOLATED_B = np.interp(\n",
    "    evenly_spaced_seconds,\n",
    "    xp=TIME_B,\n",
    "    fp=np.sin(MLT_B * 2 * np.pi / 24.0),\n",
    "    left=np.nan,\n",
    "    right=np.nan,\n",
    ")\n",
    "ANGLE_IN_RADIANS_B = np.mod(np.arctan2(Y_INTERPOLATED_B, X_INTERPOLATED_B) + 2 * np.pi, 2 * np.pi)\n",
    "MLT_B = (ANGLE_IN_RADIANS_B * 24) / (2 * np.pi)\n",
    "\n",
    "LOWER_CHORUS_B = np.interp(x=evenly_spaced_seconds, xp=TIME_B, fp=LOWER_CHORUS_B)\n",
    "UPPER_CHORUS_B = np.interp(x=evenly_spaced_seconds, xp=TIME_B, fp=UPPER_CHORUS_B)\n",
    "\n",
    "NOT_NAN_B = (\n",
    "    np.isfinite(L_B)\n",
    "    & np.isfinite(MLT_B)\n",
    "    & np.isfinite(LOWER_CHORUS_B)\n",
    "    & np.isfinite(UPPER_CHORUS_B)\n",
    ")\n",
    "\n",
    "L_B = L_B[NOT_NAN_B]\n",
    "MLT_B = MLT_B[NOT_NAN_B]\n",
    "LOWER_CHORUS_B = LOWER_CHORUS_B[NOT_NAN_B]\n",
    "UPPER_CHORUS_B = UPPER_CHORUS_B[NOT_NAN_B]\n",
    "TIME_B = evenly_spaced_seconds[NOT_NAN_B]\n",
    "# -----------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "print(\"Shapes for A:\")\n",
    "print(LOWER_CHORUS_A.shape)\n",
    "print(UPPER_CHORUS_A.shape)\n",
    "print(L_A.shape)\n",
    "print(MLT_A.shape)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Shapes for B:\")\n",
    "print(LOWER_CHORUS_B.shape)\n",
    "print(UPPER_CHORUS_B.shape)\n",
    "print(L_B.shape)\n",
    "print(MLT_B.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the RBSP stage 1 data, might honestly only need one stage\n",
    "\n",
    "np.savez(\n",
    "    file=os.path.abspath(\n",
    "        f\"./../processed_data/chorus_neural_network/STAGE_1/CHORUS/RBSP_OBSERVED_CHORUS_{year}.npz\"\n",
    "    ),\n",
    "    UNIX_TIME_A=TIME_A,\n",
    "    MLT_A=MLT_A,\n",
    "    L_A=L_A,\n",
    "    LOWER_BAND_CHORUS_A=LOWER_CHORUS_A,\n",
    "    UPPER_BAND_CHORUS_A=UPPER_CHORUS_A,\n",
    "    UNIX_TIME_B=TIME_B,\n",
    "    MLT_B=MLT_B,\n",
    "    L_B=L_B,\n",
    "    LOWER_BAND_CHORUS_B=LOWER_CHORUS_B,\n",
    "    UPPER_BAND_CHORUS_B=UPPER_CHORUS_B,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 2, clean then combine RBSP, OMNI, and POES Data and find conjunctions between RBSP and POES See find_conjunctions_rbsp_poes.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 3, Look at the data and make sure its good enough, then remove solar proton events\n",
    "VERSION = \"v2b\"\n",
    "FIELD_MODEL = \"T89\"\n",
    "\n",
    "pdata_folder = os.path.abspath(r\"./../processed_data/chorus_neural_network/\")\n",
    "\n",
    "STAGE_2_folder = os.path.join(pdata_folder, \"STAGE_2\", VERSION)\n",
    "\n",
    "CONJUNCTIONS_REFS = np.load(\n",
    "    file=os.path.join(STAGE_2_folder, rf\"CONJUNCTIONS_{VERSION}_{FIELD_MODEL}.npz\")\n",
    ")\n",
    "\n",
    "CONJUNCTIONS_TESTING = CONJUNCTIONS_REFS[\"CONJUNCTIONS\"]\n",
    "\n",
    "CONJUNCTIONS_REFS.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"CONJUNCTION = [\n",
    "                    CHUNK_TIME + (T_SIZE / 2.0),\n",
    "                    AVG_L_POES[x_bin, y_bin],\n",
    "                    AVG_MLT_POES[x_bin, y_bin],\n",
    "                    AVG_FLUX_0[x_bin, y_bin],\n",
    "                    AVG_FLUX_1[x_bin, y_bin],\n",
    "                    AVG_FLUX_2[x_bin, y_bin],\n",
    "                    AVG_FLUX_3[x_bin, y_bin],\n",
    "                    AVG_FLUX_4[x_bin, y_bin],\n",
    "                    AVG_FLUX_5[x_bin, y_bin],\n",
    "                    AVG_FLUX_6[x_bin, y_bin],\n",
    "                    AVG_FLUX_7[x_bin, y_bin],\n",
    "                    CHUNK_TIME + (T_SIZE / 2.0),\n",
    "                    AVG_L_RBSP[x_bin, y_bin],  # LSTAR OF RBSP POINT CHOSEN\n",
    "                    AVG_MLT_RBSP[x_bin, y_bin],  # DIFFERENCE IN MLT FOUND\n",
    "                    AVG_UPPER_CHORUS[x_bin, y_bin],  # UPPER BAND CHORUS OBSERVED\n",
    "                    AVG_LOWER_CHORUS[x_bin, y_bin],  # LOWER BAND CHORUS OBSERVED\n",
    "                    SUPERMAG[\"SME\"],\n",
    "                    OMNI[\"AVG_B\"],\n",
    "                    OMNI[\"FLOW_SPEED\"],\n",
    "                    OMNI[\"PROTON_DENSITY\"],\n",
    "                    OMNI[\"SYM_H\"],\n",
    "                ]\"\"\"\n",
    "\n",
    "C_POES_TIME = CONJUNCTIONS_TESTING[:, 0]\n",
    "C_POES_LSTAR = CONJUNCTIONS_TESTING[:, 1]\n",
    "C_POES_MLT = CONJUNCTIONS_TESTING[:, 2]\n",
    "C_POES_FLUX = CONJUNCTIONS_TESTING[:, 3:-10]\n",
    "C_RBSP_TIME = CONJUNCTIONS_TESTING[:, -10]\n",
    "C_RBSP_LSTAR = CONJUNCTIONS_TESTING[:, -9]\n",
    "C_RBSP_MLT = CONJUNCTIONS_TESTING[:, -8]\n",
    "C_RBSP_UPPER_BAND = CONJUNCTIONS_TESTING[:, -7]\n",
    "C_RBSP_LOWER_BAND = CONJUNCTIONS_TESTING[:, -6]\n",
    "C_AVG_SME = CONJUNCTIONS_TESTING[:, -5]\n",
    "C_AVG_AVG_B = CONJUNCTIONS_TESTING[:, -4]\n",
    "C_AVG_FLOW_SPEED = CONJUNCTIONS_TESTING[:, -3]\n",
    "C_AVG_PROTON_DENSITY = CONJUNCTIONS_TESTING[:, -2]\n",
    "C_AVG_SYM_H = CONJUNCTIONS_TESTING[:, -1]\n",
    "\n",
    "with open(\n",
    "    os.path.join(STAGE_2_folder, rf\"CONJUNCTIONS_{VERSION}_{FIELD_MODEL}.txt\"),\n",
    "    \"w\",\n",
    ") as f:\n",
    "\n",
    "    f.write(\"\\nConjunctions:\\n\")\n",
    "    f.write(f\"Number of conjunctions: {CONJUNCTIONS_TESTING.shape[0]} [#]\\n\")\n",
    "    f.write(f\"Minimum RBSP Time: {np.min(C_RBSP_TIME)} [seconds since unix epoch]\\n\")\n",
    "    f.write(f\"Maximum RBSP Time: {np.max(C_RBSP_TIME)} [seconds since unix epoch]\\n\")\n",
    "    f.write(f\"Minimum POES Time: {np.min(C_POES_TIME)} [seconds since unix epoch]\\n\")\n",
    "    f.write(f\"Maximum POES Time: {np.max(C_POES_TIME)} [seconds since unix epoch]\\n\")\n",
    "\n",
    "    f.write(\"\\nL:\\n\")\n",
    "    f.write(f\"Mean Difference: {np.mean(C_POES_LSTAR - C_RBSP_LSTAR)} [L]\\n\")\n",
    "    f.write(f\"Standard deviation of Difference {np.std(C_POES_LSTAR - C_RBSP_LSTAR)} [L]\\n\")\n",
    "    f.write(f\"Minimum Absolute Difference : {np.min(np.abs(C_POES_LSTAR - C_RBSP_LSTAR))} [L]\\n\")\n",
    "    f.write(f\"Maximum Absolute Difference : {np.max(np.abs(C_POES_LSTAR - C_RBSP_LSTAR))} [L]\\n\")\n",
    "\n",
    "    f.write(\"\\nMLT: \\n\")\n",
    "    f.write(f\"Mean Difference: {np.mean(C_POES_MLT - C_RBSP_MLT)} [MLT]\\n\")\n",
    "    f.write(f\"Standard deviation of Difference {np.std(C_POES_MLT - C_RBSP_MLT)} [MLT]\\n\")\n",
    "    f.write(f\"Minimum Absolute Difference : {np.min(np.abs(C_POES_MLT - C_RBSP_MLT))} [MLT]\\n\")\n",
    "    f.write(f\"Maximum Absolute Difference : {np.max(np.abs(C_POES_MLT - C_RBSP_MLT))} [MLT]\\n\")\n",
    "\n",
    "    f.write(\"\\nTime: \\n\")\n",
    "    f.write(f\"Mean Difference: {np.mean(C_POES_TIME - C_RBSP_TIME)} [s]\\n\")\n",
    "    f.write(f\"Standard deviation of Difference {np.std(C_POES_TIME - C_RBSP_TIME)} [s]\\n\")\n",
    "    f.write(f\"Minimum Absolute Difference : {np.min(np.abs(C_POES_TIME - C_RBSP_TIME))} [s]\\n\")\n",
    "    f.write(f\"Maximum Absolute Difference : {np.max(np.abs(C_POES_TIME - C_RBSP_TIME))} [s]\\n\")\n",
    "\n",
    "    f.write(\"\\nUpper Band Chorus: \\n\")\n",
    "    f.write(f\"Mean: {np.mean(C_RBSP_UPPER_BAND)} [pT]\\n\")\n",
    "    f.write(f\"Standard Deviation: {np.std(C_RBSP_UPPER_BAND)} [pT]\\n\")\n",
    "    f.write(f\"Minimum: {np.min(C_RBSP_UPPER_BAND)} [pT]\\n\")\n",
    "    f.write(f\"Maximum: {np.max(C_RBSP_UPPER_BAND)} [pT]\\n\")\n",
    "\n",
    "    f.write(\"\\nLower Band Chorus: \\n\")\n",
    "    f.write(f\"Mean: {np.mean(C_RBSP_LOWER_BAND)} [pT]\\n\")\n",
    "    f.write(f\"Standard Deviation: {np.std(C_RBSP_LOWER_BAND)} [pT]\\n\")\n",
    "    f.write(f\"Minimum: {np.min(C_RBSP_LOWER_BAND)} [pT]\\n\")\n",
    "    f.write(f\"Maximum: {np.max(C_RBSP_LOWER_BAND)} [pT]\\n\")\n",
    "\n",
    "    f.write(\"\\nSME: \\n\")\n",
    "    f.write(f\"Mean: {np.mean(C_AVG_SME)} [nT]\\n\")\n",
    "    f.write(f\"Standard Deviation: {np.std(C_AVG_SME)} [nT]\\n\")\n",
    "    f.write(f\"Minimum: {np.min(C_AVG_SME)} [nT]\\n\")\n",
    "    f.write(f\"Maximum: {np.max(C_AVG_SME)} [nT]\\n\")\n",
    "\n",
    "    f.write(\"\\nAVG_B: \\n\")\n",
    "    f.write(f\"Mean: {np.mean(C_AVG_AVG_B)} [nT]\\n\")\n",
    "    f.write(f\"Standard Deviation: {np.std(C_AVG_AVG_B)} [nT]\\n\")\n",
    "    f.write(f\"Minimum: {np.min(C_AVG_AVG_B)} [nT]\\n\")\n",
    "    f.write(f\"Maximum: {np.max(C_AVG_AVG_B)} [nT]\\n\")\n",
    "\n",
    "    f.write(\"\\nFlow Speed: \\n\")\n",
    "    f.write(f\"Mean: {np.mean(C_AVG_FLOW_SPEED)} [km/s]\\n\")\n",
    "    f.write(f\"Standard Deviation: {np.std(C_AVG_FLOW_SPEED)} [km/s]\\n\")\n",
    "    f.write(f\"Minimum: {np.min(C_AVG_FLOW_SPEED)} [km/s]\\n\")\n",
    "    f.write(f\"Maximum: {np.max(C_AVG_FLOW_SPEED)} [km/s]\\n\")\n",
    "\n",
    "    f.write(\"\\nProton Density: \\n\")\n",
    "    f.write(f\"Mean: {np.mean(C_AVG_PROTON_DENSITY)} [n/cc]\\n\")\n",
    "    f.write(f\"Standard Deviation: {np.std(C_AVG_PROTON_DENSITY)} [n/cc]\\n\")\n",
    "    f.write(f\"Minimum: {np.min(C_AVG_PROTON_DENSITY)} [n/cc]\\n\")\n",
    "    f.write(f\"Maximum: {np.max(C_AVG_PROTON_DENSITY)} [n/cc]\\n\")\n",
    "\n",
    "    f.write(\"\\nSYM_H: \\n\")\n",
    "    f.write(f\"Mean: {np.mean(C_AVG_SYM_H)} [nT]\\n\")\n",
    "    f.write(f\"Standard Deviation: {np.std(C_AVG_SYM_H)} [nT]\\n\")\n",
    "    f.write(f\"Minimum: {np.min(C_AVG_SYM_H)} [nT]\\n\")\n",
    "    f.write(f\"Maximum: {np.max(C_AVG_SYM_H)} [nT]\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean difference: -5.1011684997619414e-05\n",
      "Standard deviation of difference 0.004311385268303223\n",
      "Maximum difference : 0.024900121050439594\n"
     ]
    }
   ],
   "source": [
    "plt.title(\"RBSP - Closest POES L Shell Comparison\")\n",
    "plt.xlabel(\"RBSP L-Shell\")\n",
    "plt.ylabel(\"Closest POES L-Shell\")\n",
    "plt.hlines(y=4, xmin=1, xmax=7, color=\"black\")\n",
    "plt.vlines(x=4, ymin=1, ymax=7, color=\"black\")\n",
    "\n",
    "plt.scatter(C_RBSP_LSTAR, C_POES_LSTAR, c=C_RBSP_LOWER_BAND, norm=matplotlib.colors.LogNorm(), s=1.5)\n",
    "\n",
    "print(f\"Mean difference: {np.mean(C_POES_LSTAR - C_RBSP_LSTAR)}\")\n",
    "print(f\"Standard deviation of difference {np.std(C_POES_LSTAR - C_RBSP_LSTAR)}\")\n",
    "print(f\"Maximum difference : {np.max(C_POES_LSTAR - C_RBSP_LSTAR)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 3 Continued, Removing solar proton events!\n",
    "\n",
    "VERSION = \"v2b\"\n",
    "FIELD_MODEL = \"T89\"\n",
    "\n",
    "pdata_folder = os.path.abspath(r\"./../processed_data/chorus_neural_network/\")\n",
    "\n",
    "STAGE_2_folder = os.path.join(pdata_folder, \"STAGE_2\", VERSION)\n",
    "STAGE_3_folder = os.path.join(pdata_folder, \"STAGE_3\", VERSION)\n",
    "\n",
    "\n",
    "CONJUNCTIONS_REFS = np.load(\n",
    "    os.path.join(STAGE_2_folder, rf\"CONJUNCTIONS_{VERSION}_{FIELD_MODEL}.npz\")\n",
    ")\n",
    "\n",
    "CONJUNCTIONS = CONJUNCTIONS_REFS[\"CONJUNCTIONS\"]\n",
    "\n",
    "CONJUNCTIONS_REFS.close()\n",
    "\n",
    "SOLAR_PROTON_EVENT_LIST = pd.read_csv(\n",
    "    os.path.join(pdata_folder, r\"SOLAR_PROTON_EVENT_LIST_1976_2024.csv\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting shape of conjunctions list: (1280149, 21)\n",
      "Removing high energy solar proton events!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 309/309 [00:17<00:00, 17.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished removing high energy solar proton events!\n",
      "Saving!\n",
      "Creating documentation of dataset!\n",
      "Finished!\n",
      "Ending shape of conjunctions : (1271173, 21)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"CONJUNCTION =  [UNIX_TIME,\n",
    "L,\n",
    "MLT,\n",
    "*FLUX_SPECTRUM,\n",
    "candidate[0], #TIME\n",
    "candidate[1], #L\n",
    "candidate[2], #MLT\n",
    "candidate[3], #del_MLT\n",
    "candidate[4], #CHORUS\n",
    "AVG_SME,\n",
    "AVG_AVG_B,\n",
    "AVG_FLOW_SPEED,\n",
    "AVG_PROTON_DENSITY,\n",
    "AVG_SYM_H]\"\"\"\n",
    "\n",
    "order_to_sort_conjunctions = np.argsort(\n",
    "    CONJUNCTIONS[:, 0]\n",
    ")  # Sorted based on POES Conjunction time!\n",
    "SORTED_CONJUNCTIONS = CONJUNCTIONS[order_to_sort_conjunctions, :]\n",
    "\n",
    "print(f\"Starting shape of conjunctions list: {SORTED_CONJUNCTIONS.shape}\")\n",
    "\n",
    "SORTED_POES_CONJUNCTION_TIMES = SORTED_CONJUNCTIONS[:, 0]\n",
    "\n",
    "START_OF_SEP_EVENTS_UTC = SOLAR_PROTON_EVENT_LIST[\"START\"]\n",
    "END_OF_SEP_EVENTS_UTC = SOLAR_PROTON_EVENT_LIST[\"END\"]\n",
    "ZIPPED_EVENTS = list(zip(START_OF_SEP_EVENTS_UTC, END_OF_SEP_EVENTS_UTC))\n",
    "\n",
    "print(\"Removing high energy solar proton events!\")\n",
    "\n",
    "for SEP_EVENT in tqdm.tqdm(range(len(ZIPPED_EVENTS))):\n",
    "\n",
    "    START = ZIPPED_EVENTS[SEP_EVENT][0].strip()\n",
    "    END = ZIPPED_EVENTS[SEP_EVENT][1].strip()\n",
    "\n",
    "    START_YMDHMS = {\n",
    "        \"year\": int(START[0:4]),\n",
    "        \"month\": int(START[5:7]),\n",
    "        \"day\": int(START[8:10]),\n",
    "        \"hour\": int(START[11:13]),\n",
    "        \"minute\": int(START[13:15]),\n",
    "        \"second\": 0,\n",
    "    }\n",
    "    END_YMDHMS = {\n",
    "        \"year\": int(END[0:4]),\n",
    "        \"month\": int(END[5:7]),\n",
    "        \"day\": int(END[8:10]),\n",
    "        \"hour\": int(END[11:13]),\n",
    "        \"minute\": int(END[13:15]),\n",
    "        \"second\": 0,\n",
    "    }\n",
    "\n",
    "    START_UNIX = astropy.time.Time(START_YMDHMS, format=\"ymdhms\", scale=\"utc\").unix\n",
    "    END_UNIX = astropy.time.Time(END_YMDHMS, format=\"ymdhms\", scale=\"utc\").unix\n",
    "\n",
    "    RANGE_TO_REMOVE = np.searchsorted(a=SORTED_POES_CONJUNCTION_TIMES, v=[START_UNIX, END_UNIX])\n",
    "\n",
    "    SORTED_CONJUNCTIONS = np.vstack(\n",
    "        (\n",
    "            SORTED_CONJUNCTIONS[0 : RANGE_TO_REMOVE[0], :],\n",
    "            SORTED_CONJUNCTIONS[RANGE_TO_REMOVE[1] :, :],\n",
    "        )\n",
    "    )\n",
    "\n",
    "print(\"Finished removing high energy solar proton events!\")\n",
    "\n",
    "print(\"Saving!\")\n",
    "\n",
    "CLEANED_CONJUNCTIONS = SORTED_CONJUNCTIONS  # Should be cleaned by now!\n",
    "\n",
    "np.savez(\n",
    "    file=os.path.join(STAGE_3_folder, rf\"CLEANED_CONJUNCTIONS_{VERSION}_{FIELD_MODEL}.npz\"),\n",
    "    CONJUNCTIONS=CLEANED_CONJUNCTIONS,\n",
    ")\n",
    "\n",
    "C_POES_TIME = CLEANED_CONJUNCTIONS[:, 0]\n",
    "C_POES_LSTAR = CLEANED_CONJUNCTIONS[:, 1]\n",
    "C_POES_MLT = CLEANED_CONJUNCTIONS[:, 2]\n",
    "C_POES_FLUX = CLEANED_CONJUNCTIONS[:, 3:-10]\n",
    "C_RBSP_TIME = CLEANED_CONJUNCTIONS[:, -10]\n",
    "C_RBSP_LSTAR = CLEANED_CONJUNCTIONS[:, -9]\n",
    "C_RBSP_MLT = CLEANED_CONJUNCTIONS[:, -8]\n",
    "C_RBSP_UPPER_BAND = CLEANED_CONJUNCTIONS[:, -7]\n",
    "C_RBSP_LOWER_BAND = CLEANED_CONJUNCTIONS[:, -6]\n",
    "C_AVG_SME = CLEANED_CONJUNCTIONS[:, -5]\n",
    "C_AVG_AVG_B = CLEANED_CONJUNCTIONS[:, -4]\n",
    "C_AVG_FLOW_SPEED = CLEANED_CONJUNCTIONS[:, -3]\n",
    "C_AVG_PROTON_DENSITY = CLEANED_CONJUNCTIONS[:, -2]\n",
    "C_AVG_SYM_H = CLEANED_CONJUNCTIONS[:, -1]\n",
    "\n",
    "print(\"Creating documentation of dataset!\")\n",
    "\n",
    "\n",
    "with open(\n",
    "    os.path.join(STAGE_3_folder, rf\"CLEANED_CONJUNCTIONS_{VERSION}_{FIELD_MODEL}.txt\"),\n",
    "    \"w\",\n",
    ") as f:\n",
    "\n",
    "    f.write(\"\\nConjunctions:\\n\")\n",
    "    f.write(f\"Number of conjunctions: {CLEANED_CONJUNCTIONS.shape[0]} [#]\\n\")\n",
    "    f.write(\n",
    "        f\"Number lost from cleaning solar proton events: {CONJUNCTIONS.shape[0] - CLEANED_CONJUNCTIONS.shape[0]} [#]\\n\"\n",
    "    )\n",
    "    f.write(f\"Minimum RBSP Time: {np.min(C_RBSP_TIME)} [seconds since unix epoch]\\n\")\n",
    "    f.write(f\"Maximum RBSP Time: {np.max(C_RBSP_TIME)} [seconds since unix epoch]\\n\")\n",
    "    f.write(f\"Minimum POES Time: {np.min(C_POES_TIME)} [seconds since unix epoch]\\n\")\n",
    "    f.write(f\"Maximum POES Time: {np.max(C_POES_TIME)} [seconds since unix epoch]\\n\")\n",
    "\n",
    "    f.write(\"\\nL:\\n\")\n",
    "    f.write(f\"Mean Difference: {np.mean(C_POES_LSTAR - C_RBSP_LSTAR)} [L]\\n\")\n",
    "    f.write(f\"Standard deviation of Difference {np.std(C_POES_LSTAR - C_RBSP_LSTAR)} [L]\\n\")\n",
    "    f.write(f\"Minimum Absolute Difference : {np.min(np.abs(C_POES_LSTAR - C_RBSP_LSTAR))} [L]\\n\")\n",
    "    f.write(f\"Maximum Absolute Difference : {np.max(np.abs(C_POES_LSTAR - C_RBSP_LSTAR))} [L]\\n\")\n",
    "\n",
    "    f.write(\"\\nMLT: \\n\")\n",
    "    f.write(f\"Mean Absolute Difference: {np.mean(C_POES_MLT - C_RBSP_MLT)} [MLT]\\n\")\n",
    "    f.write(f\"Standard deviation of Absolute Difference {np.std(C_POES_MLT - C_RBSP_MLT)} [MLT]\\n\")\n",
    "    f.write(f\"Minimum Absolute Difference : {np.min(np.abs(C_POES_MLT - C_RBSP_MLT))} [MLT]\\n\")\n",
    "    f.write(f\"Maximum Absolute Difference : {np.max(np.abs(C_POES_MLT - C_RBSP_MLT))} [MLT]\\n\")\n",
    "\n",
    "    f.write(\"\\nTime: \\n\")\n",
    "    f.write(f\"Mean Difference: {np.mean(C_POES_TIME - C_RBSP_TIME)} [s]\\n\")\n",
    "    f.write(f\"Standard deviation of Difference {np.std(C_POES_TIME - C_RBSP_TIME)} [s]\\n\")\n",
    "    f.write(f\"Minimum Absolute Difference : {np.min(np.abs(C_POES_TIME - C_RBSP_TIME))} [s]\\n\")\n",
    "    f.write(f\"Maximum Absolute Difference : {np.max(np.abs(C_POES_TIME - C_RBSP_TIME))} [s]\\n\")\n",
    "\n",
    "    f.write(\"\\nUpper Band Chorus: \\n\")\n",
    "    f.write(f\"Mean: {np.mean(C_RBSP_UPPER_BAND)} [pT]\\n\")\n",
    "    f.write(f\"Standard Deviation: {np.std(C_RBSP_UPPER_BAND)} [pT]\\n\")\n",
    "    f.write(f\"Minimum: {np.min(C_RBSP_UPPER_BAND)} [pT]\\n\")\n",
    "    f.write(f\"Maximum: {np.max(C_RBSP_UPPER_BAND)} [pT]\\n\")\n",
    "\n",
    "    f.write(\"\\nLower Band Chorus: \\n\")\n",
    "    f.write(f\"Mean: {np.mean(C_RBSP_LOWER_BAND)} [pT]\\n\")\n",
    "    f.write(f\"Standard Deviation: {np.std(C_RBSP_LOWER_BAND)} [pT]\\n\")\n",
    "    f.write(f\"Minimum: {np.min(C_RBSP_LOWER_BAND)} [pT]\\n\")\n",
    "    f.write(f\"Maximum: {np.max(C_RBSP_LOWER_BAND)} [pT]\\n\")\n",
    "\n",
    "    f.write(\"\\nSME: \\n\")\n",
    "    f.write(f\"Mean: {np.mean(C_AVG_SME)} [nT]\\n\")\n",
    "    f.write(f\"Standard Deviation: {np.std(C_AVG_SME)} [nT]\\n\")\n",
    "    f.write(f\"Minimum: {np.min(C_AVG_SME)} [nT]\\n\")\n",
    "    f.write(f\"Maximum: {np.max(C_AVG_SME)} [nT]\\n\")\n",
    "\n",
    "    f.write(\"\\nAVG_B: \\n\")\n",
    "    f.write(f\"Mean: {np.mean(C_AVG_AVG_B)} [nT]\\n\")\n",
    "    f.write(f\"Standard Deviation: {np.std(C_AVG_AVG_B)} [nT]\\n\")\n",
    "    f.write(f\"Minimum: {np.min(C_AVG_AVG_B)} [nT]\\n\")\n",
    "    f.write(f\"Maximum: {np.max(C_AVG_AVG_B)} [nT]\\n\")\n",
    "\n",
    "    f.write(\"\\nFlow Speed: \\n\")\n",
    "    f.write(f\"Mean: {np.mean(C_AVG_FLOW_SPEED)} [km/s]\\n\")\n",
    "    f.write(f\"Standard Deviation: {np.std(C_AVG_FLOW_SPEED)} [km/s]\\n\")\n",
    "    f.write(f\"Minimum: {np.min(C_AVG_FLOW_SPEED)} [km/s]\\n\")\n",
    "    f.write(f\"Maximum: {np.max(C_AVG_FLOW_SPEED)} [km/s]\\n\")\n",
    "\n",
    "    f.write(\"\\nProton Density: \\n\")\n",
    "    f.write(f\"Mean: {np.mean(C_AVG_PROTON_DENSITY)} [n/cc]\\n\")\n",
    "    f.write(f\"Standard Deviation: {np.std(C_AVG_PROTON_DENSITY)} [n/cc]\\n\")\n",
    "    f.write(f\"Minimum: {np.min(C_AVG_PROTON_DENSITY)} [n/cc]\\n\")\n",
    "    f.write(f\"Maximum: {np.max(C_AVG_PROTON_DENSITY)} [n/cc]\\n\")\n",
    "\n",
    "    f.write(\"\\nSYM_H: \\n\")\n",
    "    f.write(f\"Mean: {np.mean(C_AVG_SYM_H)} [nT]\\n\")\n",
    "    f.write(f\"Standard Deviation: {np.std(C_AVG_SYM_H)} [nT]\\n\")\n",
    "    f.write(f\"Minimum: {np.min(C_AVG_SYM_H)} [nT]\\n\")\n",
    "    f.write(f\"Maximum: {np.max(C_AVG_SYM_H)} [nT]\\n\")\n",
    "\n",
    "print(\"Finished!\")\n",
    "print(f\"Ending shape of conjunctions : {CLEANED_CONJUNCTIONS.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 4, Create datasets used for training, testing, etc\n",
    "\n",
    "VERSION = \"v2b\"\n",
    "FIELD_MODEL = \"T89\"\n",
    "MODEL_TYPE = \"LOWER_BAND\"\n",
    "\n",
    "pdata_folder = os.path.abspath(r\"./../processed_data/chorus_neural_network/\")\n",
    "STAGE_3_folder = os.path.join(pdata_folder, \"STAGE_3\", VERSION)\n",
    "STAGE_4_folder = os.path.join(pdata_folder, \"STAGE_4\", VERSION)\n",
    "\n",
    "CONJUNCTIONS_REFS = np.load(\n",
    "    file=os.path.join(STAGE_3_folder, rf\"CLEANED_CONJUNCTIONS_{VERSION}_{FIELD_MODEL}.npz\")\n",
    ")\n",
    "\n",
    "CONJUNCTIONS = CONJUNCTIONS_REFS[\"CONJUNCTIONS\"]\n",
    "\n",
    "CONJUNCTIONS_REFS.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 27.933563  34.87377   43.538303  54.355576  67.86044   84.72065\n",
      " 105.769844 132.0488  ]\n",
      "[ 6.9402084  8.664532  10.817272  13.504868  16.860207  21.049194\n",
      " 26.278954  32.80806  ]\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "POES = data_loader.load_raw_data_from_config(\n",
    "    id=[\"POES\", \"SEM\", \"MPE\"],\n",
    "    start=datetime.datetime(year=2000, month=1, day=1),\n",
    "    end=datetime.datetime(year=2000, month=1, day=2),\n",
    "    satellite=\"n15\",\n",
    ")\n",
    "\n",
    "ENERGIES = POES[\"energy\"][0]\n",
    "print(ENERGIES[:8])\n",
    "DIFF_E = ENERGIES[1:9] - ENERGIES[:8]\n",
    "print(DIFF_E)\n",
    "print(len(DIFF_E))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1271173, 21)\n",
      "Identifying Days of Data Points....\n",
      "Min day of year : 1.0\n",
      "Max day of year : 2600.0\n",
      "Number of conjunctions between jan 1, apr 1 2016: 12667\n",
      "(1271173, 1)\n",
      "(1271173, 1)\n",
      "(1271173, 1)\n",
      "(1271173, 1)\n",
      "(1271173, 1)\n",
      "(1271173, 1)\n",
      "(1271173, 1)\n",
      "(1271173, 1)\n",
      "(1271173, 1)\n",
      "(1271173, 1)\n",
      "(1271173, 1)\n",
      "(1271173, 1)\n",
      "(1271173, 1)\n",
      "(1271173, 1)\n",
      "(1258506, 5)\n",
      "(1258506, 1)\n",
      "(12667, 5)\n",
      "(12667, 1)\n"
     ]
    }
   ],
   "source": [
    "print(CONJUNCTIONS.shape)\n",
    "\n",
    "mission_start_date = datetime.datetime(year=2012, month=8, day=30)\n",
    "mission_end_date = datetime.datetime(year=2019, month=10, day=19)\n",
    "\n",
    "C_POES_TIME = CONJUNCTIONS[:, 0]\n",
    "\n",
    "feb1_2016_unix = astropy.time.Time(\n",
    "    {\"year\": 2016, \"month\": 2, \"day\": 1, \"hour\": 0, \"minute\": 0, \"second\": 0},\n",
    "    format=\"ymdhms\",\n",
    "    scale=\"utc\",\n",
    ").unix\n",
    "mar1_2016_unix = astropy.time.Time(\n",
    "    {\"year\": 2016, \"month\": 3, \"day\": 1, \"hour\": 0, \"minute\": 0, \"second\": 0},\n",
    "    format=\"ymdhms\",\n",
    "    scale=\"utc\",\n",
    ").unix\n",
    "\n",
    "feb_2016 = (feb1_2016_unix < C_POES_TIME) & (C_POES_TIME < mar1_2016_unix)\n",
    "within_mission_time = (mission_start_date.timestamp() < C_POES_TIME) & (C_POES_TIME < mission_end_date.timestamp())\n",
    "train_test_subset_selected = ~feb_2016 & within_mission_time\n",
    "validation_subset_selected = feb_2016 & within_mission_time\n",
    "\n",
    "DAY = np.zeros(shape=(C_POES_TIME.shape[0]))\n",
    "print(\"Identifying Days of Data Points....\")\n",
    "for DAY_ID, dt in enumerate(rrule.rrule(rrule.DAILY, dtstart=mission_start_date, until=mission_end_date)):\n",
    "\n",
    "    within_day = (dt.timestamp() <= C_POES_TIME) & (C_POES_TIME < (dt + datetime.timedelta(days=1)).timestamp())\n",
    "    DAY[within_day] = DAY_ID\n",
    "\n",
    "print(f\"Min day of year : {np.min(DAY)}\")\n",
    "print(f\"Max day of year : {np.max(DAY)}\")\n",
    "\n",
    "print(\n",
    "    f\"Number of conjunctions between jan 1, apr 1 2016: {np.count_nonzero(feb_2016)}\"\n",
    ")\n",
    "\n",
    "C_POES_TIME = np.expand_dims(CONJUNCTIONS[:, 0], axis=1)\n",
    "C_POES_LSTAR = np.expand_dims(CONJUNCTIONS[:, 1], axis=1)\n",
    "C_POES_MLT = np.expand_dims(CONJUNCTIONS[:, 2], axis=1)\n",
    "\n",
    "C_POES_FLUX = CONJUNCTIONS[:, 3:-10]\n",
    "C_POES_FLUX_INTEGRATED = np.expand_dims(np.sum(C_POES_FLUX * DIFF_E, axis=1), axis=1)\n",
    "\n",
    "C_RBSP_TIME = np.expand_dims(CONJUNCTIONS[:, -10], axis=1)\n",
    "C_RBSP_LSTAR = np.expand_dims(CONJUNCTIONS[:, -9], axis=1)\n",
    "C_RBSP_MLT = np.expand_dims(CONJUNCTIONS[:, -8], axis=1)\n",
    "C_RBSP_UPPER_BAND = np.expand_dims(CONJUNCTIONS[:, -7], axis=1)\n",
    "C_RBSP_LOWER_BAND = np.expand_dims(CONJUNCTIONS[:, -6], axis=1)\n",
    "C_AVG_SME = np.expand_dims(CONJUNCTIONS[:, -5], axis=1)\n",
    "C_AVG_AVG_B = np.expand_dims(CONJUNCTIONS[:, -4], axis=1)\n",
    "C_AVG_FLOW_SPEED = np.expand_dims(CONJUNCTIONS[:, -3], axis=1)\n",
    "C_AVG_PROTON_DENSITY = np.expand_dims(CONJUNCTIONS[:, -2], axis=1)\n",
    "C_AVG_SYM_H = np.expand_dims(CONJUNCTIONS[:, -1], axis=1)\n",
    "\n",
    "print(C_RBSP_TIME.shape)\n",
    "print(C_RBSP_LSTAR.shape)\n",
    "print(C_RBSP_UPPER_BAND.shape)\n",
    "print(C_RBSP_LOWER_BAND.shape)\n",
    "print(C_POES_TIME.shape)\n",
    "print(C_POES_LSTAR.shape)\n",
    "print(C_POES_MLT.shape)\n",
    "print(C_RBSP_MLT.shape)\n",
    "print(C_POES_FLUX_INTEGRATED.shape)\n",
    "print(C_AVG_SME.shape)\n",
    "print(C_AVG_AVG_B.shape)\n",
    "print(C_AVG_FLOW_SPEED.shape)\n",
    "print(C_AVG_PROTON_DENSITY.shape)\n",
    "print(C_AVG_SYM_H.shape)\n",
    "\n",
    "mean_LSTAR = np.nanmean(C_POES_LSTAR)\n",
    "std_LSTAR = np.std(C_POES_LSTAR)\n",
    "\n",
    "mean_fluxes = np.log10(np.nanmean(C_POES_FLUX))\n",
    "std_fluxes = np.log10(np.nanstd(C_POES_FLUX))\n",
    "\n",
    "mean_sme = np.log10(np.nanmean(C_AVG_SME))\n",
    "std_sme = np.log10(np.std(C_AVG_SME))\n",
    "\n",
    "mean_avg_b = np.nanmean(C_AVG_AVG_B)\n",
    "std_avg_b = np.std(C_AVG_AVG_B)\n",
    "\n",
    "mean_flow_speed = np.nanmean(C_AVG_FLOW_SPEED)\n",
    "std_flow_speed = np.std(C_AVG_FLOW_SPEED)\n",
    "\n",
    "mean_avg_proton_density = np.nanmean(C_AVG_PROTON_DENSITY)\n",
    "std_avg_proton_density = np.std(C_AVG_PROTON_DENSITY)\n",
    "\n",
    "mean_avg_sym_h = np.nanmean(C_AVG_SYM_H)\n",
    "std_avg_sym_h = np.std(C_AVG_SYM_H)\n",
    "\n",
    "\n",
    "'''from scipy.special import i0, i1\n",
    "def derivative_of_von_mises(x, mu, k):\n",
    "\n",
    "    return ((k * np.sin(x - mu) * np.exp(k * np.cos(x - mu)) / i0(x-mu)) - (i1(x-mu) * np.exp(k * np.cos(x - mu)) / (i0(x-mu) ** 2)))**2'''\n",
    "\n",
    "L_MAX = 9\n",
    "\n",
    "FEATURES = np.hstack(\n",
    "    (\n",
    "        C_POES_LSTAR,\n",
    "        np.cos((C_POES_MLT * 2 * np.pi) / 24.0),\n",
    "        np.sin((C_POES_MLT * 2 * np.pi) / 24.0),\n",
    "        np.log10(C_POES_FLUX_INTEGRATED),\n",
    "        np.log10(C_AVG_SME),\n",
    "    )\n",
    ")\n",
    "\n",
    "FEATURES_T = FEATURES[train_test_subset_selected, :]\n",
    "FEATURES_V = FEATURES[validation_subset_selected, :]\n",
    "\n",
    "if MODEL_TYPE == \"UPPER_BAND\":\n",
    "    MODEL_LABELS = C_RBSP_UPPER_BAND[train_test_subset_selected]\n",
    "    MODEL_LABELS_V = C_RBSP_UPPER_BAND[validation_subset_selected]\n",
    "\n",
    "elif MODEL_TYPE == \"LOWER_BAND\":\n",
    "    MODEL_LABELS = C_RBSP_LOWER_BAND[train_test_subset_selected]\n",
    "    MODEL_LABELS_V = C_RBSP_LOWER_BAND[validation_subset_selected]\n",
    "\n",
    "DAY_T = DAY[train_test_subset_selected]\n",
    "DAY_V = DAY[validation_subset_selected]\n",
    "\n",
    "print(FEATURES_T.shape)\n",
    "print(MODEL_LABELS.shape)\n",
    "print(FEATURES_V.shape)\n",
    "print(MODEL_LABELS_V.shape)\n",
    "\n",
    "np.savez(\n",
    "    file=os.path.join(STAGE_4_folder, f\"MODEL_READY_DATA_{VERSION}_{FIELD_MODEL}_{MODEL_TYPE}.npz\"),\n",
    "    FEATURES=FEATURES_T,\n",
    "    LABELS=MODEL_LABELS,\n",
    "    VALIDATION_FEATURES=FEATURES_V,\n",
    "    VALIDATION_LABELS=MODEL_LABELS_V,\n",
    "    TRAINING_DAY_IDS=DAY_T,\n",
    "    VALIDATION_DAY_IDS=DAY_V,\n",
    "    TRAINING_MLT=C_POES_MLT,\n",
    "    MEAN_L=mean_LSTAR,\n",
    "    STD_L=std_LSTAR,\n",
    "    MEAN_FLUXES=mean_fluxes,\n",
    "    STD_FLUXES=std_fluxes,\n",
    "    MEAN_SME=mean_sme,\n",
    "    STD_SME=std_sme,\n",
    "    MEAN_AVG_B=mean_avg_b,\n",
    "    STD_AVG_B=std_avg_b,\n",
    "    MEAN_FLOW_SPEED=mean_flow_speed,\n",
    "    STD_FLOW_SPEED=std_flow_speed,\n",
    "    MEAN_AVG_PROTON_DENSITY=mean_avg_proton_density,\n",
    "    STD_AVG_PROTON_DENSITY=std_avg_proton_density,\n",
    "    MEAN_AVG_SYM_H=mean_avg_sym_h,\n",
    "    STD_AVG_SYM_H=std_avg_sym_h,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
