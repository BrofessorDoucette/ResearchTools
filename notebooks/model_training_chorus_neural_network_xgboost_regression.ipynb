{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors\n",
    "import random\n",
    "import scipy.stats as stats\n",
    "import scipy.optimize\n",
    "\n",
    "\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: ((127456, 6), (127456, 1))\n",
      "Validation set shape: ((3284, 6), (3284, 1))\n"
     ]
    }
   ],
   "source": [
    "version = \"v5a\"\n",
    "\n",
    "CONJUNCTIONS_REFS = np.load(f\"./../processed_data_chorus_neural_network/STAGE_4/{version}/MODEL_READY_DATA_{version}.npz\")\n",
    "\n",
    "TRAINING_FEATURES = CONJUNCTIONS_REFS[\"FEATURES\"]\n",
    "TRAINING_LABELS = CONJUNCTIONS_REFS[\"LABELS\"]\n",
    "TRAINING_MLT = CONJUNCTIONS_REFS[\"TRAINING_MLT\"]\n",
    "\n",
    "VALIDATION_FEATURES = CONJUNCTIONS_REFS[\"VALIDATION_FEATURES\"]\n",
    "VALIDATION_LABELS = CONJUNCTIONS_REFS[\"VALIDATION_LABELS\"]\n",
    "\n",
    "#BINS = CONJUNCTIONS_REFS[\"BINS\"]\n",
    "\n",
    "CONJUNCTIONS_REFS.close()\n",
    "\n",
    "print(f\"Training set shape: {TRAINING_FEATURES.shape, TRAINING_LABELS.shape}\")\n",
    "print(f\"Validation set shape: {VALIDATION_FEATURES.shape, VALIDATION_LABELS.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20202284213155508 396.82318419218063\n",
      "[1.05008292 0.30878761 1.35738169 ... 0.56917765 0.19059114 0.27939985]\n"
     ]
    }
   ],
   "source": [
    "#Find weights \n",
    "\n",
    "MAX_CHORUS = np.nanmax(TRAINING_LABELS)\n",
    "MIN_CHORUS = np.nanmin(TRAINING_LABELS)\n",
    "\n",
    "print(MIN_CHORUS, MAX_CHORUS)\n",
    "\n",
    "CHORUS_WEIGHTING_BINS = np.logspace(np.log10(MIN_CHORUS), np.log10(MAX_CHORUS), base = 10, num=30)\n",
    "BINNED_CHORUS_HISTOGRAM = np.histogram(TRAINING_LABELS, bins = CHORUS_WEIGHTING_BINS, density=True)\n",
    "\n",
    "\n",
    "X_POINTS = (BINNED_CHORUS_HISTOGRAM[1][:-1] + BINNED_CHORUS_HISTOGRAM[1][1:]) / 2.0\n",
    "Y_POINTS = BINNED_CHORUS_HISTOGRAM[0]\n",
    "\n",
    "SAMPLE_WEIGHTS_FROM_CHORUS_DISTRIBUTION = np.log10(1 / np.exp(np.interp(x = TRAINING_LABELS.flatten(), xp = X_POINTS, fp = np.log(Y_POINTS))))\n",
    "\n",
    "order_of_labels = np.argsort(TRAINING_LABELS.flatten())\n",
    "\n",
    "print(SAMPLE_WEIGHTS_FROM_CHORUS_DISTRIBUTION)\n",
    "\n",
    "# Plot the histogram of the data and the fitted distribution\n",
    "plt.plot(X_POINTS, BINNED_CHORUS_HISTOGRAM[0], label = \"Data\")\n",
    "\n",
    "plt.ylabel(\"Percentage of dataset\")\n",
    "plt.xlabel(\"Chorus Amplitude (pT)\")\n",
    "plt.plot(TRAINING_LABELS[order_of_labels], SAMPLE_WEIGHTS_FROM_CHORUS_DISTRIBUTION[order_of_labels].flatten(), label = \"SAMPLE_WEIGHTS\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = xgb.DMatrix(TRAINING_FEATURES, TRAINING_LABELS)\n",
    "validation_set = xgb.DMatrix(VALIDATION_FEATURES, VALIDATION_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom learning rate schedule\n",
    "def custom_learning_rate(current_iter):\n",
    "    base_learning_rate = 1.0\n",
    "    \n",
    "    lr = base_learning_rate * np.power(0.5, np.floor(current_iter / 20))\n",
    "    print(f\"Learning Rate: {lr}\")\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate: 1.0\n",
      "[0]\ttrain-rmse:8.65442\tvalidation-rmse:9.57779\n",
      "Learning Rate: 1.0\n",
      "[1]\ttrain-rmse:8.34594\tvalidation-rmse:9.35235\n",
      "Learning Rate: 1.0\n",
      "[2]\ttrain-rmse:8.23671\tvalidation-rmse:9.43479\n",
      "Learning Rate: 1.0\n",
      "[3]\ttrain-rmse:8.14659\tvalidation-rmse:9.49502\n",
      "Learning Rate: 1.0\n",
      "[4]\ttrain-rmse:8.09703\tvalidation-rmse:9.51391\n",
      "Learning Rate: 1.0\n",
      "[5]\ttrain-rmse:8.06096\tvalidation-rmse:9.50110\n",
      "Learning Rate: 1.0\n",
      "[6]\ttrain-rmse:8.04117\tvalidation-rmse:9.53754\n",
      "Learning Rate: 1.0\n",
      "[7]\ttrain-rmse:8.02137\tvalidation-rmse:9.55373\n",
      "Learning Rate: 1.0\n",
      "[8]\ttrain-rmse:8.00199\tvalidation-rmse:9.55672\n",
      "Learning Rate: 1.0\n",
      "[9]\ttrain-rmse:7.97389\tvalidation-rmse:9.61413\n",
      "Learning Rate: 1.0\n",
      "[10]\ttrain-rmse:7.94661\tvalidation-rmse:9.62616\n",
      "Learning Rate: 1.0\n",
      "[11]\ttrain-rmse:7.92687\tvalidation-rmse:9.65545\n",
      "Learning Rate: 1.0\n",
      "[12]\ttrain-rmse:7.90208\tvalidation-rmse:9.65999\n",
      "Learning Rate: 1.0\n",
      "[13]\ttrain-rmse:7.88776\tvalidation-rmse:9.67143\n",
      "Learning Rate: 1.0\n",
      "[14]\ttrain-rmse:7.86466\tvalidation-rmse:9.64886\n",
      "Learning Rate: 1.0\n",
      "[15]\ttrain-rmse:7.84295\tvalidation-rmse:9.65576\n",
      "Learning Rate: 1.0\n",
      "[16]\ttrain-rmse:7.82796\tvalidation-rmse:9.63285\n",
      "Learning Rate: 1.0\n",
      "[17]\ttrain-rmse:7.81066\tvalidation-rmse:9.66599\n",
      "Learning Rate: 1.0\n",
      "[18]\ttrain-rmse:7.79049\tvalidation-rmse:9.67379\n",
      "Learning Rate: 1.0\n",
      "[19]\ttrain-rmse:7.77991\tvalidation-rmse:9.69352\n",
      "Learning Rate: 0.5\n",
      "[20]\ttrain-rmse:7.75934\tvalidation-rmse:9.70012\n",
      "Learning Rate: 0.5\n",
      "[21]\ttrain-rmse:7.74907\tvalidation-rmse:9.69495\n",
      "Learning Rate: 0.5\n",
      "[22]\ttrain-rmse:7.74046\tvalidation-rmse:9.68891\n",
      "Learning Rate: 0.5\n",
      "[23]\ttrain-rmse:7.73310\tvalidation-rmse:9.71000\n",
      "Learning Rate: 0.5\n",
      "[24]\ttrain-rmse:7.72558\tvalidation-rmse:9.71743\n",
      "Learning Rate: 0.5\n",
      "[25]\ttrain-rmse:7.71517\tvalidation-rmse:9.71103\n",
      "Learning Rate: 0.5\n",
      "[26]\ttrain-rmse:7.70722\tvalidation-rmse:9.70939\n",
      "Learning Rate: 0.5\n",
      "[27]\ttrain-rmse:7.69930\tvalidation-rmse:9.70520\n",
      "Learning Rate: 0.5\n",
      "[28]\ttrain-rmse:7.68981\tvalidation-rmse:9.71096\n",
      "Learning Rate: 0.5\n",
      "[29]\ttrain-rmse:7.68138\tvalidation-rmse:9.72675\n",
      "Learning Rate: 0.5\n",
      "[30]\ttrain-rmse:7.67386\tvalidation-rmse:9.72283\n",
      "Learning Rate: 0.5\n",
      "[31]\ttrain-rmse:7.66580\tvalidation-rmse:9.72841\n",
      "Learning Rate: 0.5\n",
      "[32]\ttrain-rmse:7.65835\tvalidation-rmse:9.72598\n",
      "Learning Rate: 0.5\n",
      "[33]\ttrain-rmse:7.65050\tvalidation-rmse:9.72057\n",
      "Learning Rate: 0.5\n",
      "[34]\ttrain-rmse:7.64370\tvalidation-rmse:9.72490\n",
      "Learning Rate: 0.5\n",
      "[35]\ttrain-rmse:7.63583\tvalidation-rmse:9.72136\n",
      "Learning Rate: 0.5\n",
      "[36]\ttrain-rmse:7.63032\tvalidation-rmse:9.72375\n",
      "Learning Rate: 0.5\n",
      "[37]\ttrain-rmse:7.62650\tvalidation-rmse:9.72438\n",
      "Learning Rate: 0.5\n",
      "[38]\ttrain-rmse:7.62217\tvalidation-rmse:9.71298\n",
      "Learning Rate: 0.5\n",
      "[39]\ttrain-rmse:7.61677\tvalidation-rmse:9.71431\n",
      "Learning Rate: 0.25\n",
      "[40]\ttrain-rmse:7.60944\tvalidation-rmse:9.71917\n",
      "Learning Rate: 0.25\n",
      "[41]\ttrain-rmse:7.60830\tvalidation-rmse:9.71441\n",
      "Learning Rate: 0.25\n",
      "[42]\ttrain-rmse:7.60506\tvalidation-rmse:9.71128\n",
      "Learning Rate: 0.25\n",
      "[43]\ttrain-rmse:7.60167\tvalidation-rmse:9.70187\n",
      "Learning Rate: 0.25\n",
      "[44]\ttrain-rmse:7.59654\tvalidation-rmse:9.70301\n",
      "Learning Rate: 0.25\n",
      "[45]\ttrain-rmse:7.59163\tvalidation-rmse:9.69914\n",
      "Learning Rate: 0.25\n",
      "[46]\ttrain-rmse:7.58750\tvalidation-rmse:9.70094\n",
      "Learning Rate: 0.25\n",
      "[47]\ttrain-rmse:7.58409\tvalidation-rmse:9.71520\n",
      "Learning Rate: 0.25\n",
      "[48]\ttrain-rmse:7.58096\tvalidation-rmse:9.72061\n",
      "Learning Rate: 0.25\n",
      "[49]\ttrain-rmse:7.57636\tvalidation-rmse:9.71931\n",
      "Learning Rate: 0.25\n",
      "[50]\ttrain-rmse:7.57366\tvalidation-rmse:9.72825\n",
      "Learning Rate: 0.25\n",
      "[51]\ttrain-rmse:7.57008\tvalidation-rmse:9.72647\n",
      "Learning Rate: 0.25\n",
      "[52]\ttrain-rmse:7.56545\tvalidation-rmse:9.72108\n",
      "Learning Rate: 0.25\n",
      "[53]\ttrain-rmse:7.56080\tvalidation-rmse:9.72213\n",
      "Learning Rate: 0.25\n",
      "[54]\ttrain-rmse:7.55704\tvalidation-rmse:9.72405\n",
      "Learning Rate: 0.25\n",
      "[55]\ttrain-rmse:7.55362\tvalidation-rmse:9.71705\n",
      "Learning Rate: 0.25\n",
      "[56]\ttrain-rmse:7.55029\tvalidation-rmse:9.71184\n",
      "Learning Rate: 0.25\n",
      "[57]\ttrain-rmse:7.54714\tvalidation-rmse:9.70831\n",
      "Learning Rate: 0.25\n",
      "[58]\ttrain-rmse:7.54564\tvalidation-rmse:9.71024\n",
      "Learning Rate: 0.25\n",
      "[59]\ttrain-rmse:7.54208\tvalidation-rmse:9.70505\n",
      "Learning Rate: 0.125\n",
      "[60]\ttrain-rmse:7.53863\tvalidation-rmse:9.71220\n",
      "Learning Rate: 0.125\n",
      "[61]\ttrain-rmse:7.53635\tvalidation-rmse:9.71399\n",
      "Learning Rate: 0.125\n",
      "[62]\ttrain-rmse:7.53412\tvalidation-rmse:9.71561\n",
      "Learning Rate: 0.125\n",
      "[63]\ttrain-rmse:7.53215\tvalidation-rmse:9.71894\n",
      "Learning Rate: 0.125\n",
      "[64]\ttrain-rmse:7.53055\tvalidation-rmse:9.71749\n",
      "Learning Rate: 0.125\n",
      "[65]\ttrain-rmse:7.52899\tvalidation-rmse:9.71390\n",
      "Learning Rate: 0.125\n",
      "[66]\ttrain-rmse:7.52705\tvalidation-rmse:9.71215\n",
      "Learning Rate: 0.125\n",
      "[67]\ttrain-rmse:7.52539\tvalidation-rmse:9.71427\n",
      "Learning Rate: 0.125\n",
      "[68]\ttrain-rmse:7.52333\tvalidation-rmse:9.71308\n",
      "Learning Rate: 0.125\n",
      "[69]\ttrain-rmse:7.52132\tvalidation-rmse:9.71544\n",
      "Learning Rate: 0.125\n",
      "[70]\ttrain-rmse:7.51994\tvalidation-rmse:9.71538\n",
      "Learning Rate: 0.125\n",
      "[71]\ttrain-rmse:7.51819\tvalidation-rmse:9.71557\n",
      "Learning Rate: 0.125\n",
      "[72]\ttrain-rmse:7.51647\tvalidation-rmse:9.71303\n",
      "Learning Rate: 0.125\n",
      "[73]\ttrain-rmse:7.51416\tvalidation-rmse:9.71390\n",
      "Learning Rate: 0.125\n",
      "[74]\ttrain-rmse:7.51275\tvalidation-rmse:9.71233\n",
      "Learning Rate: 0.125\n",
      "[75]\ttrain-rmse:7.51139\tvalidation-rmse:9.71229\n",
      "Learning Rate: 0.125\n",
      "[76]\ttrain-rmse:7.50941\tvalidation-rmse:9.71550\n",
      "Learning Rate: 0.125\n",
      "[77]\ttrain-rmse:7.50743\tvalidation-rmse:9.71656\n",
      "Learning Rate: 0.125\n",
      "[78]\ttrain-rmse:7.50608\tvalidation-rmse:9.71751\n",
      "Learning Rate: 0.125\n",
      "[79]\ttrain-rmse:7.50409\tvalidation-rmse:9.71345\n",
      "Learning Rate: 0.0625\n",
      "[80]\ttrain-rmse:7.50212\tvalidation-rmse:9.71325\n",
      "Learning Rate: 0.0625\n",
      "[81]\ttrain-rmse:7.50110\tvalidation-rmse:9.71359\n",
      "Learning Rate: 0.0625\n",
      "[82]\ttrain-rmse:7.50038\tvalidation-rmse:9.71302\n",
      "Learning Rate: 0.0625\n",
      "[83]\ttrain-rmse:7.49948\tvalidation-rmse:9.71288\n",
      "Learning Rate: 0.0625\n",
      "[84]\ttrain-rmse:7.49917\tvalidation-rmse:9.71143\n",
      "Learning Rate: 0.0625\n",
      "[85]\ttrain-rmse:7.49843\tvalidation-rmse:9.71070\n",
      "Learning Rate: 0.0625\n",
      "[86]\ttrain-rmse:7.49748\tvalidation-rmse:9.71110\n",
      "Learning Rate: 0.0625\n",
      "[87]\ttrain-rmse:7.49654\tvalidation-rmse:9.71226\n",
      "Learning Rate: 0.0625\n",
      "[88]\ttrain-rmse:7.49581\tvalidation-rmse:9.71271\n",
      "Learning Rate: 0.0625\n",
      "[89]\ttrain-rmse:7.49476\tvalidation-rmse:9.71207\n",
      "Learning Rate: 0.0625\n",
      "[90]\ttrain-rmse:7.49381\tvalidation-rmse:9.71123\n",
      "Learning Rate: 0.0625\n",
      "[91]\ttrain-rmse:7.49285\tvalidation-rmse:9.71261\n",
      "Learning Rate: 0.0625\n",
      "[92]\ttrain-rmse:7.49195\tvalidation-rmse:9.71238\n",
      "Learning Rate: 0.0625\n",
      "[93]\ttrain-rmse:7.49135\tvalidation-rmse:9.71491\n",
      "Learning Rate: 0.0625\n",
      "[94]\ttrain-rmse:7.49053\tvalidation-rmse:9.71423\n",
      "Learning Rate: 0.0625\n",
      "[95]\ttrain-rmse:7.48957\tvalidation-rmse:9.71485\n",
      "Learning Rate: 0.0625\n",
      "[96]\ttrain-rmse:7.48861\tvalidation-rmse:9.71540\n",
      "Learning Rate: 0.0625\n",
      "[97]\ttrain-rmse:7.48783\tvalidation-rmse:9.71472\n",
      "Learning Rate: 0.0625\n",
      "[98]\ttrain-rmse:7.48685\tvalidation-rmse:9.71288\n",
      "Learning Rate: 0.0625\n",
      "[99]\ttrain-rmse:7.48607\tvalidation-rmse:9.71312\n",
      "Learning Rate: 0.03125\n",
      "[100]\ttrain-rmse:7.48524\tvalidation-rmse:9.71445\n",
      "Learning Rate: 0.03125\n",
      "[101]\ttrain-rmse:7.48485\tvalidation-rmse:9.71472\n",
      "Learning Rate: 0.03125\n",
      "[102]\ttrain-rmse:7.48444\tvalidation-rmse:9.71440\n",
      "Learning Rate: 0.03125\n",
      "[103]\ttrain-rmse:7.48398\tvalidation-rmse:9.71396\n",
      "Learning Rate: 0.03125\n",
      "[104]\ttrain-rmse:7.48354\tvalidation-rmse:9.71422\n",
      "Learning Rate: 0.03125\n",
      "[105]\ttrain-rmse:7.48334\tvalidation-rmse:9.71500\n",
      "Learning Rate: 0.03125\n",
      "[106]\ttrain-rmse:7.48299\tvalidation-rmse:9.71585\n",
      "Learning Rate: 0.03125\n",
      "[107]\ttrain-rmse:7.48255\tvalidation-rmse:9.71737\n",
      "Learning Rate: 0.03125\n",
      "[108]\ttrain-rmse:7.48208\tvalidation-rmse:9.71754\n",
      "Learning Rate: 0.03125\n",
      "[109]\ttrain-rmse:7.48160\tvalidation-rmse:9.71770\n",
      "Learning Rate: 0.03125\n",
      "[110]\ttrain-rmse:7.48121\tvalidation-rmse:9.71695\n",
      "Learning Rate: 0.03125\n",
      "[111]\ttrain-rmse:7.48078\tvalidation-rmse:9.71747\n",
      "Learning Rate: 0.03125\n",
      "[112]\ttrain-rmse:7.48043\tvalidation-rmse:9.71741\n",
      "Learning Rate: 0.03125\n",
      "[113]\ttrain-rmse:7.47993\tvalidation-rmse:9.71777\n",
      "Learning Rate: 0.03125\n",
      "[114]\ttrain-rmse:7.47958\tvalidation-rmse:9.71728\n",
      "Learning Rate: 0.03125\n",
      "[115]\ttrain-rmse:7.47924\tvalidation-rmse:9.71747\n",
      "Learning Rate: 0.03125\n",
      "[116]\ttrain-rmse:7.47873\tvalidation-rmse:9.71838\n",
      "Learning Rate: 0.03125\n",
      "[117]\ttrain-rmse:7.47821\tvalidation-rmse:9.71854\n",
      "Learning Rate: 0.03125\n",
      "[118]\ttrain-rmse:7.47783\tvalidation-rmse:9.71801\n",
      "Learning Rate: 0.03125\n",
      "[119]\ttrain-rmse:7.47743\tvalidation-rmse:9.71847\n",
      "Learning Rate: 0.015625\n",
      "[120]\ttrain-rmse:7.47691\tvalidation-rmse:9.71819\n",
      "Learning Rate: 0.015625\n",
      "[121]\ttrain-rmse:7.47672\tvalidation-rmse:9.71830\n",
      "Learning Rate: 0.015625\n",
      "[122]\ttrain-rmse:7.47648\tvalidation-rmse:9.71793\n",
      "Learning Rate: 0.015625\n",
      "[123]\ttrain-rmse:7.47630\tvalidation-rmse:9.71769\n",
      "Learning Rate: 0.015625\n",
      "[124]\ttrain-rmse:7.47610\tvalidation-rmse:9.71774\n",
      "Learning Rate: 0.015625\n",
      "[125]\ttrain-rmse:7.47585\tvalidation-rmse:9.71763\n",
      "Learning Rate: 0.015625\n",
      "[126]\ttrain-rmse:7.47566\tvalidation-rmse:9.71757\n",
      "Learning Rate: 0.015625\n",
      "[127]\ttrain-rmse:7.47543\tvalidation-rmse:9.71747\n",
      "Learning Rate: 0.015625\n",
      "[128]\ttrain-rmse:7.47524\tvalidation-rmse:9.71766\n",
      "Learning Rate: 0.015625\n",
      "[129]\ttrain-rmse:7.47506\tvalidation-rmse:9.71763\n",
      "Learning Rate: 0.015625\n",
      "[130]\ttrain-rmse:7.47485\tvalidation-rmse:9.71782\n",
      "Learning Rate: 0.015625\n",
      "[131]\ttrain-rmse:7.47467\tvalidation-rmse:9.71798\n",
      "Learning Rate: 0.015625\n",
      "[132]\ttrain-rmse:7.47448\tvalidation-rmse:9.71828\n",
      "Learning Rate: 0.015625\n",
      "[133]\ttrain-rmse:7.47425\tvalidation-rmse:9.71795\n",
      "Learning Rate: 0.015625\n",
      "[134]\ttrain-rmse:7.47403\tvalidation-rmse:9.71778\n",
      "Learning Rate: 0.015625\n",
      "[135]\ttrain-rmse:7.47372\tvalidation-rmse:9.71759\n",
      "Learning Rate: 0.015625\n",
      "[136]\ttrain-rmse:7.47349\tvalidation-rmse:9.71798\n",
      "Learning Rate: 0.015625\n",
      "[137]\ttrain-rmse:7.47336\tvalidation-rmse:9.71802\n",
      "Learning Rate: 0.015625\n",
      "[138]\ttrain-rmse:7.47314\tvalidation-rmse:9.71809\n",
      "Learning Rate: 0.015625\n",
      "[139]\ttrain-rmse:7.47298\tvalidation-rmse:9.71856\n",
      "Learning Rate: 0.0078125\n",
      "[140]\ttrain-rmse:7.47275\tvalidation-rmse:9.71809\n",
      "Learning Rate: 0.0078125\n",
      "[141]\ttrain-rmse:7.47264\tvalidation-rmse:9.71786\n",
      "Learning Rate: 0.0078125\n",
      "[142]\ttrain-rmse:7.47252\tvalidation-rmse:9.71785\n",
      "Learning Rate: 0.0078125\n",
      "[143]\ttrain-rmse:7.47242\tvalidation-rmse:9.71769\n",
      "Learning Rate: 0.0078125\n",
      "[144]\ttrain-rmse:7.47230\tvalidation-rmse:9.71780\n",
      "Learning Rate: 0.0078125\n",
      "[145]\ttrain-rmse:7.47219\tvalidation-rmse:9.71796\n",
      "Learning Rate: 0.0078125\n",
      "[146]\ttrain-rmse:7.47208\tvalidation-rmse:9.71792\n",
      "Learning Rate: 0.0078125\n",
      "[147]\ttrain-rmse:7.47204\tvalidation-rmse:9.71794\n",
      "Learning Rate: 0.0078125\n",
      "[148]\ttrain-rmse:7.47191\tvalidation-rmse:9.71786\n",
      "Learning Rate: 0.0078125\n",
      "[149]\ttrain-rmse:7.47180\tvalidation-rmse:9.71784\n",
      "Learning Rate: 0.0078125\n",
      "[150]\ttrain-rmse:7.47170\tvalidation-rmse:9.71809\n",
      "Learning Rate: 0.0078125\n",
      "[151]\ttrain-rmse:7.47160\tvalidation-rmse:9.71812\n",
      "Learning Rate: 0.0078125\n",
      "[152]\ttrain-rmse:7.47151\tvalidation-rmse:9.71826\n",
      "Learning Rate: 0.0078125\n",
      "[153]\ttrain-rmse:7.47139\tvalidation-rmse:9.71826\n",
      "Learning Rate: 0.0078125\n",
      "[154]\ttrain-rmse:7.47129\tvalidation-rmse:9.71822\n",
      "Learning Rate: 0.0078125\n",
      "[155]\ttrain-rmse:7.47118\tvalidation-rmse:9.71810\n",
      "Learning Rate: 0.0078125\n",
      "[156]\ttrain-rmse:7.47107\tvalidation-rmse:9.71811\n",
      "Learning Rate: 0.0078125\n",
      "[157]\ttrain-rmse:7.47098\tvalidation-rmse:9.71833\n",
      "Learning Rate: 0.0078125\n",
      "[158]\ttrain-rmse:7.47086\tvalidation-rmse:9.71813\n",
      "Learning Rate: 0.0078125\n",
      "[159]\ttrain-rmse:7.47073\tvalidation-rmse:9.71806\n",
      "Learning Rate: 0.00390625\n",
      "[160]\ttrain-rmse:7.47060\tvalidation-rmse:9.71797\n",
      "Learning Rate: 0.00390625\n",
      "[161]\ttrain-rmse:7.47056\tvalidation-rmse:9.71790\n",
      "Learning Rate: 0.00390625\n",
      "[162]\ttrain-rmse:7.47049\tvalidation-rmse:9.71812\n",
      "Learning Rate: 0.00390625\n",
      "[163]\ttrain-rmse:7.47043\tvalidation-rmse:9.71808\n",
      "Learning Rate: 0.00390625\n",
      "[164]\ttrain-rmse:7.47038\tvalidation-rmse:9.71811\n",
      "Learning Rate: 0.00390625\n",
      "[165]\ttrain-rmse:7.47033\tvalidation-rmse:9.71805\n",
      "Learning Rate: 0.00390625\n",
      "[166]\ttrain-rmse:7.47027\tvalidation-rmse:9.71805\n",
      "Learning Rate: 0.00390625\n",
      "[167]\ttrain-rmse:7.47020\tvalidation-rmse:9.71805\n",
      "Learning Rate: 0.00390625\n",
      "[168]\ttrain-rmse:7.47015\tvalidation-rmse:9.71809\n",
      "Learning Rate: 0.00390625\n",
      "[169]\ttrain-rmse:7.47010\tvalidation-rmse:9.71810\n",
      "Learning Rate: 0.00390625\n",
      "[170]\ttrain-rmse:7.47004\tvalidation-rmse:9.71818\n",
      "Learning Rate: 0.00390625\n",
      "[171]\ttrain-rmse:7.46999\tvalidation-rmse:9.71813\n",
      "Learning Rate: 0.00390625\n",
      "[172]\ttrain-rmse:7.46994\tvalidation-rmse:9.71814\n",
      "Learning Rate: 0.00390625\n",
      "[173]\ttrain-rmse:7.46989\tvalidation-rmse:9.71804\n",
      "Learning Rate: 0.00390625\n",
      "[174]\ttrain-rmse:7.46983\tvalidation-rmse:9.71795\n",
      "Learning Rate: 0.00390625\n",
      "[175]\ttrain-rmse:7.46978\tvalidation-rmse:9.71810\n",
      "Learning Rate: 0.00390625\n",
      "[176]\ttrain-rmse:7.46974\tvalidation-rmse:9.71811\n",
      "Learning Rate: 0.00390625\n",
      "[177]\ttrain-rmse:7.46968\tvalidation-rmse:9.71809\n",
      "Learning Rate: 0.00390625\n",
      "[178]\ttrain-rmse:7.46963\tvalidation-rmse:9.71813\n",
      "Learning Rate: 0.00390625\n",
      "[179]\ttrain-rmse:7.46956\tvalidation-rmse:9.71800\n",
      "Learning Rate: 0.001953125\n",
      "[180]\ttrain-rmse:7.46952\tvalidation-rmse:9.71800\n",
      "Learning Rate: 0.001953125\n",
      "[181]\ttrain-rmse:7.46950\tvalidation-rmse:9.71803\n",
      "Learning Rate: 0.001953125\n",
      "[182]\ttrain-rmse:7.46948\tvalidation-rmse:9.71805\n",
      "Learning Rate: 0.001953125\n",
      "[183]\ttrain-rmse:7.46945\tvalidation-rmse:9.71808\n",
      "Learning Rate: 0.001953125\n",
      "[184]\ttrain-rmse:7.46942\tvalidation-rmse:9.71811\n",
      "Learning Rate: 0.001953125\n",
      "[185]\ttrain-rmse:7.46939\tvalidation-rmse:9.71807\n",
      "Learning Rate: 0.001953125\n",
      "[186]\ttrain-rmse:7.46936\tvalidation-rmse:9.71810\n",
      "Learning Rate: 0.001953125\n",
      "[187]\ttrain-rmse:7.46933\tvalidation-rmse:9.71806\n",
      "Learning Rate: 0.001953125\n",
      "[188]\ttrain-rmse:7.46930\tvalidation-rmse:9.71802\n",
      "Learning Rate: 0.001953125\n",
      "[189]\ttrain-rmse:7.46927\tvalidation-rmse:9.71805\n",
      "Learning Rate: 0.001953125\n",
      "[190]\ttrain-rmse:7.46924\tvalidation-rmse:9.71803\n",
      "Learning Rate: 0.001953125\n",
      "[191]\ttrain-rmse:7.46921\tvalidation-rmse:9.71803\n",
      "Learning Rate: 0.001953125\n",
      "[192]\ttrain-rmse:7.46919\tvalidation-rmse:9.71808\n",
      "Learning Rate: 0.001953125\n",
      "[193]\ttrain-rmse:7.46916\tvalidation-rmse:9.71807\n",
      "Learning Rate: 0.001953125\n",
      "[194]\ttrain-rmse:7.46914\tvalidation-rmse:9.71800\n",
      "Learning Rate: 0.001953125\n",
      "[195]\ttrain-rmse:7.46912\tvalidation-rmse:9.71808\n",
      "Learning Rate: 0.001953125\n",
      "[196]\ttrain-rmse:7.46909\tvalidation-rmse:9.71810\n",
      "Learning Rate: 0.001953125\n",
      "[197]\ttrain-rmse:7.46906\tvalidation-rmse:9.71806\n",
      "Learning Rate: 0.001953125\n",
      "[198]\ttrain-rmse:7.46903\tvalidation-rmse:9.71810\n",
      "Learning Rate: 0.001953125\n",
      "[199]\ttrain-rmse:7.46901\tvalidation-rmse:9.71814\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "  \"colsample_bynode\": 0.8,\n",
    "  'colsample_bytree': 0.8,\n",
    "  \"learning_rate\": 2.0,\n",
    "  \"max_depth\": 15,\n",
    "  \"objective\": \"reg:squarederror\",\n",
    "  \"subsample\": 0.5,\n",
    "  \"gamma\" : 1.0, \n",
    "  \"lambda\" : 1000.0,\n",
    "  \"tree_method\": \"hist\",\n",
    "  \"device\": \"cuda\",\n",
    "  \"nthread\" : 10,\n",
    "}\n",
    "\n",
    "evals = [(training_set, \"train\"), (validation_set, \"validation\")]\n",
    "\n",
    "n = 200\n",
    "\n",
    "lr_scheduler = xgb.callback.LearningRateScheduler(custom_learning_rate)\n",
    "\n",
    "'''results = xgb.cv(\n",
    "   params = params,\n",
    "   nfold = 5,\n",
    "   dtrain = training_set,\n",
    "   num_boost_round = n,\n",
    "   verbose_eval=1,\n",
    "   seed = random.randint(0, int(1e5)),\n",
    "   early_stopping_rounds=100,\n",
    "   shuffle = True,\n",
    "   metrics = [\"mape\", \"rmse\"],\n",
    "   callbacks=[lr_scheduler])'''\n",
    "\n",
    "model = xgb.train(\n",
    "   params = params,\n",
    "   dtrain = training_set,\n",
    "   num_boost_round = n,\n",
    "   evals = evals,\n",
    "   verbose_eval=1,\n",
    "   callbacks = [lr_scheduler]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "#model.save_model(f\"./../processed_data_chorus_neural_network/TRAINED_MODELS/Weighted_L2/XG_BOOSTED_REGRESSION_MSE_WEIGHTED_LINEAR_WEIGHTING.model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model(f\"./../processed_data_chorus_neural_network/TRAINED_MODELS/Weighted_L2/XG_BOOSTED_REGRESSION_MSE_WEIGHTED_ON_AMPLITUDE_AND_L_AT_AGU.model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross fold validation results:\n",
    "\n",
    "plt.plot(results[\"train-rmse-mean\"], label=\"train-rmse-mean\")\n",
    "plt.plot(results[\"test-rmse-mean\"], label=\"test-rmse-mean\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = xgb.Booster({'nthread': 4})  # init model\n",
    "#model.load_model(f\"./../processed_data_chorus_neural_network/TRAINED_MODELS/XG_BOOSTED_REGRESSION.model\")  # load model data\n",
    "\n",
    "validation_pred = (model.predict(validation_set))\n",
    "training_pred = (model.predict(training_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.604550324403079e-16\n",
      "0.9999999999999999\n"
     ]
    }
   ],
   "source": [
    "print(np.nanmean(TRAINING_FEATURES[:, 0]))\n",
    "print(np.std(TRAINING_FEATURES[:, 0]))\n",
    "\n",
    "\n",
    "plt.scatter(TRAINING_LABELS, training_pred, s = 0.8, c = TRAINING_FEATURES[:, 0])\n",
    "plt.plot(np.logspace(-2, 4), np.logspace(-2, 4), color = \"black\")\n",
    "plt.grid()\n",
    "cbar = plt.colorbar()\n",
    "cbar.ax.set_ylabel('L - Shell\\n', rotation=270, loc=\"center\", labelpad = 1.0)\n",
    "\n",
    "plt.xlim(1e-1, 1e3)\n",
    "plt.ylim(1e-1, 1e3)\n",
    "plt.xlabel(\"RBSP OBSERVED CHORUS\")\n",
    "plt.ylabel(\"MODEL PREDICTED CHORUS\")\n",
    "plt.title(\"TRAINING SET\")\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.min(TRAINING_FEATURES[:, 0]))\n",
    "print(np.max(TRAINING_FEATURES[:, 0]))\n",
    "\n",
    "print(np.nanmean((training_pred.flatten() - TRAINING_LABELS.flatten())**2))\n",
    "\n",
    "plt.scatter(TRAINING_FEATURES[:, 0], np.abs((training_pred.flatten() - TRAINING_LABELS.flatten()) / TRAINING_LABELS.flatten()) * 100, s = 0.8, c = TRAINING_LABELS, norm=matplotlib.colors.LogNorm())\n",
    "plt.colorbar()\n",
    "\n",
    "plt.grid()\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(VALIDATION_LABELS, validation_pred, s = 0.8, c = VALIDATION_FEATURES[:, 0])\n",
    "plt.plot(np.logspace(-2, 4), np.logspace(-2, 4), color = \"black\")\n",
    "plt.grid()\n",
    "plt.colorbar()\n",
    "plt.xlim(1e-1, 1e3)\n",
    "plt.ylim(1e-1, 1e3)\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.get_score(importance_type='gain'))\n",
    "print(model.get_score(importance_type='weight'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, subplot_kw=dict(projection=\"polar\"))\n",
    "\n",
    "ax[0][0].set_xlim(xmin=0, xmax= 2 * np.pi)\n",
    "ax[0][0].set_ylim(ymin=0, ymax=7)\n",
    "\n",
    "ax[0][1].set_xlim(xmin=0, xmax=  2 * np.pi)\n",
    "ax[0][1].set_ylim(ymin=0, ymax=7)\n",
    "\n",
    "ax[1][0].set_xlim(xmin = 0, xmax = 2 * np.pi)\n",
    "ax[1][0].set_ylim(ymin = 0, ymax=7)\n",
    "\n",
    "ax[1][1].set_xlim(xmin=0, xmax= 2 * np.pi)\n",
    "ax[1][1].set_ylim(ymin=0, ymax=7)\n",
    "\n",
    "radius_of_points_training = TRAINING_FEATURES[:, 0] * 1.345 + 4.1 # <---------------------------------------------\n",
    "angles_of_points_training = np.arctan2(TRAINING_FEATURES[:, 1], TRAINING_FEATURES[:, 2])\n",
    "\n",
    "radius_of_points_validation = VALIDATION_FEATURES[:, 0] * 1.345 + 4.1 # <---------------------------------------------------------\n",
    "angles_of_points_validation = np.arctan2(VALIDATION_FEATURES[:, 1], VALIDATION_FEATURES[:, 2])\n",
    "\n",
    "rbins = np.linspace(0, 8, 30)\n",
    "abins = np.linspace(-1 * np.pi, np.pi, 60)\n",
    "\n",
    "A, R = np.meshgrid(abins, rbins)\n",
    "\n",
    "average_chorus_pred_training = np.zeros_like(A)\n",
    "average_chorus_pred_validation = np.zeros_like(A)\n",
    "average_chorus_real_training = np.zeros_like(A)\n",
    "average_chorus_real_validation = np.zeros_like(A)\n",
    "\n",
    "for r in range(len(rbins) - 1):\n",
    "    for a in range(len(abins) - 1):\n",
    "        \n",
    "        average_chorus_pred_training[r, a] += np.nanmean(training_pred[(rbins[r] <= radius_of_points_training) & (radius_of_points_training < rbins[r+1]) & (abins[a] < angles_of_points_training) & (angles_of_points_training < abins[a+1])])\n",
    "        average_chorus_real_training[r, a] += np.nanmean(TRAINING_LABELS[(rbins[r] <= radius_of_points_training) & (radius_of_points_training < rbins[r+1]) & (abins[a] < angles_of_points_training) & (angles_of_points_training < abins[a+1])])\n",
    "        average_chorus_pred_validation[r, a] += np.nanmean(validation_pred[(rbins[r] <= radius_of_points_validation) & (radius_of_points_validation < rbins[r+1]) & (abins[a] < angles_of_points_validation) & (angles_of_points_validation < abins[a+1])])\n",
    "        average_chorus_real_validation[r, a] += np.nanmean(VALIDATION_LABELS[(rbins[r] <= radius_of_points_validation) & (radius_of_points_validation < rbins[r+1]) & (abins[a] < angles_of_points_validation) & (angles_of_points_validation < abins[a+1])])\n",
    "\n",
    "\n",
    "pc = ax[0][0].pcolormesh(A, R, average_chorus_pred_training, norm=matplotlib.colors.LogNorm(vmin = 1, vmax = 100))\n",
    "plt.colorbar(pc)\n",
    "\n",
    "ax[0][0].set_xticklabels(['MLT 0', \"\", 'MLT 6', \"\", 'MLT 12', \"\", 'MLT 18'])\n",
    "ax[0][1].set_xticklabels(['MLT 0', \"\", 'MLT 6', \"\", 'MLT 12', \"\", 'MLT 18'])\n",
    "ax[1][0].set_xticklabels(['MLT 0', \"\", 'MLT 6', \"\", 'MLT 12', \"\", 'MLT 18'])\n",
    "ax[1][1].set_xticklabels(['MLT 0', \"\", 'MLT 6', \"\", 'MLT 12', \"\", 'MLT 18'])\n",
    "\n",
    "\n",
    "pc = ax[0][1].pcolormesh(A, R, average_chorus_pred_validation, norm=matplotlib.colors.LogNorm(vmin = 1, vmax = 100))\n",
    "plt.colorbar(pc)\n",
    "\n",
    "pc = ax[1][0].pcolormesh(A, R, average_chorus_real_training, norm=matplotlib.colors.LogNorm(vmin = 1, vmax = 100))\n",
    "plt.colorbar(pc)\n",
    "\n",
    "pc = ax[1][1].pcolormesh(A, R, average_chorus_real_validation, norm=matplotlib.colors.LogNorm(vmin = 1, vmax = 100))\n",
    "plt.colorbar(pc)\n",
    "\n",
    "ax[0][0].set_title(\"Predicted on Training Set\")\n",
    "ax[0][1].set_title(\"Predicted on Validation Set\")\n",
    "ax[1][0].set_title(\"Labels of Training Set\")\n",
    "ax[1][1].set_title(\"Labels of Validation Set\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ResearchPy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
