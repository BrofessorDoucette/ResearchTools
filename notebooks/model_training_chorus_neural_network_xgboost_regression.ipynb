{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.colors\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: ((865758, 10), (865758,))\n",
      "Validation set shape: ((16887, 10), (16887,))\n"
     ]
    }
   ],
   "source": [
    "VERSION = \"v1b\"\n",
    "FIELD_MODEL = \"T89\"\n",
    "MODEL_TYPE = \"LOWER_BAND\"\n",
    "\n",
    "CONJUNCTIONS_REFS = np.load(\n",
    "    f\"./../chorus_neural_network/STAGE_4/{VERSION}/MODEL_READY_DATA_{VERSION}_{FIELD_MODEL}_{MODEL_TYPE}.npz\"\n",
    ")\n",
    "\n",
    "TRAINING_FEATURES = CONJUNCTIONS_REFS[\"FEATURES\"]\n",
    "TRAINING_LABELS = CONJUNCTIONS_REFS[\"LABELS\"].flatten()\n",
    "MEAN_L = CONJUNCTIONS_REFS[\"\"]\n",
    "\n",
    "TRAINING_MLT = CONJUNCTIONS_REFS[\"TRAINING_MLT\"]\n",
    "\n",
    "VALIDATION_FEATURES = CONJUNCTIONS_REFS[\"VALIDATION_FEATURES\"]\n",
    "VALIDATION_LABELS = CONJUNCTIONS_REFS[\"VALIDATION_LABELS\"].flatten()\n",
    "\n",
    "# BINS = CONJUNCTIONS_REFS[\"BINS\"]\n",
    "\n",
    "CONJUNCTIONS_REFS.close()\n",
    "\n",
    "print(f\"Training set shape: {TRAINING_FEATURES.shape, TRAINING_LABELS.shape}\")\n",
    "print(f\"Validation set shape: {VALIDATION_FEATURES.shape, VALIDATION_LABELS.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find weights\n",
    "\n",
    "MEAN_CHORUS = np.nanmean(TRAINING_LABELS)\n",
    "STD_CHORUS = np.nanstd(TRAINING_LABELS)\n",
    "\n",
    "SAMPLE_WEIGHTS_FROM_CHORUS_DISTRIBUTION = np.abs((TRAINING_LABELS - MEAN_CHORUS) / STD_CHORUS) + 1\n",
    "SAMPLE_WEIGHTS_FROM_CHORUS_DISTRIBUTION[SAMPLE_WEIGHTS_FROM_CHORUS_DISTRIBUTION > 3] = 3\n",
    "\n",
    "order_of_labels = np.argsort(TRAINING_LABELS.flatten())\n",
    "\n",
    "\n",
    "plt.ylabel(\"Weights of dataset\")\n",
    "plt.xlabel(\"Chorus Amplitude (pT)\")\n",
    "plt.plot(\n",
    "    TRAINING_LABELS[order_of_labels],\n",
    "    SAMPLE_WEIGHTS_FROM_CHORUS_DISTRIBUTION[order_of_labels].flatten(),\n",
    "    label=\"SAMPLE_WEIGHTS\",\n",
    ")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = xgb.DMatrix(TRAINING_FEATURES, TRAINING_LABELS)\n",
    "validation_set = xgb.DMatrix(VALIDATION_FEATURES, VALIDATION_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom learning rate schedule\n",
    "def custom_learning_rate(current_iter):\n",
    "    base_learning_rate = 1.0\n",
    "\n",
    "    lr = base_learning_rate * np.power(0.5, np.floor(current_iter / 50))\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:9.80898\tvalidation-rmse:11.35851\n",
      "[100]\ttrain-rmse:5.06888\tvalidation-rmse:11.97424\n",
      "[200]\ttrain-rmse:4.59592\tvalidation-rmse:11.98886\n",
      "[300]\ttrain-rmse:4.49362\tvalidation-rmse:11.99425\n",
      "[400]\ttrain-rmse:4.46865\tvalidation-rmse:11.99486\n",
      "[500]\ttrain-rmse:4.46249\tvalidation-rmse:11.99507\n",
      "[600]\ttrain-rmse:4.46092\tvalidation-rmse:11.99509\n",
      "[700]\ttrain-rmse:4.46055\tvalidation-rmse:11.99510\n",
      "[800]\ttrain-rmse:4.46045\tvalidation-rmse:11.99510\n",
      "[900]\ttrain-rmse:4.46043\tvalidation-rmse:11.99511\n",
      "[999]\ttrain-rmse:4.46042\tvalidation-rmse:11.99511\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"colsample_bynode\": 0.8,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"learning_rate\": 0.5,\n",
    "    \"max_depth\": 15,\n",
    "    \"objective\": \"reg:squarederror\",\n",
    "    \"subsample\": 0.5,\n",
    "    \"gamma\": 0.5,\n",
    "    \"lambda\": 1000.0,\n",
    "    \"tree_method\": \"hist\",\n",
    "    \"device\": \"cuda\",\n",
    "    \"nthread\": 10,\n",
    "}\n",
    "\n",
    "evals = [(training_set, \"train\"), (validation_set, \"validation\")]\n",
    "\n",
    "n = 1000\n",
    "\n",
    "lr_scheduler = xgb.callback.LearningRateScheduler(custom_learning_rate)\n",
    "\n",
    "\"\"\"results = xgb.cv(\n",
    "   params = params,\n",
    "   nfold = 5,\n",
    "   dtrain = training_set,\n",
    "   num_boost_round = n,\n",
    "   verbose_eval=1,\n",
    "   seed = random.randint(0, int(1e5)),\n",
    "   early_stopping_rounds=100,\n",
    "   shuffle = True,\n",
    "   metrics = [\"mape\", \"rmse\"],\n",
    "   callbacks=[lr_scheduler])\"\"\"\n",
    "\n",
    "model = xgb.train(\n",
    "    params=params,\n",
    "    dtrain=training_set,\n",
    "    num_boost_round=n,\n",
    "    evals=evals,\n",
    "    verbose_eval=100,\n",
    "    callbacks=[lr_scheduler],\n",
    ")\n",
    "\n",
    "\n",
    "# model.save_model(f\"./../processed_data_chorus_neural_network/TRAINED_MODELS/Weighted_L2/XG_BOOSTED_REGRESSION_MSE_WEIGHTED_LINEAR_WEIGHTING.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Dev\\Research\\REPT_Enhancements_Tool\\ResearchPy\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [17:36:03] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\c_api\\c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "model.save_model(\n",
    "    f\"./../chorus_neural_network/TRAINED_MODELS/WEIGHTED_CHORUS_WITH_MEDIAN_INSTEAD_OF_MEAN.model\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = xgb.Booster({'nthread': 4})  # init model\n",
    "# model.load_model(f\"./../processed_data_chorus_neural_network/TRAINED_MODELS/XG_BOOSTED_REGRESSION.model\")  # load model data\n",
    "\n",
    "validation_pred = model.predict(validation_set)\n",
    "training_pred = model.predict(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.8305282975604355e-16\n"
     ]
    }
   ],
   "source": [
    "mean_L = np.nanmean(TRAINING_FEATURES[:, 0])\n",
    "std_L = np.std(TRAINING_FEATURES[:, 0])\n",
    "\n",
    "print(mean_L)\n",
    "\n",
    "plt.scatter(TRAINING_LABELS, training_pred, s=0.8, c=(TRAINING_FEATURES[:, 0] * std_L) + mean_L)\n",
    "plt.plot(np.logspace(-2, 4), np.logspace(-2, 4), color=\"black\")\n",
    "plt.colorbar()\n",
    "plt.grid()\n",
    "\n",
    "plt.xlim(1e-1, 1e3)\n",
    "plt.ylim(1e-1, 1e3)\n",
    "plt.xlabel(\"RBSP OBSERVED CHORUS\")\n",
    "plt.ylabel(\"MODEL PREDICTED CHORUS\")\n",
    "plt.title(\"TRAINING SET\")\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.min(TRAINING_FEATURES[:, 0]))\n",
    "print(np.max(TRAINING_FEATURES[:, 0]))\n",
    "\n",
    "print(np.nanmean((training_pred.flatten() - TRAINING_LABELS.flatten()) ** 2))\n",
    "\n",
    "plt.scatter(\n",
    "    TRAINING_FEATURES[:, 0],\n",
    "    np.abs((training_pred.flatten() - TRAINING_LABELS.flatten()) / TRAINING_LABELS.flatten()) * 100,\n",
    "    s=0.8,\n",
    "    c=TRAINING_LABELS,\n",
    "    norm=matplotlib.colors.LogNorm(),\n",
    ")\n",
    "plt.colorbar()\n",
    "\n",
    "plt.grid()\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(VALIDATION_LABELS, validation_pred, s=0.8, c=VALIDATION_FEATURES[:, 0])\n",
    "plt.plot(np.logspace(-2, 4), np.logspace(-2, 4), color=\"black\")\n",
    "plt.grid()\n",
    "plt.colorbar()\n",
    "plt.xlim(1e-1, 1e3)\n",
    "plt.ylim(1e-1, 1e3)\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f0': 139.73208618164062, 'f1': 205.9730682373047, 'f2': 209.689453125, 'f3': 176.5742950439453, 'f4': 194.00253295898438, 'f5': 235.54627990722656, 'f6': 241.77963256835938, 'f7': 208.5730743408203, 'f8': 240.8218994140625, 'f9': 230.89112854003906}\n",
      "{'f0': 101372.0, 'f1': 66591.0, 'f2': 60473.0, 'f3': 61993.0, 'f4': 64411.0, 'f5': 56883.0, 'f6': 55257.0, 'f7': 55568.0, 'f8': 54463.0, 'f9': 45974.0}\n"
     ]
    }
   ],
   "source": [
    "print(model.get_score(importance_type=\"gain\"))\n",
    "print(model.get_score(importance_type=\"weight\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, subplot_kw=dict(projection=\"polar\"))\n",
    "\n",
    "ax[0][0].set_xlim(xmin=0, xmax=2 * np.pi)\n",
    "ax[0][0].set_ylim(ymin=0, ymax=7)\n",
    "\n",
    "ax[0][1].set_xlim(xmin=0, xmax=2 * np.pi)\n",
    "ax[0][1].set_ylim(ymin=0, ymax=7)\n",
    "\n",
    "ax[1][0].set_xlim(xmin=0, xmax=2 * np.pi)\n",
    "ax[1][0].set_ylim(ymin=0, ymax=7)\n",
    "\n",
    "ax[1][1].set_xlim(xmin=0, xmax=2 * np.pi)\n",
    "ax[1][1].set_ylim(ymin=0, ymax=7)\n",
    "\n",
    "radius_of_points_training = (\n",
    "    TRAINING_FEATURES[:, 0] * 1.345 + 4.1\n",
    ")  # <---------------------------------------------\n",
    "angles_of_points_training = np.arctan2(TRAINING_FEATURES[:, 1], TRAINING_FEATURES[:, 2])\n",
    "\n",
    "radius_of_points_validation = (\n",
    "    VALIDATION_FEATURES[:, 0] * 1.345 + 4.1\n",
    ")  # <---------------------------------------------------------\n",
    "angles_of_points_validation = np.arctan2(VALIDATION_FEATURES[:, 1], VALIDATION_FEATURES[:, 2])\n",
    "\n",
    "rbins = np.linspace(0, 8, 30)\n",
    "abins = np.linspace(-1 * np.pi, np.pi, 60)\n",
    "\n",
    "A, R = np.meshgrid(abins, rbins)\n",
    "\n",
    "average_chorus_pred_training = np.zeros_like(A)\n",
    "average_chorus_pred_validation = np.zeros_like(A)\n",
    "average_chorus_real_training = np.zeros_like(A)\n",
    "average_chorus_real_validation = np.zeros_like(A)\n",
    "\n",
    "for r in range(len(rbins) - 1):\n",
    "    for a in range(len(abins) - 1):\n",
    "\n",
    "        average_chorus_pred_training[r, a] += np.nanmean(\n",
    "            training_pred[\n",
    "                (rbins[r] <= radius_of_points_training) & (radius_of_points_training < rbins[r + 1]) & (abins[a] < angles_of_points_training) & (angles_of_points_training < abins[a + 1])\n",
    "            ]\n",
    "        )\n",
    "        average_chorus_real_training[r, a] += np.nanmean(\n",
    "            TRAINING_LABELS[\n",
    "                (rbins[r] <= radius_of_points_training) & (radius_of_points_training < rbins[r + 1]) & (abins[a] < angles_of_points_training) & (angles_of_points_training < abins[a + 1])\n",
    "            ]\n",
    "        )\n",
    "        average_chorus_pred_validation[r, a] += np.nanmean(\n",
    "            validation_pred[\n",
    "                (rbins[r] <= radius_of_points_validation) & (radius_of_points_validation < rbins[r + 1]) & (abins[a] < angles_of_points_validation) & (angles_of_points_validation < abins[a + 1])\n",
    "            ]\n",
    "        )\n",
    "        average_chorus_real_validation[r, a] += np.nanmean(\n",
    "            VALIDATION_LABELS[\n",
    "                (rbins[r] <= radius_of_points_validation) & (radius_of_points_validation < rbins[r + 1]) & (abins[a] < angles_of_points_validation) & (angles_of_points_validation < abins[a + 1])\n",
    "            ]\n",
    "        )\n",
    "\n",
    "\n",
    "pc = ax[0][0].pcolormesh(\n",
    "    A, R, average_chorus_pred_training, norm=matplotlib.colors.LogNorm(vmin=1, vmax=100)\n",
    ")\n",
    "plt.colorbar(pc)\n",
    "\n",
    "ax[0][0].set_xticklabels([\"MLT 0\", \"\", \"MLT 6\", \"\", \"MLT 12\", \"\", \"MLT 18\"])\n",
    "ax[0][1].set_xticklabels([\"MLT 0\", \"\", \"MLT 6\", \"\", \"MLT 12\", \"\", \"MLT 18\"])\n",
    "ax[1][0].set_xticklabels([\"MLT 0\", \"\", \"MLT 6\", \"\", \"MLT 12\", \"\", \"MLT 18\"])\n",
    "ax[1][1].set_xticklabels([\"MLT 0\", \"\", \"MLT 6\", \"\", \"MLT 12\", \"\", \"MLT 18\"])\n",
    "\n",
    "\n",
    "pc = ax[0][1].pcolormesh(\n",
    "    A, R, average_chorus_pred_validation, norm=matplotlib.colors.LogNorm(vmin=1, vmax=100)\n",
    ")\n",
    "plt.colorbar(pc)\n",
    "\n",
    "pc = ax[1][0].pcolormesh(\n",
    "    A, R, average_chorus_real_training, norm=matplotlib.colors.LogNorm(vmin=1, vmax=100)\n",
    ")\n",
    "plt.colorbar(pc)\n",
    "\n",
    "pc = ax[1][1].pcolormesh(\n",
    "    A, R, average_chorus_real_validation, norm=matplotlib.colors.LogNorm(vmin=1, vmax=100)\n",
    ")\n",
    "plt.colorbar(pc)\n",
    "\n",
    "ax[0][0].set_title(\"Predicted on Training Set\")\n",
    "ax[0][1].set_title(\"Predicted on Validation Set\")\n",
    "ax[1][0].set_title(\"Labels of Training Set\")\n",
    "ax[1][1].set_title(\"Labels of Validation Set\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
