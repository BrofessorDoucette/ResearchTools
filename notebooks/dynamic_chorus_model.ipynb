{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3522b78-30e0-44b7-9298-323fa9c642f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/uxlfoundation/scikit-learn-intelex)\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (dynamic_chorus_model.py, line 71)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[36m(most recent call last)\u001b[39m:\n",
      "  File \u001b[92mC:\\Dev\\Research\\Research_Tools\\ResearchPy\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3549\u001b[39m in \u001b[95mrun_code\u001b[39m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  Cell \u001b[92mIn[7]\u001b[39m\u001b[92m, line 27\u001b[39m\n    importlib.reload(dynamic_chorus_model)\n",
      "  File \u001b[92m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\importlib\\__init__.py:131\u001b[39m in \u001b[95mreload\u001b[39m\n    _bootstrap._exec(spec, module)\n",
      "  File \u001b[92m<frozen importlib._bootstrap>:866\u001b[39m in \u001b[95m_exec\u001b[39m\n",
      "  File \u001b[92m<frozen importlib._bootstrap_external>:991\u001b[39m in \u001b[95mexec_module\u001b[39m\n",
      "  File \u001b[92m<frozen importlib._bootstrap_external>:1129\u001b[39m in \u001b[95mget_code\u001b[39m\n",
      "  File \u001b[92m<frozen importlib._bootstrap_external>:1059\u001b[39m in \u001b[95msource_to_code\u001b[39m\n",
      "\u001b[36m  \u001b[39m\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:488\u001b[39m\u001b[36m in \u001b[39m\u001b[35m_call_with_frames_removed\u001b[39m\n",
      "  \u001b[36mFile \u001b[39m\u001b[32mC:\\Dev\\Research\\Research_Tools\\src\\dynamic_chorus_model.py:71\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mfor\u001b[39m\n        ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# caution: path[0] is reserved for script path (or '' in REPL).\n",
    "sys.path.insert(1, os.path.abspath(\"./../src\"))\n",
    "\n",
    "import datetime\n",
    "import importlib\n",
    "\n",
    "import astropy\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "\n",
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()\n",
    "import sklearn\n",
    "\n",
    "import chorus_machine_learning_helper\n",
    "import data_loader\n",
    "import dynamic_chorus_model\n",
    "import plot_tools\n",
    "\n",
    "importlib.reload(data_loader)\n",
    "importlib.reload(dynamic_chorus_model)\n",
    "importlib.reload(chorus_machine_learning_helper)\n",
    "importlib.reload(plot_tools)\n",
    "\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bb1306-d3ec-47b7-9c06-b92d5cff7cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = \"v1\"\n",
    "MODEL_TYPE = \"LOWER_BAND\"\n",
    "\n",
    "pdata_folder = os.path.abspath(\"./../processed_data/chorus_neural_network/\")\n",
    "rbsp_chorus_folder = os.path.join(pdata_folder, \"observed_chorus\")\n",
    "output_folder = os.path.join(pdata_folder, \"models\", VERSION)\n",
    "\n",
    "T_SIZE = 31860 / 2\n",
    "SAMPLING_SIZE = 100000\n",
    "\n",
    "year = 2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fed1266b-edce-40b0-9357-6ef5b40a3e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "POES_temp = data_loader.load_raw_data_from_config(\n",
    "    id=[\"POES\", \"SEM\", \"MPE\"],\n",
    "    start=datetime.datetime(year=2000, month=1, day=1),\n",
    "    end=datetime.datetime(year=2000, month=1, day=2),\n",
    "    satellite=\"n15\",\n",
    ")\n",
    "\n",
    "ENERGIES = POES_temp[\"energy\"][0]\n",
    "DIFF_E = ENERGIES[1:] - ENERGIES[:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b714ceae-29af-47e9-b3c9-a60577b19b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Began loading RBSP Data for year: 2012\n",
      "\n",
      "RBSP-A SHAPES BEFORE PREPROCESSING:\n",
      "(3220864,)\n",
      "(3220864,)\n",
      "(3220864,)\n",
      "(3220864,)\n",
      "(3220864,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Dev\\Research\\Research_Tools\\ResearchPy\\Lib\\site-packages\\erfa\\core.py:133: ErfaWarning: ERFA function \"dtf2d\" yielded 1 of \"dubious year (Note 6)\"\n",
      "  warn(f'ERFA function \"{func_name}\" yielded {wmsg}', ErfaWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RBSP-A SHAPES AFTER REMOVING POINTS OUTSIDE BINS and INSIDE PLASMASPHERE:\n",
      "(3090772,)\n",
      "(3090772,)\n",
      "(3090772,)\n",
      "(3090772,)\n",
      "(3090772,)\n",
      "Began loading RBSP Data for year: 2012\n",
      "\n",
      "RBSP-B SHAPES BEFORE PREPROCESSING:\n",
      "(3179153,)\n",
      "(3179153,)\n",
      "(3179153,)\n",
      "(3179153,)\n",
      "(3179153,)\n",
      "\n",
      "RBSP-B SHAPES AFTER REMOVING POINTS OUTSIDE BINS and INSIDE PLASMASPHERE:\n",
      "(3052023,)\n",
      "(3052023,)\n",
      "(3052023,)\n",
      "(3052023,)\n",
      "(3052023,)\n",
      "RBSP Data loaded for year : 2012\n",
      "Began loading POES Data for year : 2012\n",
      "Finished loading POES data for year : 2012\n",
      "Finished loading POES data for year : 2012\n",
      "Began loading SUPERMAG data for year : 2012\n",
      "Finished loading SUPERMAG data for year : 2012\n",
      "Loading HP data for year : 2012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Dev\\Research\\Research_Tools\\src\\chorus_machine_learning_helper.py:222: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  hp = pd.read_csv(os.path.abspath(path), delim_whitespace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Loading HP data for year : 2012\n",
      "CPU times: total: 46.8 s\n",
      "Wall time: 1min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "RBSP = []\n",
    "\n",
    "for SATID in [\"A\", \"B\"]:\n",
    "\n",
    "    # LOAD THE OBSERVED CHORUS\n",
    "    print(f\"Began loading RBSP Data for year: {year}\")\n",
    "    refs = np.load(\n",
    "        file=os.path.join(rbsp_chorus_folder, rf\"observed_chorus_{year}_{SATID}_{MODEL_TYPE}.npz\"),\n",
    "        allow_pickle=True,\n",
    "    )\n",
    "    PROBE = {}\n",
    "    PROBE[\"UNIX_TIME\"] = refs[\"UNIX_TIME\"]\n",
    "    PROBE[\"MLT\"] = refs[\"MLT\"]\n",
    "    PROBE[\"MLAT\"] = refs[\"MLAT\"]\n",
    "    PROBE[\"L\"] = refs[\"L\"]\n",
    "    PROBE[\"CHORUS\"] = refs[\"CHORUS\"]\n",
    "\n",
    "    refs.close()\n",
    "\n",
    "    print(f\"\\nRBSP-{SATID} SHAPES BEFORE PREPROCESSING:\")\n",
    "    print(PROBE[\"UNIX_TIME\"].shape)\n",
    "    print(PROBE[\"MLT\"].shape)\n",
    "    print(PROBE[\"L\"].shape)\n",
    "    print(PROBE[\"MLAT\"].shape)\n",
    "    print(PROBE[\"CHORUS\"].shape)\n",
    "\n",
    "    order = np.argsort(PROBE[\"UNIX_TIME\"])\n",
    "    PROBE[\"UNIX_TIME\"] = PROBE[\"UNIX_TIME\"][order]\n",
    "    PROBE[\"MLT\"] = PROBE[\"MLT\"][order]\n",
    "    PROBE[\"L\"] = PROBE[\"L\"][order]\n",
    "    PROBE[\"MLAT\"] = PROBE[\"MLAT\"][order]\n",
    "    PROBE[\"CHORUS\"] = PROBE[\"CHORUS\"][order]\n",
    "\n",
    "    #t_Lpp, Lpp = chorus_machine_learning_helper.load_plasmapause_filter(year=year)\n",
    "    #Lpp_i = np.interp(x=PROBE[\"UNIX_TIME\"], xp=t_Lpp, fp=Lpp, left=None, right=None)\n",
    "    #inside_plasmasphere = PROBE[\"L\"] < Lpp_i\n",
    "    #PROBE[\"CHORUS\"][inside_plasmasphere] = 0\n",
    "\n",
    "    print(f\"\\nRBSP-{SATID} SHAPES AFTER REMOVING POINTS OUTSIDE BINS and INSIDE PLASMASPHERE:\")\n",
    "    print(PROBE[\"UNIX_TIME\"].shape)\n",
    "    print(PROBE[\"MLT\"].shape)\n",
    "    print(PROBE[\"L\"].shape)\n",
    "    print(PROBE[\"MLAT\"].shape)\n",
    "    print(PROBE[\"CHORUS\"].shape)\n",
    "\n",
    "    RBSP.append(PROBE)\n",
    "\n",
    "print(f\"RBSP Data loaded for year : {year}\")\n",
    "print(f\"Began loading POES Data for year : {year}\")\n",
    "\n",
    "POES = chorus_machine_learning_helper.load_MPE_year(year=year)\n",
    "\n",
    "print(f\"Finished loading POES data for year : {year}\")\n",
    "\n",
    "SUPERMAG = chorus_machine_learning_helper.load_SUPERMAG_SME_year(year)\n",
    "\n",
    "print(f\"Loading HP data for year : {year}\")\n",
    "\n",
    "HP_UNIX_TIME, HP = chorus_machine_learning_helper.load_hp30(os.path.join(pdata_folder, \"Hp30_Ap30_1996_2025.txt\"))\n",
    "\n",
    "tstart = datetime.datetime(year=year, month=1, day=1, tzinfo=datetime.UTC).timestamp()\n",
    "tend = datetime.datetime(year=year + 1, month=1, day=1, tzinfo=datetime.UTC).timestamp()\n",
    "\n",
    "order = np.argsort(HP_UNIX_TIME)\n",
    "HP_UNIX_TIME = HP_UNIX_TIME[order]\n",
    "HP = HP[order]\n",
    "\n",
    "time_mask_hp = np.searchsorted(a=HP_UNIX_TIME, v=[tstart, tend])\n",
    "HP_UNIX_TIME = HP_UNIX_TIME[time_mask_hp[0]:time_mask_hp[-1]]\n",
    "HP = HP[time_mask_hp[0]:time_mask_hp[-1]]\n",
    "\n",
    "print(f\"Finished Loading HP data for year : {year}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5954f1ea-6f3c-4a15-812b-fbf4b7a735e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of conjunctions: 1\n",
      "2012-08-30 14:43:30\n",
      "Total number of conjunctions: 11\n",
      "2012-09-01 10:58:30\n",
      "Total number of conjunctions: 21\n",
      "2012-09-03 07:13:30\n",
      "Total number of conjunctions: 31\n",
      "2012-09-05 03:28:30\n",
      "Total number of conjunctions: 41\n",
      "2012-09-06 23:43:30\n",
      "Total number of conjunctions: 51\n",
      "2012-09-08 19:58:30\n",
      "Total number of conjunctions: 61\n",
      "2012-09-10 20:39:00\n",
      "Total number of conjunctions: 71\n",
      "2012-09-12 16:54:00\n",
      "Total number of conjunctions: 81\n",
      "2012-09-14 13:09:00\n",
      "Total number of conjunctions: 91\n",
      "2012-09-16 09:24:00\n",
      "Total number of conjunctions: 101\n",
      "2012-09-18 05:39:00\n",
      "Total number of conjunctions: 111\n",
      "2012-09-20 01:54:00\n",
      "Total number of conjunctions: 121\n",
      "2012-09-21 22:09:00\n",
      "Total number of conjunctions: 131\n",
      "2012-09-23 18:24:00\n",
      "Total number of conjunctions: 141\n",
      "2012-09-25 14:39:00\n",
      "Total number of conjunctions: 151\n",
      "2012-09-27 10:54:00\n",
      "Total number of conjunctions: 161\n",
      "2012-09-29 07:09:00\n",
      "Total number of conjunctions: 171\n",
      "2012-10-01 03:24:00\n",
      "Total number of conjunctions: 181\n",
      "2012-10-02 23:39:00\n",
      "Total number of conjunctions: 191\n",
      "2012-10-04 19:54:00\n",
      "Total number of conjunctions: 201\n",
      "2012-10-06 16:09:00\n",
      "Total number of conjunctions: 211\n",
      "2012-10-08 12:24:00\n",
      "Total number of conjunctions: 221\n",
      "2012-10-10 08:39:00\n",
      "Total number of conjunctions: 231\n",
      "2012-10-12 04:54:00\n",
      "Total number of conjunctions: 241\n",
      "2012-10-14 01:09:00\n",
      "Total number of conjunctions: 251\n",
      "2012-10-15 21:24:00\n",
      "Total number of conjunctions: 261\n",
      "2012-10-17 17:39:00\n",
      "Total number of conjunctions: 271\n",
      "2012-10-19 13:54:00\n",
      "Total number of conjunctions: 281\n",
      "2012-10-21 10:09:00\n",
      "Total number of conjunctions: 291\n",
      "2012-10-23 06:24:00\n",
      "Total number of conjunctions: 301\n",
      "2012-10-25 02:39:00\n",
      "Total number of conjunctions: 311\n",
      "2012-10-26 22:54:00\n",
      "Total number of conjunctions: 321\n",
      "2012-10-28 19:09:00\n",
      "Total number of conjunctions: 331\n",
      "2012-10-30 15:24:00\n",
      "Total number of conjunctions: 341\n",
      "2012-11-01 11:39:00\n",
      "Total number of conjunctions: 351\n",
      "2012-11-03 07:54:00\n",
      "Total number of conjunctions: 361\n",
      "2012-11-05 03:09:00\n",
      "Total number of conjunctions: 371\n",
      "2012-11-06 23:24:00\n",
      "Total number of conjunctions: 381\n",
      "2012-11-08 19:39:00\n",
      "Total number of conjunctions: 391\n",
      "2012-11-10 15:54:00\n",
      "Total number of conjunctions: 401\n",
      "2012-11-12 12:09:00\n",
      "Total number of conjunctions: 411\n",
      "2012-11-14 08:24:00\n",
      "Total number of conjunctions: 421\n",
      "2012-11-16 04:39:00\n",
      "Total number of conjunctions: 431\n",
      "2012-11-18 00:54:00\n",
      "Total number of conjunctions: 441\n",
      "2012-11-19 21:09:00\n",
      "Total number of conjunctions: 451\n",
      "2012-11-21 17:24:00\n",
      "Total number of conjunctions: 461\n",
      "2012-11-23 13:39:00\n",
      "Total number of conjunctions: 471\n",
      "2012-11-25 09:54:00\n",
      "Total number of conjunctions: 481\n",
      "2012-11-27 06:09:00\n",
      "Total number of conjunctions: 491\n",
      "2012-11-29 02:24:00\n",
      "Total number of conjunctions: 501\n",
      "2012-11-30 22:39:00\n",
      "Total number of conjunctions: 511\n",
      "2012-12-02 18:54:00\n",
      "Total number of conjunctions: 521\n",
      "2012-12-04 15:09:00\n",
      "Total number of conjunctions: 531\n",
      "2012-12-06 11:24:00\n",
      "Total number of conjunctions: 541\n",
      "2012-12-08 07:39:00\n",
      "Total number of conjunctions: 551\n",
      "2012-12-10 03:54:00\n",
      "Total number of conjunctions: 561\n",
      "2012-12-12 00:09:00\n",
      "Total number of conjunctions: 571\n",
      "2012-12-13 20:24:00\n",
      "Total number of conjunctions: 581\n",
      "2012-12-15 16:39:00\n",
      "Total number of conjunctions: 591\n",
      "2012-12-17 12:54:00\n",
      "Total number of conjunctions: 601\n",
      "2012-12-19 09:09:00\n",
      "Total number of conjunctions: 611\n",
      "2012-12-21 05:24:00\n",
      "Total number of conjunctions: 621\n",
      "2012-12-23 01:39:00\n",
      "Total number of conjunctions: 631\n",
      "2012-12-24 21:54:00\n",
      "Total number of conjunctions: 641\n",
      "2012-12-26 18:09:00\n",
      "Total number of conjunctions: 651\n",
      "2012-12-28 14:24:00\n",
      "Total number of conjunctions: 661\n",
      "2012-12-30 10:39:00\n",
      "CPU times: total: 11min 16s\n",
      "Wall time: 11min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "X_conditional_total = []\n",
    "X_convolutional_total = []\n",
    "y_total = []\n",
    "\n",
    "i = 0\n",
    "\n",
    "for tcurr in np.arange(tstart, tend, T_SIZE):\n",
    "\n",
    "    POES_L = []\n",
    "    POES_MLT = []\n",
    "    POES_FLUX = []\n",
    "\n",
    "    for SAT in POES:\n",
    "        TIME_RANGE = np.searchsorted(SAT[\"UNIX_TIME\"], v=[tcurr, tcurr + T_SIZE])\n",
    "        POES_L.append(SAT[\"L\"][TIME_RANGE[0] : TIME_RANGE[-1]])\n",
    "        POES_MLT.append(SAT[\"MLT\"][TIME_RANGE[0] : TIME_RANGE[-1]])\n",
    "        POES_FLUX.append(SAT[\"BLC_Flux\"][TIME_RANGE[0] : TIME_RANGE[-1], :])\n",
    "\n",
    "    POES_L = np.hstack(POES_L)\n",
    "    POES_MLT = np.hstack(POES_MLT)\n",
    "    POES_FLUX = np.vstack(POES_FLUX)\n",
    "\n",
    "    if POES_L.shape[0] == 0:\n",
    "        continue\n",
    "\n",
    "    RBSP_L = []\n",
    "    RBSP_MLT = []\n",
    "    RBSP_CHORUS = []\n",
    "    RBSP_MLAT = []\n",
    "\n",
    "    for PROBE in RBSP:\n",
    "\n",
    "        TIME_RANGE = np.searchsorted(\n",
    "            a=PROBE[\"UNIX_TIME\"],\n",
    "            v=[tcurr, tcurr + T_SIZE],\n",
    "        )\n",
    "\n",
    "        RBSP_L.append(PROBE[\"L\"][TIME_RANGE[0] : TIME_RANGE[1]])\n",
    "        RBSP_MLT.append(PROBE[\"MLT\"][TIME_RANGE[0] : TIME_RANGE[1]])\n",
    "        RBSP_CHORUS.append(PROBE[\"CHORUS\"][TIME_RANGE[0] : TIME_RANGE[1]])\n",
    "        RBSP_MLAT.append(PROBE[\"MLAT\"][TIME_RANGE[0] : TIME_RANGE[1]])\n",
    "\n",
    "    RBSP_L = np.hstack(RBSP_L)\n",
    "    RBSP_MLT = np.hstack(RBSP_MLT)\n",
    "    RBSP_CHORUS = np.hstack(RBSP_CHORUS)\n",
    "    RBSP_MLAT = np.hstack(RBSP_MLAT)\n",
    "\n",
    "    if RBSP_L.shape[0] == 0:\n",
    "        continue\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "    POES_theta = (POES_MLT / 24) * (2 * np.pi)\n",
    "\n",
    "    UNDER_130_KeV_FLUX = np.nansum((POES_FLUX[:, :7] * DIFF_E[:7]), axis=1)\n",
    "    TOTAL_FLUX = np.nansum((POES_FLUX[:, :-1] * DIFF_E), axis=1)\n",
    "    FLUX_RATIO = UNDER_130_KeV_FLUX / TOTAL_FLUX\n",
    "\n",
    "    # Query points\n",
    "    r_query = np.abs(np.random.normal(loc=0, scale=5, size=SAMPLING_SIZE))\n",
    "    theta_query = np.abs(np.mod(np.random.normal(loc=0, scale=np.pi, size=SAMPLING_SIZE), 2*np.pi))\n",
    "\n",
    "    ratio_interp = (\n",
    "        dynamic_chorus_model.interpolate_around_points(\n",
    "            POES_L,\n",
    "            POES_theta,\n",
    "            FLUX_RATIO,\n",
    "            r_query,\n",
    "            theta_query,\n",
    "            k=5\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "    RBSP_theta = (RBSP_MLT / 24) * (2 * np.pi)\n",
    "\n",
    "    chorus_interp = (\n",
    "        dynamic_chorus_model.interpolate_around_points(\n",
    "            RBSP_L,\n",
    "            RBSP_theta,\n",
    "            RBSP_CHORUS,\n",
    "            r_query,\n",
    "            theta_query,\n",
    "            k=5\n",
    "        )\n",
    "    )\n",
    "\n",
    "    mlat_interp = (\n",
    "        dynamic_chorus_model.interpolate_around_points(\n",
    "            RBSP_L,\n",
    "            RBSP_theta,\n",
    "            RBSP_MLAT,\n",
    "            r_query,\n",
    "            theta_query,\n",
    "            k=5\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "    labeled = np.isfinite(chorus_interp) & np.isfinite(ratio_interp)\n",
    "\n",
    "    if not np.any(labeled):\n",
    "        continue\n",
    "\n",
    "    L_sampled = r_query[labeled]\n",
    "    MLT_sampled = (theta_query[labeled] * 24) / (2 * np.pi)\n",
    "    MLAT_sampled = mlat_interp[labeled]\n",
    "    flux_sampled = ratio_interp[labeled]\n",
    "    chorus_sampled = chorus_interp[labeled]\n",
    "\n",
    "    time_mask_hp_2 = np.searchsorted(a=HP_UNIX_TIME, v=[tcurr, tcurr + T_SIZE])\n",
    "    max_hp = np.nanmax(HP[time_mask_hp_2[0] : time_mask_hp_2[-1]])\n",
    "    hp_sampled = np.array([max_hp for l in range(len(L_sampled))])\n",
    "\n",
    "    t_data = np.array([tcurr for l in range(len(L_sampled))])\n",
    "\n",
    "    X_conditional = np.hstack([np.expand_dims(L_sampled, axis=1),\n",
    "                               np.expand_dims(MLT_sampled, axis=1),\n",
    "                               np.expand_dims(MLAT_sampled, axis=1),\n",
    "                               np.expand_dims(flux_sampled, axis=1),\n",
    "                               np.expand_dims(hp_sampled, axis=1),\n",
    "                               np.expand_dims(t_data, axis=1)])\n",
    "\n",
    "    y = chorus_sampled\n",
    "\n",
    "    time_mask_sme = np.searchsorted(a=SUPERMAG[\"UNIX_TIME\"], v=[tcurr - T_SIZE])\n",
    "    X_convolutional = SUPERMAG[\"SME\"][time_mask_sme[0]:time_mask_sme[0] + 512]\n",
    "\n",
    "    if len(X_convolutional) < 512:\n",
    "        continue\n",
    "\n",
    "    X_convolutional = np.vstack([np.expand_dims(X_convolutional, axis=0) for i in range(len(L_sampled))])\n",
    "\n",
    "    X_conditional_total.append(X_conditional)\n",
    "    X_convolutional_total.append(X_convolutional)\n",
    "    y_total.append(y)\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        print(f\"Total number of conjunctions: {len(y_total)}\")\n",
    "        print(datetime.datetime.fromtimestamp(tcurr))\n",
    "\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d81b97f9-0e65-4a1b-ae54-031d46439d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(530081, 6)\n",
      "(530081, 512)\n",
      "(530081,)\n"
     ]
    }
   ],
   "source": [
    "X_conditional_total = np.vstack(X_conditional_total)\n",
    "X_convolutional_total = np.vstack(X_convolutional_total)\n",
    "y_total = np.hstack(y_total)\n",
    "\n",
    "print(X_conditional_total.shape)\n",
    "print(X_convolutional_total.shape)\n",
    "print(y_total.shape)\n",
    "\n",
    "np.savez(\n",
    "    file=os.path.join(output_folder, rf\"raw_dataset_{VERSION}_{MODEL_TYPE}_{year}.npz\"),\n",
    "    X_conditional_total=X_conditional_total,\n",
    "    X_convolutional_total=X_convolutional_total,\n",
    "    y_total=y_total\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9f7af12-7c71-4285-8fc0-885f1ae49548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Solar Proton Event List\n",
      "Finished Reading Solar Proton Event List\n",
      "\n",
      "Before removing non-valid values\n",
      "Conditional Shape: (530081, 6)\n",
      "Convolutional Shape: (530081, 512)\n",
      "Labels Shape: (530081,)\n",
      "\n",
      "After removing non-valid values\n",
      "Conditional Shape: (530081, 6)\n",
      "Convolutional Shape: (530081, 512)\n",
      "Labels Shape: (530081,)\n",
      "Removing high energy solar proton events!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 309/309 [02:11<00:00,  2.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished removing high energy solar proton events!\n",
      "\n",
      "After removing solar proton events\n",
      "Conditional Shape: (523929, 6)\n",
      "Convolutional Shape: (523929, 512)\n",
      "Labels Shape: (523929,)\n",
      "Saving!\n"
     ]
    }
   ],
   "source": [
    "dataset = np.load(\n",
    "    file=os.path.join(output_folder, rf\"raw_dataset_{VERSION}_{MODEL_TYPE}_{year}.npz\")\n",
    ")\n",
    "\n",
    "print(\"Reading Solar Proton Event List\")\n",
    "\n",
    "SOLAR_PROTON_EVENT_LIST = pd.read_csv(\n",
    "    os.path.join(pdata_folder, r\"SOLAR_PROTON_EVENT_LIST_1976_2024.csv\")\n",
    ")\n",
    "\n",
    "print(\"Finished Reading Solar Proton Event List\")\n",
    "\n",
    "print(\"\\nBefore removing non-valid values\")\n",
    "print(f\"Conditional Shape: {X_conditional_total.shape}\")\n",
    "print(f\"Convolutional Shape: {X_convolutional_total.shape}\")\n",
    "print(f\"Labels Shape: {y_total.shape}\")\n",
    "\n",
    "order_to_sort_conjunctions = np.argsort(\n",
    "    X_conditional_total[:, -1]\n",
    ")  # Sorted based on POES Conjunction time!\n",
    "X_conditional_total = X_conditional_total[order_to_sort_conjunctions, :]\n",
    "X_convolutional_total = X_convolutional_total[order_to_sort_conjunctions, :]\n",
    "y_total = y_total[order_to_sort_conjunctions]\n",
    "\n",
    "all_valid_conditional = np.all(np.isfinite(X_conditional_total), axis=1)\n",
    "all_valid_convolutional = np.all(np.isfinite(X_convolutional_total), axis=1)\n",
    "valid_y = np.isfinite(y_total) & (y_total >= 0)\n",
    "\n",
    "all_valid = all_valid_conditional & all_valid_convolutional & valid_y\n",
    "\n",
    "X_conditional_total = X_conditional_total[all_valid, :]\n",
    "X_convolutional_total = X_convolutional_total[all_valid, :]\n",
    "y_total = y_total[all_valid]\n",
    "\n",
    "print(\"\\nAfter removing non-valid values\")\n",
    "print(f\"Conditional Shape: {X_conditional_total.shape}\")\n",
    "print(f\"Convolutional Shape: {X_convolutional_total.shape}\")\n",
    "print(f\"Labels Shape: {y_total.shape}\")\n",
    "\n",
    "times_sorted = X_conditional_total[:, -1]\n",
    "\n",
    "start_of_sep_events_utc = SOLAR_PROTON_EVENT_LIST[\"START\"]\n",
    "end_of_sep_events_utc = SOLAR_PROTON_EVENT_LIST[\"END\"]\n",
    "zipped_events = list(zip(start_of_sep_events_utc, end_of_sep_events_utc))\n",
    "\n",
    "print(\"Removing high energy solar proton events!\")\n",
    "\n",
    "for SEP in tqdm.tqdm(range(len(zipped_events))):\n",
    "\n",
    "    S = zipped_events[SEP][0].strip()\n",
    "    E = zipped_events[SEP][1].strip()\n",
    "\n",
    "    S_YMDHMS = {\n",
    "        \"year\": int(S[0:4]),\n",
    "        \"month\": int(S[5:7]),\n",
    "        \"day\": int(S[8:10]),\n",
    "        \"hour\": int(S[11:13]),\n",
    "        \"minute\": int(S[13:15]),\n",
    "        \"second\": 0,\n",
    "    }\n",
    "    E_YMDHMS = {\n",
    "        \"year\": int(E[0:4]),\n",
    "        \"month\": int(E[5:7]),\n",
    "        \"day\": int(E[8:10]),\n",
    "        \"hour\": int(E[11:13]),\n",
    "        \"minute\": int(E[13:15]),\n",
    "        \"second\": 0,\n",
    "    }\n",
    "\n",
    "    S_UNIX = astropy.time.Time(S_YMDHMS, format=\"ymdhms\", scale=\"utc\").unix\n",
    "    E_UNIX = astropy.time.Time(E_YMDHMS, format=\"ymdhms\", scale=\"utc\").unix\n",
    "\n",
    "    RANGE_TO_REMOVE = np.searchsorted(a=times_sorted, v=[S_UNIX - T_SIZE, E_UNIX + T_SIZE])\n",
    "\n",
    "    X_conditional_total = np.vstack(\n",
    "        (\n",
    "            X_conditional_total[0 : RANGE_TO_REMOVE[0], :],\n",
    "            X_conditional_total[RANGE_TO_REMOVE[1] :, :],\n",
    "        )\n",
    "    )\n",
    "\n",
    "    X_convolutional_total = np.vstack(\n",
    "        (\n",
    "            X_convolutional_total[0 : RANGE_TO_REMOVE[0], :],\n",
    "            X_convolutional_total[RANGE_TO_REMOVE[1] :, :],\n",
    "        )\n",
    "    )\n",
    "\n",
    "    y_total = np.hstack(\n",
    "        (\n",
    "            y_total[0 : RANGE_TO_REMOVE[0]],\n",
    "            y_total[RANGE_TO_REMOVE[1] :],\n",
    "        )\n",
    "    )\n",
    "\n",
    "print(\"Finished removing high energy solar proton events!\")\n",
    "\n",
    "print(\"\\nAfter removing solar proton events\")\n",
    "print(f\"Conditional Shape: {X_conditional_total.shape}\")\n",
    "print(f\"Convolutional Shape: {X_convolutional_total.shape}\")\n",
    "print(f\"Labels Shape: {y_total.shape}\")\n",
    "\n",
    "print(\"Saving!\")\n",
    "\n",
    "dataset.close()\n",
    "\n",
    "\n",
    "np.savez(\n",
    "    file=os.path.join(output_folder, rf\"spe_cleaned_dataset_{VERSION}_{MODEL_TYPE}_{year}.npz\"),\n",
    "    X_conditional_total=X_conditional_total,\n",
    "    X_convolutional_total=X_convolutional_total,\n",
    "    y_total=y_total\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11542508-0d4d-46e0-99a5-fd6b9c478dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Min chorus power: {np.min(y_total)}\")\n",
    "print(f\"Max chorus power: {np.max(y_total)}\")\n",
    "\n",
    "print(f\"Min chorus power: {np.min(np.sqrt(y_total))}\")\n",
    "print(f\"Max chorus power: {np.max(np.sqrt(y_total))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82ad370a-d0f0-49a1-b2e2-0377bdc1c73c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9852471, 6)\n",
      "(9852471, 512)\n",
      "(9852471,)\n",
      "(9852471, 7)\n",
      "(9852471, 512)\n",
      "(9852471,)\n"
     ]
    }
   ],
   "source": [
    "X_conditional = []\n",
    "X_convolutional = []\n",
    "y = []\n",
    "\n",
    "\n",
    "for year in range(2012, 2020):\n",
    "\n",
    "    d = np.load(\n",
    "        file=os.path.join(output_folder, rf\"spe_cleaned_dataset_{VERSION}_{MODEL_TYPE}_{year}.npz\")\n",
    "    )\n",
    "\n",
    "    X_conditional.append(d[\"X_conditional_total\"])\n",
    "    X_convolutional.append(d[\"X_convolutional_total\"])\n",
    "    y.append(d[\"y_total\"])\n",
    "    d.close()\n",
    "\n",
    "X_conditional = np.vstack(X_conditional)\n",
    "X_convolutional = np.vstack(X_convolutional)\n",
    "y = np.hstack(y)\n",
    "\n",
    "print(X_conditional.shape)\n",
    "print(X_convolutional.shape)\n",
    "print(y.shape)\n",
    "\n",
    "transformed_mlt = np.hstack([np.cos((X_conditional[:, 1:2] / 24) * (2 * np.pi)) , np.sin((X_conditional[:, 1:2] / 24) * (2 * np.pi))])\n",
    "\n",
    "X_conditional = np.hstack([X_conditional[:, 0:1], transformed_mlt, X_conditional[:, 2:]])\n",
    "\n",
    "print(X_conditional.shape)\n",
    "print(X_convolutional.shape)\n",
    "print(y.shape)\n",
    "\n",
    "np.savez(\n",
    "    file=os.path.join(output_folder, rf\"total_dataset_{VERSION}_{MODEL_TYPE}.npz\"),\n",
    "    X_conditional=X_conditional,\n",
    "    X_convolutional=X_convolutional,\n",
    "    y=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "e424f699-67f4-44db-8944-2fb30a58d120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min chorus power: 0.0\n",
      "Max chorus power: 683759.2197013681\n",
      "Min chorus power: 0.0\n",
      "Max chorus power: 826.897345322482\n"
     ]
    }
   ],
   "source": [
    "print(f\"Min chorus power: {np.min(y)}\")\n",
    "print(f\"Max chorus power: {np.max(y)}\")\n",
    "\n",
    "print(f\"Min chorus amplitude: {np.min(np.sqrt(y))}\")\n",
    "print(f\"Max chorus amplitude: {np.max(np.sqrt(y))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "53f91e1d-2d49-4acc-aefa-9e7d0e5dee63",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tools.plot_2d_heatmap(X_conditional[:, 1],\n",
    "                           X_conditional[:, 0],\n",
    "                           np.sqrt(y),\n",
    "                           bins=20,\n",
    "                           xlim=(0.0, 24.0),\n",
    "                           ylim=(2, 7),\n",
    "                           xtitle=\"MLT\",\n",
    "                           ytitle=\"L\",\n",
    "                           ztitle=\"Average Chorus Amplitude (pT)\",\n",
    "                           title=\"Average Chorus Amplitude vs L vs MLT\",\n",
    "                           norm=\"symlog\",\n",
    "                           plot_density = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c47c5e-458f-4cf2-bf79-43a5f5f92e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tools.plot_2d_heatmap(X_conditional[:, -3],\n",
    "                           X_conditional[:, -2],\n",
    "                           y,\n",
    "                           bins=20,\n",
    "                           xlim=(0.0, 1.0),\n",
    "                           ylim=(0, 8),\n",
    "                           xtitle=\"Ratio of flux from (30 KeV to 130 KeV) / Total\",\n",
    "                           ytitle=\"Max Kp in past 4 hours\",\n",
    "                           ztitle=\"Average Chorus Power (pT^2)\",\n",
    "                           title=\"Average Chorus Power vs Kp vs Flux Ratio\",\n",
    "                           norm=\"symlog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b904bb-0069-4716-8bca-594f051acbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tools.plot_2d_heatmap(X_conditional[:, -3],\n",
    "                           X_conditional[:, 0],\n",
    "                           y,\n",
    "                           bins=50,\n",
    "                           xlim=(0.0, 1.0),\n",
    "                           ylim=(2, 7),\n",
    "                           xtitle=\"Ratio of flux from (30 KeV to 130 KeV) / Total\",\n",
    "                           ytitle=\"L-Shell\",\n",
    "                           ztitle=\"Average Chorus Power (pT^2)\",\n",
    "                           title=\"Average Chorus Power vs L vs Flux Ratio\",\n",
    "                           norm=\"symlog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140bdad7-dbda-41b6-9022-9246f60d8aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\n",
    "    file=os.path.join(output_folder, rf\"model_ready_dataset_{VERSION}_{MODEL_TYPE}_{year}.npz\"),\n",
    "    X_conditional=X_conditional,\n",
    "    X_convolutional=X_convolutional,\n",
    "    y=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf72d77c-dd68-4a8a-8295-e7b420379d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tools.plot_2d_heatmap(X_conditional[:, -2],\n",
    "                           X_conditional[:, 0],\n",
    "                           y,\n",
    "                           bins=20,\n",
    "                           xlim=(0.0, 8.0),\n",
    "                           ylim=(2, 7),\n",
    "                           xtitle=\"Hp30 (max in 4h)\",\n",
    "                           ytitle=\"L-Shell\",\n",
    "                           ztitle=\"Average Chorus Power (pT^2)\",\n",
    "                           title=\"Average Chorus Power vs L vs Hp\",\n",
    "                           norm=\"symlog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfba9f9c-cfb0-4ee4-839a-4b05de3125d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tools.plot_2d_heatmap(X_conditional[:, -2],\n",
    "                           X_conditional[:, 0],\n",
    "                           np.sqrt(y),\n",
    "                           bins=20,\n",
    "                           xlim=(0.0, 8.0),\n",
    "                           ylim=(2, 7),\n",
    "                           xtitle=\"Hp30 (max in 4h)\",\n",
    "                           ytitle=\"L-Shell\",\n",
    "                           ztitle=\"Average Chorus Amplitude (pT)\",\n",
    "                           title=\"Average Chorus Amplitude vs L vs Hp\",\n",
    "                           norm=matplotlib.colors.SymLogNorm(vmin=0, vmax=1000, linthresh=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f09d5a-d404-4c7f-9c46-772611681531",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=r_query * np.cos(theta_query), y=r_query * np.sin(theta_query), c=ratio_interp, marker=\"+\", s=20, norm=matplotlib.colors.LogNorm(vmin=1e-1, vmax=1e7))\n",
    "plt.scatter(x=POES_L * np.cos(POES_theta), y=POES_L * np.sin(POES_theta), c=FLUX_INTEGRATED, marker=\"x\", s=30, norm=matplotlib.colors.LogNorm(vmin=1e-1, vmax=1e7))\n",
    "plt.colorbar()\n",
    "plt.xlim(-8, 8)\n",
    "plt.ylim(-8, 8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c913e9c2-403c-40d7-bd28-5d96e0c01306",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=r_query * np.cos(theta_query), y=r_query * np.sin(theta_query), c=chorus_interp, marker=\"+\", s=20, norm=matplotlib.colors.LogNorm(vmin=1e-1, vmax=1e2))\n",
    "plt.scatter(x=RBSP_L * np.cos(RBSP_theta), y=RBSP_L * np.sin(RBSP_theta), c=RBSP_CHORUS, marker=\"x\", s=30, norm=matplotlib.colors.LogNorm(vmin=1e-1, vmax=1e2))\n",
    "plt.colorbar()\n",
    "plt.xlim(-8, 8)\n",
    "plt.ylim(-8, 8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795b01a5-d117-4c20-94c7-5d5bed966aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled = np.isfinite(chorus_interp) & np.isfinite(ratio_interp)\n",
    "\n",
    "plt.scatter(x=r_query[labeled] * np.cos(theta_query[labeled]),\n",
    "            y=r_query[labeled] * np.sin(theta_query[labeled]),\n",
    "            c=chorus_interp[labeled],\n",
    "            marker=\"+\",\n",
    "            s=20,\n",
    "            norm=matplotlib.colors.LogNorm(vmin=1e-1, vmax=1e2))\n",
    "\n",
    "plt.xlim(-8, 8)\n",
    "plt.ylim(-8, 8)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
