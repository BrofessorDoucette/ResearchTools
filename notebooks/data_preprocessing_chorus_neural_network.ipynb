{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "# caution: path[0] is reserved for script path (or '' in REPL).\n",
    "sys.path.insert(1, os.path.abspath('./../src'))\n",
    "\n",
    "\n",
    "from cdflib.epochs_astropy import CDFAstropy as cdfepoch\n",
    "import astropy.time\n",
    "import data_loader\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "\n",
    "import data_loader\n",
    "import rbsp_chorus_tool\n",
    "import chorus_machine_learning_helper\n",
    "\n",
    "import importlib\n",
    "importlib.reload(data_loader)\n",
    "importlib.reload(rbsp_chorus_tool)\n",
    "\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STAGE 0 DATA VERIFICATION FOR POES LSTAR CALCULATIONS\n",
    "\n",
    "year = 2012\n",
    "SATID = \"m02\"\n",
    "refs = np.load(fr\"./../processed_data_chorus_neural_network/STAGE_0/MPE_DATA_PREPROCESSED_WITH_LSTAR/MPE_PREPROCESSED_DATA_T89_{year}.npz\", allow_pickle=True)\n",
    "\n",
    "DATA = refs[\"DATA\"].flatten()[0]\n",
    "print(DATA)\n",
    "SAT = DATA[SATID]\n",
    "print(type(SAT))\n",
    "\n",
    "dt_for_all = np.array([datetime.datetime.fromtimestamp(t) for t in SAT[\"UNIX_TIME\"]])\n",
    "\n",
    "plt.plot(dt_for_all, SAT[\"Lstar\"], label=\"L*\", color = \"red\", marker=\"*\")\n",
    "plt.plot(dt_for_all, SAT[\"L\"], label = \"IGRF Lm\", color = \"black\", marker=\"*\")\n",
    "plt.ylabel(\"|L|\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.title(f\"Some Orbits for {SATID} in {year}\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2013\n",
    "sat = \"a\"\n",
    "refs = np.load(fr\"./../processed_data/chorus_neural_network/STAGE_1/Lstar/RBSP_{sat.upper()}_T89_{year}.npz\", allow_pickle=True)\n",
    "\n",
    "OMNI = data_loader.load_raw_data_from_config(id = [\"OMNI\", \"ONE_HOUR_RESOLUTION\"],\n",
    "                                                 start = datetime.datetime(year = year, month = 1, day = 1),\n",
    "                                                 end = datetime.datetime(year = year + 1, month = 1, day = 1), \n",
    "                                                 root_data_dir = \"./../raw_data/\")\n",
    "\n",
    "OMNI_TIME = cdfepoch.unixtime(OMNI[\"Epoch\"])\n",
    "KP = OMNI[\"KP\"].astype(np.float64)\n",
    "\n",
    "invalid_omni_times = (OMNI_TIME < 0) | (KP < 0) | (KP >= 99) | np.isnan(KP) | np.isnan(OMNI_TIME)\n",
    "KP[invalid_omni_times] = np.nan\n",
    "    \n",
    "KP_INTERPOLATED = np.interp(refs[\"UNIX_TIME\"], OMNI_TIME, KP, left = np.nan, right = np.nan)    \n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, sharex=True)\n",
    "\n",
    "dates = np.array([datetime.datetime.fromtimestamp(t) for t in refs[\"UNIX_TIME\"]])\n",
    "\n",
    "\n",
    "axs[0].plot(dates, refs[\"Lstar\"])\n",
    "axs[1].plot(dates, KP_INTERPOLATED)\n",
    "plt.xlabel(\"Time (UTC)\")\n",
    "axs[0].set_ylabel(\"L*\")\n",
    "axs[1].set_ylabel(\"KP-Index\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Interface for stage 1, Designed to do a year at a time\n",
    "\n",
    "year = 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stage 1 RBSP Chorus Preprocessing, Obtains clean chorus amplitudes\n",
    "\n",
    "#start = datetime.datetime(year = year, month = 1, day = 1)\n",
    "#end = datetime.datetime(year = year + 1, month = 1, day = 1)\n",
    "\n",
    "start = datetime.datetime(year = 2019, month = 1, day = 1)\n",
    "end = datetime.datetime(year = 2019, month = 10, day = 13, hour = 23, minute = 59, second = 59)\n",
    "\n",
    "WNA_survey_a = data_loader.load_raw_data_from_config(id=[\"RBSP\", \"EMFISIS\", \"L4\", \"WNA_SURVEY\"],\n",
    "                                                     start=start,\n",
    "                                                     end=end,\n",
    "                                                     satellite=\"a\",\n",
    "                                                     root_data_dir=\"/project/rbsp/data/\",\n",
    "                                                     use_config_keys_in_subdir=False)\n",
    "\n",
    "WNA_survey_b = data_loader.load_raw_data_from_config(id=[\"RBSP\", \"EMFISIS\", \"L4\", \"WNA_SURVEY\"],\n",
    "                                                     start=start,\n",
    "                                                     end=end,\n",
    "                                                     satellite=\"b\",\n",
    "                                                     root_data_dir=\"/project/rbsp/data/\",\n",
    "                                                     use_config_keys_in_subdir=False)\n",
    "\n",
    "WFR_spectral_matrix_a = data_loader.load_raw_data_from_config(id=[\"RBSP\", \"EMFISIS\", \"L2\", \"WFR_SPECTRAL_MATRIX_DIAGONAL\"],\n",
    "                                                              start=start,\n",
    "                                                              end=end,\n",
    "                                                              satellite=\"a\",\n",
    "                                                              root_data_dir=\"/project/rbsp/data/\",\n",
    "                                                              use_config_keys_in_subdir=False)\n",
    "\n",
    "WFR_spectral_matrix_b = data_loader.load_raw_data_from_config(id=[\"RBSP\", \"EMFISIS\", \"L2\", \"WFR_SPECTRAL_MATRIX_DIAGONAL\"],\n",
    "                                                              start=start,\n",
    "                                                              end=end,\n",
    "                                                              satellite=\"b\",\n",
    "                                                              root_data_dir=\"/project/rbsp/data/\",\n",
    "                                                              use_config_keys_in_subdir=False)\n",
    "\n",
    "num_wna_files_A = len(WNA_survey_a[\"timestamps_per_file\"])\n",
    "num_wna_files_B = len(WNA_survey_b[\"timestamps_per_file\"])\n",
    "num_wfr_files_A = WFR_spectral_matrix_a[\"WFR_bandwidth\"].shape[0]\n",
    "num_wfr_files_B = WFR_spectral_matrix_b[\"WFR_bandwidth\"].shape[0]\n",
    "\n",
    "print(f\"Number of files loaded: {num_wna_files_A, num_wna_files_B, num_wfr_files_A, num_wfr_files_B}\")\n",
    "\n",
    "if len({num_wna_files_A, num_wfr_files_A}) != 1:\n",
    "    raise Exception(\"The same number of days wasn't loaded for RBSP-A!\")\n",
    "\n",
    "if len({num_wna_files_B, num_wfr_files_B}) != 1:\n",
    "    raise Exception(\"The same number of days wasn't loaded for RBSP-B!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlt_A = WNA_survey_a[\"MLT\"]\n",
    "L_A = WNA_survey_a[\"L\"]\n",
    "epoch_A = WNA_survey_a[\"Epoch\"]\n",
    "\n",
    "time_A = astropy.time.Time(cdfepoch.to_datetime(epoch_A), format=\"datetime\").utc\n",
    "\n",
    "chorus_A = rbsp_chorus_tool.iterate_through_days_and_calculate_chorus_amplitudes(WNA_survey = WNA_survey_a,\n",
    "                                                                                 WFR_spectral_matrix = WFR_spectral_matrix_a)\n",
    "\n",
    "lower_band_chorus_A = chorus_A[\"Lower_Band\"]\n",
    "upper_band_chorus_A = chorus_A[\"Upper_Band\"]\n",
    "\n",
    "within_epoch_range_A = (start < time_A) & (time_A < end)\n",
    "finite_chorus_A = np.isfinite(lower_band_chorus_A) & np.isfinite(upper_band_chorus_A)\n",
    "#This line might not be necessary but we want to train on clean data, literally any np.nan will fuck it ALL up. Ill probably double check before training\n",
    "all_valid_coordinates_A = (epoch_A > 0) & (0 <= mlt_A) & (mlt_A <= 24) & (0 < L_A) & (L_A < 10)\n",
    "\n",
    "epoch_A = epoch_A[within_epoch_range_A & finite_chorus_A & all_valid_coordinates_A]\n",
    "L_A = L_A[within_epoch_range_A & finite_chorus_A & all_valid_coordinates_A]\n",
    "mlt_A = mlt_A[within_epoch_range_A & finite_chorus_A & all_valid_coordinates_A]\n",
    "lower_band_chorus_A = lower_band_chorus_A[within_epoch_range_A & finite_chorus_A & all_valid_coordinates_A]\n",
    "upper_band_chorus_A = upper_band_chorus_A[within_epoch_range_A & finite_chorus_A & all_valid_coordinates_A]\n",
    "\n",
    "mlt_B = WNA_survey_b[\"MLT\"]\n",
    "L_B = WNA_survey_b[\"L\"]\n",
    "epoch_B = WNA_survey_b[\"Epoch\"]\n",
    "time_B = astropy.time.Time(cdfepoch.to_datetime(epoch_B), format=\"datetime\").utc\n",
    "\n",
    "chorus_B = rbsp_chorus_tool.iterate_through_days_and_calculate_chorus_amplitudes(WNA_survey = WNA_survey_b,\n",
    "                                                                                 WFR_spectral_matrix = WFR_spectral_matrix_b)\n",
    "\n",
    "lower_band_chorus_B = chorus_B[\"Lower_Band\"]\n",
    "upper_band_chorus_B = chorus_B[\"Upper_Band\"]\n",
    "\n",
    "within_epoch_range_B = (start < time_B) & (time_B < end)\n",
    "finite_chorus_B = np.isfinite(lower_band_chorus_B) & np.isfinite(upper_band_chorus_B)\n",
    "all_valid_coordinates_B = (epoch_B > 0) & (0 <= mlt_B) & (mlt_B <= 24) & (0 < L_B) & (L_B < 10)\n",
    "\n",
    "epoch_B = epoch_B[within_epoch_range_B & finite_chorus_B & all_valid_coordinates_B]\n",
    "L_B = L_B[within_epoch_range_B & finite_chorus_B & all_valid_coordinates_B]\n",
    "mlt_B = mlt_B[within_epoch_range_B & finite_chorus_B & all_valid_coordinates_B]\n",
    "lower_band_chorus_B = lower_band_chorus_B[within_epoch_range_B & finite_chorus_B & all_valid_coordinates_B]\n",
    "upper_band_chorus_B = upper_band_chorus_B[within_epoch_range_B & finite_chorus_B & all_valid_coordinates_B]\n",
    "\n",
    "\n",
    "print(epoch_A.shape)\n",
    "print(lower_band_chorus_A.shape)\n",
    "print(upper_band_chorus_A.shape)\n",
    "print(L_A.shape)\n",
    "print(mlt_A.shape)\n",
    "\n",
    "print(epoch_B.shape)\n",
    "print(lower_band_chorus_B.shape)\n",
    "print(upper_band_chorus_B.shape)\n",
    "print(L_B.shape)\n",
    "print(mlt_B.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the RBSP stage 1 data, might honestly only need one stage\n",
    "np.savez(file = os.path.abspath(f\"./../processed_data/chorus_neural_network/STAGE_1/CHORUS/RBSP_OBSERVED_CHORUS_{year}.npz\"), \n",
    "         EPOCH_A = epoch_A, \n",
    "         MLT_A = mlt_A, \n",
    "         L_A = L_A, \n",
    "         LOWER_BAND_CHORUS_A = lower_band_chorus_A,\n",
    "         UPPER_BAND_CHORUS_A = upper_band_chorus_A,\n",
    "         EPOCH_B = epoch_B, \n",
    "         MLT_B = mlt_B, \n",
    "         L_B = L_B, \n",
    "         LOWER_BAND_CHORUS_B = lower_band_chorus_B,\n",
    "         UPPER_BAND_CHORUS_B = upper_band_chorus_B)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Began processing year : 2012\n",
      "Began loading RBSP Data for year: 2012\n",
      "RBSP Data loaded for year : 2012\n",
      "Began loading POES Data for year : 2012\n",
      "Finished loading POES data for year : 2012\n",
      "Began loading OMNI data for year : 2012\n",
      "Finished loading OMNI data for year : 2012\n",
      "Began loading SUPERMAG data for year : 2012\n",
      "Finished loading SUPERMAG data for year : 2012\n",
      "Finding CONJUNCTIONS for year : 2012\n",
      "Number of records: 11216727 for POES SATELLITE: m02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 7291684/11216727 [00:40<04:21, 14981.48it/s] /tmp/ipykernel_2505857/812721852.py:223: RuntimeWarning: Mean of empty slice\n",
      "  AVG_AVG_B = np.nanmean(OMNI[\"AVG_B\"][TIME_RANGE[0]:TIME_RANGE[1]])\n",
      "/tmp/ipykernel_2505857/812721852.py:224: RuntimeWarning: Mean of empty slice\n",
      "  AVG_FLOW_SPEED = np.nanmean(OMNI[\"FLOW_SPEED\"][TIME_RANGE[0]:TIME_RANGE[1]])\n",
      "/tmp/ipykernel_2505857/812721852.py:225: RuntimeWarning: Mean of empty slice\n",
      "  AVG_PROTON_DENSITY = np.nanmean(OMNI[\"PROTON_DENSITY\"][TIME_RANGE[0]:TIME_RANGE[1]])\n",
      "/home/jddoucette/Research_Tools/ResearchPy/lib64/python3.12/site-packages/numpy/_core/fromnumeric.py:3860: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/jddoucette/Research_Tools/ResearchPy/lib64/python3.12/site-packages/numpy/_core/_methods.py:145: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "100%|██████████| 11216727/11216727 [11:08<00:00, 16777.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of conjunctions: 8953\n",
      "Number of records: 11451286 for POES SATELLITE: n15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11451286/11451286 [11:11<00:00, 17054.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of conjunctions: 11836\n",
      "Number of records: 11313190 for POES SATELLITE: n17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11313190/11313190 [11:01<00:00, 17112.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of conjunctions: 12906\n",
      "Number of records: 11786451 for POES SATELLITE: n18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11786451/11786451 [11:24<00:00, 17226.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of conjunctions: 8650\n",
      "Number of records: 11755449 for POES SATELLITE: n19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11755449/11755449 [11:31<00:00, 17010.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of conjunctions: 5649\n",
      "Total number of conjunctions so far: 47994\n",
      "Began processing year : 2013\n",
      "Began loading RBSP Data for year: 2013\n",
      "RBSP Data loaded for year : 2013\n",
      "Began loading POES Data for year : 2013\n",
      "Finished loading POES data for year : 2013\n",
      "Began loading OMNI data for year : 2013\n",
      "Finished loading OMNI data for year : 2013\n",
      "Began loading SUPERMAG data for year : 2013\n",
      "Finished loading SUPERMAG data for year : 2013\n",
      "Finding CONJUNCTIONS for year : 2013\n",
      "Number of records: 10305126 for POES SATELLITE: m02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 73921/10305126 [00:11<13:42, 12441.39it/s]/tmp/ipykernel_2505857/812721852.py:223: RuntimeWarning: Mean of empty slice\n",
      "  AVG_AVG_B = np.nanmean(OMNI[\"AVG_B\"][TIME_RANGE[0]:TIME_RANGE[1]])\n",
      "/tmp/ipykernel_2505857/812721852.py:224: RuntimeWarning: Mean of empty slice\n",
      "  AVG_FLOW_SPEED = np.nanmean(OMNI[\"FLOW_SPEED\"][TIME_RANGE[0]:TIME_RANGE[1]])\n",
      "/tmp/ipykernel_2505857/812721852.py:225: RuntimeWarning: Mean of empty slice\n",
      "  AVG_PROTON_DENSITY = np.nanmean(OMNI[\"PROTON_DENSITY\"][TIME_RANGE[0]:TIME_RANGE[1]])\n",
      "/home/jddoucette/Research_Tools/ResearchPy/lib64/python3.12/site-packages/numpy/_core/fromnumeric.py:3860: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/jddoucette/Research_Tools/ResearchPy/lib64/python3.12/site-packages/numpy/_core/_methods.py:145: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "100%|██████████| 10305126/10305126 [27:53<00:00, 6156.21it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of conjunctions: 29102\n",
      "Number of records: 10272510 for POES SATELLITE: n15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10272510/10272510 [27:54<00:00, 6135.91it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of conjunctions: 30428\n",
      "Number of records: 1722924 for POES SATELLITE: n17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1722924/1722924 [04:39<00:00, 6164.16it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of conjunctions: 1922\n",
      "Number of records: 10555329 for POES SATELLITE: n18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10555329/10555329 [28:39<00:00, 6137.57it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of conjunctions: 30840\n",
      "Number of records: 10527786 for POES SATELLITE: n19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10527786/10527786 [28:40<00:00, 6119.04it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of conjunctions: 29368\n",
      "Total number of conjunctions so far: 169654\n",
      "Began processing year : 2014\n",
      "Began loading RBSP Data for year: 2014\n",
      "RBSP Data loaded for year : 2014\n",
      "Began loading POES Data for year : 2014\n",
      "Finished loading POES data for year : 2014\n",
      "Began loading OMNI data for year : 2014\n",
      "Finished loading OMNI data for year : 2014\n",
      "Began loading SUPERMAG data for year : 2014\n",
      "Finished loading SUPERMAG data for year : 2014\n",
      "Finding CONJUNCTIONS for year : 2014\n",
      "Number of records: 10365324 for POES SATELLITE: m01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 120217/10365324 [00:19<27:13, 6270.48it/s]/tmp/ipykernel_2505857/812721852.py:223: RuntimeWarning: Mean of empty slice\n",
      "  AVG_AVG_B = np.nanmean(OMNI[\"AVG_B\"][TIME_RANGE[0]:TIME_RANGE[1]])\n",
      "/tmp/ipykernel_2505857/812721852.py:224: RuntimeWarning: Mean of empty slice\n",
      "  AVG_FLOW_SPEED = np.nanmean(OMNI[\"FLOW_SPEED\"][TIME_RANGE[0]:TIME_RANGE[1]])\n",
      "/tmp/ipykernel_2505857/812721852.py:225: RuntimeWarning: Mean of empty slice\n",
      "  AVG_PROTON_DENSITY = np.nanmean(OMNI[\"PROTON_DENSITY\"][TIME_RANGE[0]:TIME_RANGE[1]])\n",
      "/home/jddoucette/Research_Tools/ResearchPy/lib64/python3.12/site-packages/numpy/_core/fromnumeric.py:3860: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/jddoucette/Research_Tools/ResearchPy/lib64/python3.12/site-packages/numpy/_core/_methods.py:145: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "100%|██████████| 10365324/10365324 [27:46<00:00, 6221.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of conjunctions: 23487\n",
      "Number of records: 10505463 for POES SATELLITE: m02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10505463/10505463 [28:22<00:00, 6170.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of conjunctions: 23822\n",
      "Number of records: 10538006 for POES SATELLITE: n15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10538006/10538006 [28:22<00:00, 6190.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of conjunctions: 20230\n",
      "Number of records: 4615328 for POES SATELLITE: n16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4615328/4615328 [12:28<00:00, 6162.81it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of conjunctions: 11952\n",
      "Number of records: 10866624 for POES SATELLITE: n18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10866624/10866624 [29:17<00:00, 6182.50it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of conjunctions: 21543\n",
      "Number of records: 10872481 for POES SATELLITE: n19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10872481/10872481 [29:25<00:00, 6156.83it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of conjunctions: 23471\n",
      "Total number of conjunctions so far: 294159\n",
      "Began processing year : 2015\n",
      "Began loading RBSP Data for year: 2015\n",
      "RBSP Data loaded for year : 2015\n",
      "Began loading POES Data for year : 2015\n",
      "Finished loading POES data for year : 2015\n",
      "Began loading OMNI data for year : 2015\n",
      "Finished loading OMNI data for year : 2015\n",
      "Began loading SUPERMAG data for year : 2015\n",
      "Finished loading SUPERMAG data for year : 2015\n",
      "Finding CONJUNCTIONS for year : 2015\n",
      "Number of records: 10129644 for POES SATELLITE: m01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3210/10129644 [00:00<31:31, 5354.96it/s]/tmp/ipykernel_2505857/812721852.py:223: RuntimeWarning: Mean of empty slice\n",
      "  AVG_AVG_B = np.nanmean(OMNI[\"AVG_B\"][TIME_RANGE[0]:TIME_RANGE[1]])\n",
      "/tmp/ipykernel_2505857/812721852.py:224: RuntimeWarning: Mean of empty slice\n",
      "  AVG_FLOW_SPEED = np.nanmean(OMNI[\"FLOW_SPEED\"][TIME_RANGE[0]:TIME_RANGE[1]])\n",
      "/tmp/ipykernel_2505857/812721852.py:225: RuntimeWarning: Mean of empty slice\n",
      "  AVG_PROTON_DENSITY = np.nanmean(OMNI[\"PROTON_DENSITY\"][TIME_RANGE[0]:TIME_RANGE[1]])\n",
      "/home/jddoucette/Research_Tools/ResearchPy/lib64/python3.12/site-packages/numpy/_core/fromnumeric.py:3860: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/jddoucette/Research_Tools/ResearchPy/lib64/python3.12/site-packages/numpy/_core/_methods.py:145: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "100%|██████████| 10129644/10129644 [27:28<00:00, 6143.58it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of conjunctions: 25927\n",
      "Number of records: 10144838 for POES SATELLITE: m02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10144838/10144838 [27:26<00:00, 6159.67it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of conjunctions: 25441\n",
      "Number of records: 10114409 for POES SATELLITE: n15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10114409/10114409 [27:25<00:00, 6146.62it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of conjunctions: 27117\n",
      "Number of records: 10414593 for POES SATELLITE: n18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10414593/10414593 [28:16<00:00, 6137.40it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of conjunctions: 28430\n",
      "Number of records: 10573495 for POES SATELLITE: n19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10573495/10573495 [28:51<00:00, 6105.46it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of conjunctions: 33336\n",
      "Total number of conjunctions so far: 434410\n",
      "Began processing year : 2016\n",
      "Began loading RBSP Data for year: 2016\n",
      "RBSP Data loaded for year : 2016\n",
      "Began loading POES Data for year : 2016\n",
      "Finished loading POES data for year : 2016\n",
      "Began loading OMNI data for year : 2016\n",
      "Finished loading OMNI data for year : 2016\n",
      "Began loading SUPERMAG data for year : 2016\n",
      "Finished loading SUPERMAG data for year : 2016\n",
      "Finding CONJUNCTIONS for year : 2016\n",
      "Number of records: 10379217 for POES SATELLITE: m02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4337/10379217 [00:00<21:14, 8138.68it/s]/tmp/ipykernel_2505857/812721852.py:223: RuntimeWarning: Mean of empty slice\n",
      "  AVG_AVG_B = np.nanmean(OMNI[\"AVG_B\"][TIME_RANGE[0]:TIME_RANGE[1]])\n",
      "/tmp/ipykernel_2505857/812721852.py:224: RuntimeWarning: Mean of empty slice\n",
      "  AVG_FLOW_SPEED = np.nanmean(OMNI[\"FLOW_SPEED\"][TIME_RANGE[0]:TIME_RANGE[1]])\n",
      "/tmp/ipykernel_2505857/812721852.py:225: RuntimeWarning: Mean of empty slice\n",
      "  AVG_PROTON_DENSITY = np.nanmean(OMNI[\"PROTON_DENSITY\"][TIME_RANGE[0]:TIME_RANGE[1]])\n",
      "/home/jddoucette/Research_Tools/ResearchPy/lib64/python3.12/site-packages/numpy/_core/fromnumeric.py:3860: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/jddoucette/Research_Tools/ResearchPy/lib64/python3.12/site-packages/numpy/_core/_methods.py:145: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "100%|██████████| 10379217/10379217 [27:52<00:00, 6206.12it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of conjunctions: 26355\n",
      "Number of records: 10420462 for POES SATELLITE: n15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10420462/10420462 [28:01<00:00, 6196.42it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of conjunctions: 20647\n",
      "Number of records: 10643241 for POES SATELLITE: n18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10643241/10643241 [28:35<00:00, 6203.08it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of conjunctions: 21942\n",
      "Number of records: 10881780 for POES SATELLITE: n19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10881780/10881780 [29:19<00:00, 6185.65it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of conjunctions: 22643\n",
      "Total number of conjunctions so far: 525997\n",
      "Began processing year : 2017\n",
      "Began loading RBSP Data for year: 2017\n",
      "RBSP Data loaded for year : 2017\n",
      "Began loading POES Data for year : 2017\n",
      "Finished loading POES data for year : 2017\n",
      "Began loading OMNI data for year : 2017\n",
      "Finished loading OMNI data for year : 2017\n",
      "Began loading SUPERMAG data for year : 2017\n",
      "Finished loading SUPERMAG data for year : 2017\n",
      "Finding CONJUNCTIONS for year : 2017\n",
      "Number of records: 10404051 for POES SATELLITE: m01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 34399/10404051 [00:05<32:24, 5333.92it/s]/tmp/ipykernel_2505857/812721852.py:223: RuntimeWarning: Mean of empty slice\n",
      "  AVG_AVG_B = np.nanmean(OMNI[\"AVG_B\"][TIME_RANGE[0]:TIME_RANGE[1]])\n",
      "/tmp/ipykernel_2505857/812721852.py:224: RuntimeWarning: Mean of empty slice\n",
      "  AVG_FLOW_SPEED = np.nanmean(OMNI[\"FLOW_SPEED\"][TIME_RANGE[0]:TIME_RANGE[1]])\n",
      "/tmp/ipykernel_2505857/812721852.py:225: RuntimeWarning: Mean of empty slice\n",
      "  AVG_PROTON_DENSITY = np.nanmean(OMNI[\"PROTON_DENSITY\"][TIME_RANGE[0]:TIME_RANGE[1]])\n",
      "/home/jddoucette/Research_Tools/ResearchPy/lib64/python3.12/site-packages/numpy/_core/fromnumeric.py:3860: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/jddoucette/Research_Tools/ResearchPy/lib64/python3.12/site-packages/numpy/_core/_methods.py:145: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "100%|██████████| 10404051/10404051 [28:11<00:00, 6149.45it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of conjunctions: 27830\n",
      "Number of records: 10407416 for POES SATELLITE: m02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10407416/10407416 [28:13<00:00, 6147.02it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of conjunctions: 27835\n",
      "Number of records: 10351902 for POES SATELLITE: n15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10351902/10351902 [28:11<00:00, 6118.32it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of conjunctions: 28609\n",
      "Number of records: 10561097 for POES SATELLITE: n18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10561097/10561097 [28:48<00:00, 6111.00it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of conjunctions: 28829\n",
      "Number of records: 10840301 for POES SATELLITE: n19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10840301/10840301 [29:39<00:00, 6090.56it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of conjunctions: 28872\n",
      "Total number of conjunctions so far: 667972\n",
      "Began processing year : 2018\n",
      "Began loading RBSP Data for year: 2018\n",
      "RBSP Data loaded for year : 2018\n",
      "Began loading POES Data for year : 2018\n",
      "Finished loading POES data for year : 2018\n",
      "Began loading OMNI data for year : 2018\n",
      "Finished loading OMNI data for year : 2018\n",
      "Began loading SUPERMAG data for year : 2018\n",
      "Finished loading SUPERMAG data for year : 2018\n",
      "Finding CONJUNCTIONS for year : 2018\n",
      "Number of records: 10201857 for POES SATELLITE: m01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2949/10201857 [00:00<05:46, 29469.44it/s]/tmp/ipykernel_2505857/812721852.py:223: RuntimeWarning: Mean of empty slice\n",
      "  AVG_AVG_B = np.nanmean(OMNI[\"AVG_B\"][TIME_RANGE[0]:TIME_RANGE[1]])\n",
      "/tmp/ipykernel_2505857/812721852.py:224: RuntimeWarning: Mean of empty slice\n",
      "  AVG_FLOW_SPEED = np.nanmean(OMNI[\"FLOW_SPEED\"][TIME_RANGE[0]:TIME_RANGE[1]])\n",
      "/tmp/ipykernel_2505857/812721852.py:225: RuntimeWarning: Mean of empty slice\n",
      "  AVG_PROTON_DENSITY = np.nanmean(OMNI[\"PROTON_DENSITY\"][TIME_RANGE[0]:TIME_RANGE[1]])\n",
      "/home/jddoucette/Research_Tools/ResearchPy/lib64/python3.12/site-packages/numpy/_core/fromnumeric.py:3860: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/jddoucette/Research_Tools/ResearchPy/lib64/python3.12/site-packages/numpy/_core/_methods.py:145: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "100%|██████████| 10201857/10201857 [27:45<00:00, 6123.73it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of conjunctions: 29803\n",
      "Number of records: 10432410 for POES SATELLITE: m02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10432410/10432410 [28:20<00:00, 6134.74it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of conjunctions: 30300\n",
      "Number of records: 10368403 for POES SATELLITE: n15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10368403/10368403 [28:14<00:00, 6118.77it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of conjunctions: 29064\n",
      "Number of records: 10660286 for POES SATELLITE: n18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10660286/10660286 [28:59<00:00, 6129.71it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of conjunctions: 31664\n",
      "Number of records: 10838917 for POES SATELLITE: n19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10838917/10838917 [29:29<00:00, 6126.01it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of conjunctions: 26640\n",
      "Total number of conjunctions so far: 815443\n",
      "Began processing year : 2019\n",
      "Began loading RBSP Data for year: 2019\n",
      "RBSP Data loaded for year : 2019\n",
      "Began loading POES Data for year : 2019\n",
      "Finished loading POES data for year : 2019\n",
      "Began loading OMNI data for year : 2019\n",
      "Finished loading OMNI data for year : 2019\n",
      "Began loading SUPERMAG data for year : 2019\n",
      "Finished loading SUPERMAG data for year : 2019\n",
      "Finding CONJUNCTIONS for year : 2019\n",
      "Number of records: 10017532 for POES SATELLITE: m02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8430/10017532 [00:01<27:52, 5984.50it/s] /tmp/ipykernel_2505857/812721852.py:223: RuntimeWarning: Mean of empty slice\n",
      "  AVG_AVG_B = np.nanmean(OMNI[\"AVG_B\"][TIME_RANGE[0]:TIME_RANGE[1]])\n",
      "/tmp/ipykernel_2505857/812721852.py:224: RuntimeWarning: Mean of empty slice\n",
      "  AVG_FLOW_SPEED = np.nanmean(OMNI[\"FLOW_SPEED\"][TIME_RANGE[0]:TIME_RANGE[1]])\n",
      "/tmp/ipykernel_2505857/812721852.py:225: RuntimeWarning: Mean of empty slice\n",
      "  AVG_PROTON_DENSITY = np.nanmean(OMNI[\"PROTON_DENSITY\"][TIME_RANGE[0]:TIME_RANGE[1]])\n",
      "/home/jddoucette/Research_Tools/ResearchPy/lib64/python3.12/site-packages/numpy/_core/fromnumeric.py:3860: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/jddoucette/Research_Tools/ResearchPy/lib64/python3.12/site-packages/numpy/_core/_methods.py:145: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "100%|██████████| 10017532/10017532 [18:14<00:00, 9149.49it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of conjunctions: 11182\n",
      "Number of records: 9066605 for POES SATELLITE: m03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9066605/9066605 [17:53<00:00, 8447.34it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of conjunctions: 11160\n",
      "Number of records: 10070766 for POES SATELLITE: n15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10070766/10070766 [18:28<00:00, 9085.56it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of conjunctions: 16017\n",
      "Number of records: 10372732 for POES SATELLITE: n18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10372732/10372732 [18:47<00:00, 9197.38it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of conjunctions: 13626\n",
      "Number of records: 10486100 for POES SATELLITE: n19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10486100/10486100 [19:03<00:00, 9169.72it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of conjunctions: 21436\n",
      "Total number of conjunctions so far: 888864\n",
      "Conjunctions to be saved: (888864, 21)\n"
     ]
    }
   ],
   "source": [
    "#Stage 2, clean then combine RBSP, OMNI, and POES Data and find conjunctions between RBSP and POES\n",
    "\n",
    "VERSION = \"v1a\"\n",
    "FIELD_MODEL = \"T89\"\n",
    "\n",
    "MAX_L_DIFF = 0.10\n",
    "MAX_MLT_DIFF = 2.0\n",
    "MAX_T_DIFF_SEC = 60\n",
    "\n",
    "L_SCALE = (1.0 / MAX_L_DIFF)**2\n",
    "MLT_SCALE = (1.0 / MAX_MLT_DIFF)**2\n",
    "TIME_SCALE = (1.0 / MAX_T_DIFF_SEC)**2\n",
    "\n",
    "CONJUNCTIONS_TOTAL = []\n",
    "\n",
    "for _year in range(2012, 2020, 1):\n",
    "    \n",
    "    print(f\"Began processing year : {_year}\")\n",
    "    \n",
    "    #LOAD THE OBSERVED CHORUS\n",
    "    print(f\"Began loading RBSP Data for year: {_year}\")\n",
    "    refs = np.load(fr\"./../processed_data/chorus_neural_network/STAGE_1/CHORUS/RBSP_OBSERVED_CHORUS_{_year}.npz\", allow_pickle=True)\n",
    "    RBSP_A = {}\n",
    "    RBSP_A[\"EPOCH\"] = refs[\"EPOCH_A\"]\n",
    "    RBSP_A[\"MLT\"] = refs[\"MLT_A\"]\n",
    "    RBSP_A[\"L\"] = refs[\"L_A\"]\n",
    "    RBSP_A[\"LOWER_BAND\"] = refs[\"LOWER_BAND_CHORUS_A\"]\n",
    "    RBSP_A[\"UPPER_BAND\"] = refs[\"UPPER_BAND_CHORUS_A\"]\n",
    "\n",
    "    RBSP_B = {}\n",
    "    RBSP_B[\"EPOCH\"] = refs[\"EPOCH_B\"]\n",
    "    RBSP_B[\"MLT\"] = refs[\"MLT_B\"]\n",
    "    RBSP_B[\"L\"] = refs[\"L_B\"]\n",
    "    RBSP_B[\"LOWER_BAND\"] = refs[\"LOWER_BAND_CHORUS_B\"]\n",
    "    RBSP_B[\"UPPER_BAND\"] = refs[\"UPPER_BAND_CHORUS_B\"]\n",
    "    \n",
    "    refs.close()\n",
    "    \n",
    "    RBSP_A[\"UNIX_TIME\"] = cdfepoch.unixtime(RBSP_A[\"EPOCH\"])\n",
    "    RBSP_B[\"UNIX_TIME\"] = cdfepoch.unixtime(RBSP_B[\"EPOCH\"])\n",
    "    \n",
    "    #LOAD THE LSTAR AND INTERPOLATE\n",
    "    refs_A = np.load(fr\"./../processed_data/chorus_neural_network/STAGE_1/Lstar/RBSP_A_{FIELD_MODEL}_{_year}.npz\", allow_pickle=True)\n",
    "    \n",
    "    MAGEPHEM_TIME_A = refs_A[\"UNIX_TIME\"]\n",
    "    MAGEPHEM_LSTAR_A = refs_A[\"Lstar\"]\n",
    "    MAGEPHEM_L_A = refs_A[\"L\"]\n",
    "    \n",
    "    refs_A.close()\n",
    "    \n",
    "    refs_B = np.load(fr\"./../processed_data/chorus_neural_network/STAGE_1/Lstar/RBSP_B_{FIELD_MODEL}_{_year}.npz\", allow_pickle=True)\n",
    "    \n",
    "    MAGEPHEM_TIME_B = refs_B[\"UNIX_TIME\"]\n",
    "    MAGEPHEM_LSTAR_B = refs_B[\"Lstar\"]\n",
    "    MAGEPHEM_L_B = refs_B[\"L\"]\n",
    "    \n",
    "    refs_B.close()\n",
    "    \n",
    "    #PREPROCESS DATA\n",
    "    \n",
    "    RBSP_A[\"LSTAR\"] = np.interp(RBSP_A[\"UNIX_TIME\"], MAGEPHEM_TIME_A, MAGEPHEM_LSTAR_A, left = np.nan, right = np.nan)\n",
    "    RBSP_B[\"LSTAR\"] = np.interp(RBSP_B[\"UNIX_TIME\"], MAGEPHEM_TIME_B, MAGEPHEM_LSTAR_B, left = np.nan, right = np.nan)\n",
    "    \n",
    "    order_A = np.argsort(RBSP_A[\"UNIX_TIME\"])\n",
    "    order_B = np.argsort(RBSP_B[\"UNIX_TIME\"])\n",
    "    \n",
    "    RBSP_A[\"UNIX_TIME\"] = RBSP_A[\"UNIX_TIME\"][order_A]\n",
    "    RBSP_A[\"EPOCH\"] = RBSP_A[\"EPOCH\"][order_A]\n",
    "    RBSP_A[\"MLT\"] = RBSP_A[\"MLT\"][order_A]\n",
    "    RBSP_A[\"L\"] = RBSP_A[\"L\"][order_A]\n",
    "    RBSP_A[\"LSTAR\"] = RBSP_A[\"LSTAR\"][order_A]\n",
    "    RBSP_A[\"LOWER_BAND\"] = RBSP_A[\"LOWER_BAND\"][order_A]\n",
    "    RBSP_A[\"UPPER_BAND\"] = RBSP_A[\"UPPER_BAND\"][order_A]\n",
    "\n",
    "    RBSP_B[\"UNIX_TIME\"] = RBSP_B[\"UNIX_TIME\"][order_B]\n",
    "    RBSP_B[\"EPOCH\"] = RBSP_B[\"EPOCH\"][order_B]\n",
    "    RBSP_B[\"MLT\"] = RBSP_B[\"MLT\"][order_B]\n",
    "    RBSP_B[\"L\"] = RBSP_B[\"L\"][order_B]\n",
    "    RBSP_B[\"LSTAR\"] = RBSP_B[\"LSTAR\"][order_B]\n",
    "    RBSP_B[\"LOWER_BAND\"] = RBSP_B[\"LOWER_BAND\"][order_B]\n",
    "    RBSP_B[\"UPPER_BAND\"] = RBSP_B[\"UPPER_BAND\"][order_B]\n",
    "    \n",
    "    RBSP = [RBSP_A, RBSP_B]\n",
    "    print(f\"RBSP Data loaded for year : {_year}\")\n",
    "    \n",
    "    print(f\"Began loading POES Data for year : {_year}\")\n",
    "    \n",
    "    POES = {}\n",
    "    \n",
    "    refs = np.load(fr\"./../processed_data/chorus_neural_network/STAGE_0/MPE_DATA_PREPROCESSED_WITH_LSTAR/MPE_PREPROCESSED_DATA_T89_{_year}.npz\", allow_pickle=True)\n",
    "    POES_DATA = refs[\"DATA\"].flatten()[0]\n",
    "    \n",
    "    for SATID in POES_DATA:\n",
    "        \n",
    "        SAT = POES_DATA[SATID]\n",
    "        \n",
    "        UNIX_TIME = []\n",
    "        LSTAR = []\n",
    "        MLT = []\n",
    "        BLC_FLUX_0 = []\n",
    "        BLC_FLUX_1 = []\n",
    "        BLC_FLUX_2 = []\n",
    "        BLC_FLUX_3 = []\n",
    "        BLC_FLUX_4 = []\n",
    "        BLC_FLUX_5 = []\n",
    "        BLC_FLUX_6 = []\n",
    "        BLC_FLUX_7 = []\n",
    "        \n",
    "        for p in range(len(SAT[\"UNIX_TIME\"]) - 1):\n",
    "            \n",
    "            t1 = SAT[\"UNIX_TIME\"][p]\n",
    "            t2 = SAT[\"UNIX_TIME\"][p + 1]\n",
    "                        \n",
    "            if t2 - t1 < 30.0:\n",
    "                \n",
    "                t_points = np.arange(t1, t2 + 1, step=2, dtype=np.float64)\n",
    "                \n",
    "                UNIX_TIME.append(t_points)\n",
    "                LSTAR.append(np.interp(x = t_points, xp = [t1, t2], fp = [SAT[\"Lstar\"][p], SAT[\"Lstar\"][p+1]], left=np.nan, right = np.nan))\n",
    "                \n",
    "                X_INTERPOLATED = np.interp(t_points, xp = [t1, t2], fp = [np.cos(SAT[\"MLT\"][p] * 2 * np.pi / 24.0), np.cos(SAT[\"MLT\"][p+1] * 2 * np.pi / 24.0)], left=np.nan, right=np.nan)\n",
    "                Y_INTERPOLATED = np.interp(t_points, xp = [t1, t2], fp = [np.sin(SAT[\"MLT\"][p] * 2 * np.pi / 24.0), np.sin(SAT[\"MLT\"][p+1] * 2 * np.pi / 24.0)], left=np.nan, right=np.nan)\n",
    "                ANGLE_IN_RADIANS = np.mod(np.arctan2(Y_INTERPOLATED, X_INTERPOLATED) + 2 * np.pi, 2 * np.pi)\n",
    "                \n",
    "                MLT.append((ANGLE_IN_RADIANS * 24.0) / (2 * np.pi))\n",
    "                                \n",
    "                BLC_FLUX_0.append(np.interp(x = t_points, xp = [t1, t2], fp = [SAT[\"BLC_Flux\"][p, 0], SAT[\"BLC_Flux\"][p + 1, 0]], left=np.nan, right=np.nan))\n",
    "                BLC_FLUX_1.append(np.interp(x = t_points, xp = [t1, t2], fp = [SAT[\"BLC_Flux\"][p, 1], SAT[\"BLC_Flux\"][p + 1, 1]], left=np.nan, right=np.nan))\n",
    "                BLC_FLUX_2.append(np.interp(x = t_points, xp = [t1, t2], fp = [SAT[\"BLC_Flux\"][p, 2], SAT[\"BLC_Flux\"][p + 1, 2]], left=np.nan, right=np.nan))\n",
    "                BLC_FLUX_3.append(np.interp(x = t_points, xp = [t1, t2], fp = [SAT[\"BLC_Flux\"][p, 3], SAT[\"BLC_Flux\"][p + 1, 3]], left=np.nan, right=np.nan))\n",
    "                BLC_FLUX_4.append(np.interp(x = t_points, xp = [t1, t2], fp = [SAT[\"BLC_Flux\"][p, 4], SAT[\"BLC_Flux\"][p + 1, 4]], left=np.nan, right=np.nan))\n",
    "                BLC_FLUX_5.append(np.interp(x = t_points, xp = [t1, t2], fp = [SAT[\"BLC_Flux\"][p, 5], SAT[\"BLC_Flux\"][p + 1, 5]], left=np.nan, right=np.nan))\n",
    "                BLC_FLUX_6.append(np.interp(x = t_points, xp = [t1, t2], fp = [SAT[\"BLC_Flux\"][p, 6], SAT[\"BLC_Flux\"][p + 1, 6]], left=np.nan, right=np.nan))\n",
    "                BLC_FLUX_7.append(np.interp(x = t_points, xp = [t1, t2], fp = [SAT[\"BLC_Flux\"][p, 7], SAT[\"BLC_Flux\"][p + 1, 7]], left=np.nan, right=np.nan))\n",
    "\n",
    "        UNIX_TIME = np.hstack(UNIX_TIME)\n",
    "        LSTAR = np.hstack(LSTAR)\n",
    "        MLT = np.hstack(MLT)\n",
    "        BLC_FLUX_0 = np.hstack(BLC_FLUX_0)\n",
    "        BLC_FLUX_1 = np.hstack(BLC_FLUX_1)\n",
    "        BLC_FLUX_2 = np.hstack(BLC_FLUX_2)\n",
    "        BLC_FLUX_3 = np.hstack(BLC_FLUX_3)\n",
    "        BLC_FLUX_4 = np.hstack(BLC_FLUX_4)\n",
    "        BLC_FLUX_5 = np.hstack(BLC_FLUX_5)\n",
    "        BLC_FLUX_6 = np.hstack(BLC_FLUX_6)\n",
    "        BLC_FLUX_7 = np.hstack(BLC_FLUX_7)\n",
    "        BLC_FLUX = np.hstack([np.expand_dims(BLC_FLUX_0, axis = 1),\n",
    "                              np.expand_dims(BLC_FLUX_1, axis = 1),\n",
    "                              np.expand_dims(BLC_FLUX_2, axis = 1), \n",
    "                              np.expand_dims(BLC_FLUX_3, axis = 1),\n",
    "                              np.expand_dims(BLC_FLUX_4, axis = 1),\n",
    "                              np.expand_dims(BLC_FLUX_5, axis = 1),\n",
    "                              np.expand_dims(BLC_FLUX_6, axis = 1),\n",
    "                              np.expand_dims(BLC_FLUX_7, axis = 1)])\n",
    "        \n",
    "        POES[SATID] = {\"UNIX_TIME\" : UNIX_TIME, \n",
    "                        \"MLT\" : MLT, \n",
    "                        \"BLC_Flux\" : BLC_FLUX, \n",
    "                        \"LSTAR\" : LSTAR}\n",
    "    \n",
    "    if not POES:\n",
    "        print(f\"No POES satellite coverage found for year : {_year}\")\n",
    "        print(f\"SKIPPING YEAR : {_year}\")\n",
    "        continue\n",
    "    \n",
    "    refs.close()\n",
    "    \n",
    "    print(f\"Finished loading POES data for year : {_year}\")\n",
    "    \n",
    "    OMNI = chorus_machine_learning_helper.load_OMNI_year(_year)\n",
    "    SUPERMAG = chorus_machine_learning_helper.load_SUPERMAG_SME_year(_year)\n",
    "    \n",
    "    \n",
    "    #FINALLY FIND THE CONJUNCTIONS\n",
    "    \n",
    "    print(f\"Finding CONJUNCTIONS for year : {_year}\")\n",
    "    CONJUNCTIONS_YEAR = []\n",
    "    for SATID in POES:\n",
    "                \n",
    "        NUMBER_OF_RECORDS = len(POES[SATID][\"UNIX_TIME\"])\n",
    "        CONJUNCTIONS = []\n",
    "        \n",
    "        print(f\"Number of records: {NUMBER_OF_RECORDS} for POES SATELLITE: {SATID}\")\n",
    "                \n",
    "        for T in tqdm.tqdm(range(NUMBER_OF_RECORDS)):\n",
    "            \n",
    "            UNIX_TIME = POES[SATID][\"UNIX_TIME\"][T]\n",
    "            LSTAR = POES[SATID][\"LSTAR\"][T]\n",
    "            MLT = POES[SATID][\"MLT\"][T]\n",
    "            FLUX_SPECTRUM = POES[SATID][\"BLC_Flux\"][T, :]\n",
    "\n",
    "            for RBSP_PROBE in RBSP:\n",
    "                \n",
    "                TIME_RANGE = np.searchsorted(a = RBSP_PROBE[\"UNIX_TIME\"], v = [(UNIX_TIME - MAX_T_DIFF_SEC), (UNIX_TIME + MAX_T_DIFF_SEC)])\n",
    "\n",
    "                CANDIDATE_TIMES = []\n",
    "                CANDIDATE_LSTAR = []\n",
    "                CANDIDATE_DEL_MLT = []\n",
    "                CANDIDATE_UPPER_BAND = []\n",
    "                CANDIDATE_LOWER_BAND = []\n",
    "                \n",
    "                for POINT in range(TIME_RANGE[0], TIME_RANGE[1], 1):\n",
    "                    \n",
    "                    DEL_LSTAR = (LSTAR - RBSP_PROBE[\"LSTAR\"][POINT])\n",
    "                    DEL_MLT = np.min( [(max(MLT, RBSP_PROBE[\"MLT\"][POINT]) -  min(MLT, RBSP_PROBE[\"MLT\"][POINT])),\n",
    "                                      ((24 - max(MLT, RBSP_PROBE[\"MLT\"][POINT])) + (min(MLT, RBSP_PROBE[\"MLT\"][POINT]) - 0))])\n",
    "                    \n",
    "                    if (DEL_LSTAR**2 < MAX_L_DIFF**2) and (DEL_MLT**2 < MAX_MLT_DIFF**2):\n",
    "                                                \n",
    "                        CANDIDATE_TIMES.append(RBSP_PROBE[\"UNIX_TIME\"][POINT])\n",
    "                        CANDIDATE_LSTAR.append(RBSP_PROBE[\"LSTAR\"][POINT])\n",
    "                        CANDIDATE_DEL_MLT.append(DEL_MLT)\n",
    "                        CANDIDATE_UPPER_BAND.append(RBSP_PROBE[\"UPPER_BAND\"][POINT])\n",
    "                        CANDIDATE_LOWER_BAND.append(RBSP_PROBE[\"LOWER_BAND\"][POINT])\n",
    "                        \n",
    "                if len(CANDIDATE_TIMES) == 0:\n",
    "                    continue\n",
    "                \n",
    "                TIME_RANGE = np.searchsorted(a = SUPERMAG[\"UNIX_TIME\"], v = [(UNIX_TIME - MAX_T_DIFF_SEC), (UNIX_TIME + MAX_T_DIFF_SEC)])\n",
    "                AVG_SME = np.nanmean(SUPERMAG[\"SME\"][TIME_RANGE[0]:TIME_RANGE[1]])\n",
    "\n",
    "                TIME_RANGE = np.searchsorted(a = OMNI[\"UNIX_TIME\"], v = [(UNIX_TIME - MAX_T_DIFF_SEC), (UNIX_TIME + MAX_T_DIFF_SEC)])\n",
    "                AVG_AVG_B = np.nanmean(OMNI[\"AVG_B\"][TIME_RANGE[0]:TIME_RANGE[1]])\n",
    "                AVG_FLOW_SPEED = np.nanmean(OMNI[\"FLOW_SPEED\"][TIME_RANGE[0]:TIME_RANGE[1]])\n",
    "                AVG_PROTON_DENSITY = np.nanmean(OMNI[\"PROTON_DENSITY\"][TIME_RANGE[0]:TIME_RANGE[1]])\n",
    "                AVG_SYM_H = np.nanmean(OMNI[\"SYM_H\"][TIME_RANGE[0]:TIME_RANGE[1]])\n",
    "                \n",
    "                if np.isfinite(AVG_SME) & np.isfinite(AVG_AVG_B) & np.isfinite(AVG_FLOW_SPEED) & np.isfinite(AVG_PROTON_DENSITY) & np.isfinite(AVG_SYM_H):\n",
    "                    \n",
    "                    \n",
    "                    CONJUNCTION =  [UNIX_TIME, \n",
    "                                    LSTAR, \n",
    "                                    MLT,\n",
    "                                    *FLUX_SPECTRUM,\n",
    "                                    np.nanmean(CANDIDATE_TIMES), #TIME OF RBSP POINT CHOSEN\n",
    "                                    np.nanmean(CANDIDATE_LSTAR), #LSTAR OF RBSP POINT CHOSEN\n",
    "                                    np.nanmean(CANDIDATE_DEL_MLT), #DIFFERENCE IN MLT FOUND\n",
    "                                    np.nanmean(CANDIDATE_UPPER_BAND), #UPPER BAND CHORUS OBSERVED\n",
    "                                    np.nanmean(CANDIDATE_LOWER_BAND), #LOWER BAND CHORUS OBSERVED\n",
    "                                    AVG_SME, \n",
    "                                    AVG_AVG_B,\n",
    "                                    AVG_FLOW_SPEED, \n",
    "                                    AVG_PROTON_DENSITY,\n",
    "                                    AVG_SYM_H]\n",
    "                                                \n",
    "                    CONJUNCTIONS.append(CONJUNCTION)\n",
    "        \n",
    "\n",
    "        print(f\"Number of conjunctions: {len(CONJUNCTIONS)}\")\n",
    "        \n",
    "        CONJUNCTIONS_YEAR.extend(CONJUNCTIONS)\n",
    "    \n",
    "    \n",
    "    CONJUNCTIONS_TOTAL.extend(CONJUNCTIONS_YEAR)\n",
    "    \n",
    "    print(f\"Total number of conjunctions so far: {len(CONJUNCTIONS_TOTAL)}\")\n",
    "    \n",
    "CONJUNCTIONS_TO_BE_SAVED = np.vstack(CONJUNCTIONS_TOTAL)\n",
    "\n",
    "print(f\"Conjunctions to be saved: {CONJUNCTIONS_TO_BE_SAVED.shape}\")\n",
    "\n",
    "np.savez(f\"./../processed_data/chorus_neural_network/STAGE_2/{VERSION}/CONJUNCTIONS_{VERSION}_{FIELD_MODEL}.npz\", CONJUNCTIONS = CONJUNCTIONS_TO_BE_SAVED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stage 3, Look at the data and make sure its good enough, then remove solar proton events\n",
    "VERSION = \"v1a\"\n",
    "FIELD_MODEL = \"T89\"\n",
    "\n",
    "CONJUNCTIONS_REFS = np.load(f\"./../processed_data/chorus_neural_network/STAGE_2/{VERSION}/CONJUNCTIONS_{VERSION}_{FIELD_MODEL}.npz\")\n",
    "\n",
    "CONJUNCTIONS_TESTING = CONJUNCTIONS_REFS[\"CONJUNCTIONS\"]\n",
    "\n",
    "CONJUNCTIONS_REFS.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''CONJUNCTION =  [UNIX_TIME, \n",
    "                    LSTAR, \n",
    "                    MLT,\n",
    "                    *FLUX_SPECTRUM,\n",
    "                    TOTAL_TIME / NUM_CANDIDATES, #TIME OF RBSP POINT CHOSEN\n",
    "                    TOTAL_LSTAR / NUM_CANDIDATES, #LSTAR OF RBSP POINT CHOSEN\n",
    "                    TOTAL_DEL_MLT / NUM_CANDIDATES, #DIFFERENCE IN MLT FOUND\n",
    "                    TOTAL_UPPER_BAND / NUM_CANDIDATES, #UPPER BAND CHORUS OBSERVED\n",
    "                    TOTAL_LOWER_BAND / NUM_CANDIDATES, #LOWER BAND CHORUS OBSERVED\n",
    "                    AVG_SME, \n",
    "                    AVG_AVG_B,\n",
    "                    AVG_FLOW_SPEED, \n",
    "                    AVG_PROTON_DENSITY,\n",
    "                    AVG_SYM_H]'''\n",
    "\n",
    "C_POES_TIME = CONJUNCTIONS_TESTING[:, 0]\n",
    "C_POES_LSTAR = CONJUNCTIONS_TESTING[:, 1]\n",
    "C_POES_MLT = CONJUNCTIONS_TESTING[:, 2]\n",
    "C_POES_FLUX = CONJUNCTIONS_TESTING[:, 3:-10]\n",
    "C_RBSP_TIME = CONJUNCTIONS_TESTING[:, -10]\n",
    "C_RBSP_LSTAR = CONJUNCTIONS_TESTING[:, -9]\n",
    "C_RBSP_DEL_MLT = CONJUNCTIONS_TESTING[:, -8]\n",
    "C_RBSP_UPPER_BAND = CONJUNCTIONS_TESTING[:, -7]\n",
    "C_RBSP_LOWER_BAND = CONJUNCTIONS_TESTING[:, -6]\n",
    "C_AVG_SME = CONJUNCTIONS_TESTING[:, -5]\n",
    "C_AVG_AVG_B = CONJUNCTIONS_TESTING[:, -4]\n",
    "C_AVG_FLOW_SPEED = CONJUNCTIONS_TESTING[:, -3]\n",
    "C_AVG_PROTON_DENSITY = CONJUNCTIONS_TESTING[:, -2]\n",
    "C_AVG_SYM_H = CONJUNCTIONS_TESTING[:, -1]\n",
    "\n",
    "with open(f\"./../processed_data/chorus_neural_network/STAGE_2/{VERSION}/CONJUNCTIONS_{VERSION}_FIELD_MODEL.txt\", \"w\") as f:\n",
    "    f.write(\"\\nConjunctions:\\n\")\n",
    "    f.write(f\"Number of conjunctions: {CONJUNCTIONS_TESTING.shape[0]} [#]\\n\")\n",
    "    f.write(f\"Minimum RBSP Time: {np.min(C_RBSP_TIME)} [seconds since unix epoch]\\n\")\n",
    "    f.write(f\"Maximum RBSP Time: {np.max(C_RBSP_TIME)} [seconds since unix epoch]\\n\")\n",
    "    f.write(f\"Minimum POES Time: {np.min(C_POES_TIME)} [seconds since unix epoch]\\n\")\n",
    "    f.write(f\"Maximum POES Time: {np.max(C_POES_TIME)} [seconds since unix epoch]\\n\")\n",
    "    \n",
    "    f.write(f\"\\nL:\\n\")\n",
    "    f.write(f\"Mean Difference: {np.mean(C_POES_LSTAR - C_RBSP_LSTAR)} [L]\\n\")\n",
    "    f.write(f\"Standard deviation of Difference {np.std(C_POES_LSTAR - C_RBSP_LSTAR)} [L]\\n\")\n",
    "    f.write(f\"Minimum Absolute Difference : {np.min(np.abs(C_POES_LSTAR - C_RBSP_LSTAR))} [L]\\n\")\n",
    "    f.write(f\"Maximum Absolute Difference : {np.max(np.abs(C_POES_LSTAR - C_RBSP_LSTAR))} [L]\\n\")\n",
    "\n",
    "    f.write(\"\\nMLT: \\n\")\n",
    "    f.write(f\"Mean Absolute Difference: {np.mean(C_RBSP_DEL_MLT)} [MLT]\\n\")\n",
    "    f.write(f\"Standard deviation of Absolute Difference {np.std(C_RBSP_DEL_MLT)} [MLT]\\n\")\n",
    "    f.write(f\"Minimum Absolute Difference : {np.min(np.abs(C_RBSP_DEL_MLT))} [MLT]\\n\")\n",
    "    f.write(f\"Maximum Absolute Difference : {np.max(np.abs(C_RBSP_DEL_MLT))} [MLT]\\n\")\n",
    "\n",
    "    f.write(f\"\\nTime: \\n\")\n",
    "    f.write(f\"Mean Difference: {np.mean(C_POES_TIME - C_RBSP_TIME)} [s]\\n\")\n",
    "    f.write(f\"Standard deviation of Difference {np.std(C_POES_TIME - C_RBSP_TIME)} [s]\\n\")\n",
    "    f.write(f\"Minimum Absolute Difference : {np.min(np.abs(C_POES_TIME - C_RBSP_TIME))} [s]\\n\")\n",
    "    f.write(f\"Maximum Absolute Difference : {np.max(np.abs(C_POES_TIME - C_RBSP_TIME))} [s]\\n\")\n",
    "\n",
    "    f.write(f\"\\nUpper Band Chorus: \\n\")\n",
    "    f.write(f\"Mean: {np.mean(C_RBSP_UPPER_BAND)} [pT]\\n\")\n",
    "    f.write(f\"Standard Deviation: {np.std(C_RBSP_UPPER_BAND)} [pT]\\n\")\n",
    "    f.write(f\"Minimum: {np.min(C_RBSP_UPPER_BAND)} [pT]\\n\")\n",
    "    f.write(f\"Maximum: {np.max(C_RBSP_UPPER_BAND)} [pT]\\n\")\n",
    "    \n",
    "    f.write(f\"\\nLower Band Chorus: \\n\")\n",
    "    f.write(f\"Mean: {np.mean(C_RBSP_LOWER_BAND)} [pT]\\n\")\n",
    "    f.write(f\"Standard Deviation: {np.std(C_RBSP_LOWER_BAND)} [pT]\\n\")\n",
    "    f.write(f\"Minimum: {np.min(C_RBSP_LOWER_BAND)} [pT]\\n\")\n",
    "    f.write(f\"Maximum: {np.max(C_RBSP_LOWER_BAND)} [pT]\\n\")\n",
    "\n",
    "\n",
    "    f.write(f\"\\nSME: \\n\")\n",
    "    f.write(f\"Mean: {np.mean(C_AVG_SME)} [nT]\\n\")\n",
    "    f.write(f\"Standard Deviation: {np.std(C_AVG_SME)} [nT]\\n\")\n",
    "    f.write(f\"Minimum: {np.min(C_AVG_SME)} [nT]\\n\")\n",
    "    f.write(f\"Maximum: {np.max(C_AVG_SME)} [nT]\\n\")\n",
    "\n",
    "    f.write(f\"\\nAVG_B: \\n\")\n",
    "    f.write(f\"Mean: {np.mean(C_AVG_AVG_B)} [nT]\\n\")\n",
    "    f.write(f\"Standard Deviation: {np.std(C_AVG_AVG_B)} [nT]\\n\")\n",
    "    f.write(f\"Minimum: {np.min(C_AVG_AVG_B)} [nT]\\n\")\n",
    "    f.write(f\"Maximum: {np.max(C_AVG_AVG_B)} [nT]\\n\")\n",
    "\n",
    "    f.write(f\"\\nFlow Speed: \\n\")\n",
    "    f.write(f\"Mean: {np.mean(C_AVG_FLOW_SPEED)} [km/s]\\n\")\n",
    "    f.write(f\"Standard Deviation: {np.std(C_AVG_FLOW_SPEED)} [km/s]\\n\")\n",
    "    f.write(f\"Minimum: {np.min(C_AVG_FLOW_SPEED)} [km/s]\\n\")\n",
    "    f.write(f\"Maximum: {np.max(C_AVG_FLOW_SPEED)} [km/s]\\n\")\n",
    "    \n",
    "    f.write(f\"\\nProton Density: \\n\")\n",
    "    f.write(f\"Mean: {np.mean(C_AVG_PROTON_DENSITY)} [n/cc]\\n\")\n",
    "    f.write(f\"Standard Deviation: {np.std(C_AVG_PROTON_DENSITY)} [n/cc]\\n\")\n",
    "    f.write(f\"Minimum: {np.min(C_AVG_PROTON_DENSITY)} [n/cc]\\n\")\n",
    "    f.write(f\"Maximum: {np.max(C_AVG_PROTON_DENSITY)} [n/cc]\\n\")\n",
    "    \n",
    "    f.write(f\"\\nSYM_H: \\n\")\n",
    "    f.write(f\"Mean: {np.mean(C_AVG_SYM_H)} [nT]\\n\")\n",
    "    f.write(f\"Standard Deviation: {np.std(C_AVG_SYM_H)} [nT]\\n\")\n",
    "    f.write(f\"Minimum: {np.min(C_AVG_SYM_H)} [nT]\\n\")\n",
    "    f.write(f\"Maximum: {np.max(C_AVG_SYM_H)} [nT]\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean difference: -0.0012989820414318393\n",
      "Standard deviation of difference 0.062155422303787004\n",
      "Maximum difference : 0.09999985918294563\n"
     ]
    }
   ],
   "source": [
    "plt.title(\"RBSP - Closest POES L Shell Comparison\")\n",
    "plt.xlabel(\"RBSP L-Shell\")\n",
    "plt.ylabel(\"Closest POES L-Shell\")\n",
    "plt.hlines(y = 4, xmin=1, xmax=7, color=\"black\")\n",
    "plt.vlines(x = 4, ymin=1, ymax=7, color=\"black\")\n",
    "\n",
    "plt.scatter(C_RBSP_LSTAR, C_POES_LSTAR)\n",
    "\n",
    "print(f\"Mean difference: {np.mean(C_POES_LSTAR - C_RBSP_LSTAR)}\")\n",
    "print(f\"Standard deviation of difference {np.std(C_POES_LSTAR - C_RBSP_LSTAR)}\")\n",
    "print(f\"Maximum difference : {np.max(C_POES_LSTAR - C_RBSP_LSTAR)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stage 3 Continued, Removing solar proton events!\n",
    "\n",
    "VERSION = \"v1a\"\n",
    "FIELD_MODEL = \"T89\"\n",
    "\n",
    "CONJUNCTIONS_REFS = np.load(f\"./../processed_data/chorus_neural_network/STAGE_2/{VERSION}/CONJUNCTIONS_{VERSION}_{FIELD_MODEL}.npz\")\n",
    "\n",
    "CONJUNCTIONS = CONJUNCTIONS_REFS[\"CONJUNCTIONS\"]\n",
    "\n",
    "CONJUNCTIONS_REFS.close()\n",
    "\n",
    "SOLAR_PROTON_EVENT_LIST = pd.read_csv(f\"./../processed_data/chorus_neural_network/SOLAR_PROTON_EVENT_LIST_1976_2024.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting shape of conjunctions list: (888864, 21)\n",
      "Removing high energy solar proton events!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/309 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 309/309 [00:05<00:00, 60.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished removing high energy solar proton events!\n",
      "Saving!\n",
      "Creating documentation of dataset!\n",
      "Finished!\n",
      "Ending shape of conjunctions : (882645, 21)\n"
     ]
    }
   ],
   "source": [
    "'''CONJUNCTION =  [UNIX_TIME, \n",
    "                    L, \n",
    "                    MLT,\n",
    "                    *FLUX_SPECTRUM,\n",
    "                    candidate[0], #TIME\n",
    "                    candidate[1], #L\n",
    "                    candidate[2], #MLT\n",
    "                    candidate[3], #del_MLT\n",
    "                    candidate[4], #CHORUS\n",
    "                    AVG_SME, \n",
    "                    AVG_AVG_B,\n",
    "                    AVG_FLOW_SPEED, \n",
    "                    AVG_PROTON_DENSITY,\n",
    "                    AVG_SYM_H]'''\n",
    "\n",
    "\n",
    "order_to_sort_conjunctions = np.argsort(CONJUNCTIONS[:, 0]) #Sorted based on POES Conjunction time!\n",
    "SORTED_CONJUNCTIONS = CONJUNCTIONS[order_to_sort_conjunctions, :]\n",
    "\n",
    "print(f\"Starting shape of conjunctions list: {SORTED_CONJUNCTIONS.shape}\")\n",
    "\n",
    "SORTED_POES_CONJUNCTION_TIMES = SORTED_CONJUNCTIONS[:, 0]\n",
    "\n",
    "START_OF_SEP_EVENTS_UTC = SOLAR_PROTON_EVENT_LIST[\"START\"]\n",
    "END_OF_SEP_EVENTS_UTC = SOLAR_PROTON_EVENT_LIST[\"END\"]\n",
    "ZIPPED_EVENTS = list(zip(START_OF_SEP_EVENTS_UTC, END_OF_SEP_EVENTS_UTC))\n",
    "\n",
    "print(f\"Removing high energy solar proton events!\")\n",
    "\n",
    "for SEP_EVENT in tqdm.tqdm(range(len(ZIPPED_EVENTS))):\n",
    "    \n",
    "    START = ZIPPED_EVENTS[SEP_EVENT][0].strip()\n",
    "    END = ZIPPED_EVENTS[SEP_EVENT][1].strip()\n",
    "    \n",
    "    START_YMDHMS = {'year': int(START[0:4]), 'month': int(START[5:7]), 'day': int(START[8:10]), 'hour': int(START[11:13]), 'minute': int(START[13:15]), 'second': 0}\n",
    "    END_YMDHMS = {'year': int(END[0:4]), 'month': int(END[5:7]), 'day': int(END[8:10]), 'hour': int(END[11:13]), 'minute': int(END[13:15]), 'second': 0}\n",
    "    \n",
    "    START_UNIX = astropy.time.Time(START_YMDHMS, format=\"ymdhms\", scale='utc').unix\n",
    "    END_UNIX = astropy.time.Time(END_YMDHMS, format=\"ymdhms\", scale='utc').unix\n",
    "\n",
    "    RANGE_TO_REMOVE = np.searchsorted(a = SORTED_POES_CONJUNCTION_TIMES, v = [START_UNIX, END_UNIX])\n",
    "    \n",
    "    SORTED_CONJUNCTIONS = np.vstack((SORTED_CONJUNCTIONS[0:RANGE_TO_REMOVE[0], :], SORTED_CONJUNCTIONS[RANGE_TO_REMOVE[1]:, :]))\n",
    "\n",
    "print(f\"Finished removing high energy solar proton events!\")\n",
    "\n",
    "print(f\"Saving!\")\n",
    "\n",
    "CLEANED_CONJUNCTIONS = SORTED_CONJUNCTIONS #Should be cleaned by now!\n",
    "\n",
    "np.savez(f\"./../processed_data/chorus_neural_network/STAGE_3/{VERSION}/CLEANED_CONJUNCTIONS_{VERSION}_{FIELD_MODEL}.npz\",\n",
    "        CONJUNCTIONS=CLEANED_CONJUNCTIONS)\n",
    "\n",
    "C_POES_TIME = CLEANED_CONJUNCTIONS[:, 0]\n",
    "C_POES_LSTAR = CLEANED_CONJUNCTIONS[:, 1]\n",
    "C_POES_MLT = CLEANED_CONJUNCTIONS[:, 2]\n",
    "C_POES_FLUX = CLEANED_CONJUNCTIONS[:, 3:-10]\n",
    "C_RBSP_TIME = CLEANED_CONJUNCTIONS[:, -10]\n",
    "C_RBSP_LSTAR = CLEANED_CONJUNCTIONS[:, -9]\n",
    "C_RBSP_DEL_MLT = CLEANED_CONJUNCTIONS[:, -8]\n",
    "C_RBSP_UPPER_BAND = CLEANED_CONJUNCTIONS[:, -7]\n",
    "C_RBSP_LOWER_BAND = CLEANED_CONJUNCTIONS[:, -6]\n",
    "C_AVG_SME = CLEANED_CONJUNCTIONS[:, -5]\n",
    "C_AVG_AVG_B = CLEANED_CONJUNCTIONS[:, -4]\n",
    "C_AVG_FLOW_SPEED = CLEANED_CONJUNCTIONS[:, -3]\n",
    "C_AVG_PROTON_DENSITY = CLEANED_CONJUNCTIONS[:, -2]\n",
    "C_AVG_SYM_H = CLEANED_CONJUNCTIONS[:, -1]\n",
    "\n",
    "print(f\"Creating documentation of dataset!\")\n",
    "\n",
    "\n",
    "with open(f\"./../processed_data/chorus_neural_network/STAGE_3/{VERSION}/CLEANED_CONJUNCTIONS_{VERSION}_{FIELD_MODEL}.txt\", \"w\") as f:\n",
    "    f.write(\"\\nConjunctions:\\n\")\n",
    "    f.write(f\"Number of conjunctions: {CLEANED_CONJUNCTIONS.shape[0]} [#]\\n\")\n",
    "    f.write(f\"Number lost from cleaning solar proton events: {CONJUNCTIONS.shape[0] - CLEANED_CONJUNCTIONS.shape[0]} [#]\\n\")\n",
    "    f.write(f\"Minimum RBSP Time: {np.min(C_RBSP_TIME)} [seconds since unix epoch]\\n\")\n",
    "    f.write(f\"Maximum RBSP Time: {np.max(C_RBSP_TIME)} [seconds since unix epoch]\\n\")\n",
    "    f.write(f\"Minimum POES Time: {np.min(C_POES_TIME)} [seconds since unix epoch]\\n\")\n",
    "    f.write(f\"Maximum POES Time: {np.max(C_POES_TIME)} [seconds since unix epoch]\\n\")\n",
    "    \n",
    "    f.write(f\"\\nL:\\n\")\n",
    "    f.write(f\"Mean Difference: {np.mean(C_POES_LSTAR - C_RBSP_LSTAR)} [L]\\n\")\n",
    "    f.write(f\"Standard deviation of Difference {np.std(C_POES_LSTAR - C_RBSP_LSTAR)} [L]\\n\")\n",
    "    f.write(f\"Minimum Absolute Difference : {np.min(np.abs(C_POES_LSTAR - C_RBSP_LSTAR))} [L]\\n\")\n",
    "    f.write(f\"Maximum Absolute Difference : {np.max(np.abs(C_POES_LSTAR - C_RBSP_LSTAR))} [L]\\n\")\n",
    "\n",
    "    f.write(\"\\nMLT: \\n\")\n",
    "    f.write(f\"Mean Absolute Difference: {np.mean(C_RBSP_DEL_MLT)} [MLT]\\n\")\n",
    "    f.write(f\"Standard deviation of Absolute Difference {np.std(C_RBSP_DEL_MLT)} [MLT]\\n\")\n",
    "    f.write(f\"Minimum Absolute Difference : {np.min(np.abs(C_RBSP_DEL_MLT))} [MLT]\\n\")\n",
    "    f.write(f\"Maximum Absolute Difference : {np.max(np.abs(C_RBSP_DEL_MLT))} [MLT]\\n\")\n",
    "\n",
    "    f.write(f\"\\nTime: \\n\")\n",
    "    f.write(f\"Mean Difference: {np.mean(C_POES_TIME - C_RBSP_TIME)} [s]\\n\")\n",
    "    f.write(f\"Standard deviation of Difference {np.std(C_POES_TIME - C_RBSP_TIME)} [s]\\n\")\n",
    "    f.write(f\"Minimum Absolute Difference : {np.min(np.abs(C_POES_TIME - C_RBSP_TIME))} [s]\\n\")\n",
    "    f.write(f\"Maximum Absolute Difference : {np.max(np.abs(C_POES_TIME - C_RBSP_TIME))} [s]\\n\")\n",
    "\n",
    "    f.write(f\"\\nUpper Band Chorus: \\n\")\n",
    "    f.write(f\"Mean: {np.mean(C_RBSP_UPPER_BAND)} [pT]\\n\")\n",
    "    f.write(f\"Standard Deviation: {np.std(C_RBSP_UPPER_BAND)} [pT]\\n\")\n",
    "    f.write(f\"Minimum: {np.min(C_RBSP_UPPER_BAND)} [pT]\\n\")\n",
    "    f.write(f\"Maximum: {np.max(C_RBSP_UPPER_BAND)} [pT]\\n\")\n",
    "    \n",
    "    f.write(f\"\\nLower Band Chorus: \\n\")\n",
    "    f.write(f\"Mean: {np.mean(C_RBSP_LOWER_BAND)} [pT]\\n\")\n",
    "    f.write(f\"Standard Deviation: {np.std(C_RBSP_LOWER_BAND)} [pT]\\n\")\n",
    "    f.write(f\"Minimum: {np.min(C_RBSP_LOWER_BAND)} [pT]\\n\")\n",
    "    f.write(f\"Maximum: {np.max(C_RBSP_LOWER_BAND)} [pT]\\n\")\n",
    "\n",
    "\n",
    "    f.write(f\"\\nSME: \\n\")\n",
    "    f.write(f\"Mean: {np.mean(C_AVG_SME)} [nT]\\n\")\n",
    "    f.write(f\"Standard Deviation: {np.std(C_AVG_SME)} [nT]\\n\")\n",
    "    f.write(f\"Minimum: {np.min(C_AVG_SME)} [nT]\\n\")\n",
    "    f.write(f\"Maximum: {np.max(C_AVG_SME)} [nT]\\n\")\n",
    "\n",
    "    f.write(f\"\\nAVG_B: \\n\")\n",
    "    f.write(f\"Mean: {np.mean(C_AVG_AVG_B)} [nT]\\n\")\n",
    "    f.write(f\"Standard Deviation: {np.std(C_AVG_AVG_B)} [nT]\\n\")\n",
    "    f.write(f\"Minimum: {np.min(C_AVG_AVG_B)} [nT]\\n\")\n",
    "    f.write(f\"Maximum: {np.max(C_AVG_AVG_B)} [nT]\\n\")\n",
    "\n",
    "    f.write(f\"\\nFlow Speed: \\n\")\n",
    "    f.write(f\"Mean: {np.mean(C_AVG_FLOW_SPEED)} [km/s]\\n\")\n",
    "    f.write(f\"Standard Deviation: {np.std(C_AVG_FLOW_SPEED)} [km/s]\\n\")\n",
    "    f.write(f\"Minimum: {np.min(C_AVG_FLOW_SPEED)} [km/s]\\n\")\n",
    "    f.write(f\"Maximum: {np.max(C_AVG_FLOW_SPEED)} [km/s]\\n\")\n",
    "    \n",
    "    f.write(f\"\\nProton Density: \\n\")\n",
    "    f.write(f\"Mean: {np.mean(C_AVG_PROTON_DENSITY)} [n/cc]\\n\")\n",
    "    f.write(f\"Standard Deviation: {np.std(C_AVG_PROTON_DENSITY)} [n/cc]\\n\")\n",
    "    f.write(f\"Minimum: {np.min(C_AVG_PROTON_DENSITY)} [n/cc]\\n\")\n",
    "    f.write(f\"Maximum: {np.max(C_AVG_PROTON_DENSITY)} [n/cc]\\n\")\n",
    "    \n",
    "    f.write(f\"\\nSYM_H: \\n\")\n",
    "    f.write(f\"Mean: {np.mean(C_AVG_SYM_H)} [nT]\\n\")\n",
    "    f.write(f\"Standard Deviation: {np.std(C_AVG_SYM_H)} [nT]\\n\")\n",
    "    f.write(f\"Minimum: {np.min(C_AVG_SYM_H)} [nT]\\n\")\n",
    "    f.write(f\"Maximum: {np.max(C_AVG_SYM_H)} [nT]\\n\")\n",
    "\n",
    "print(f\"Finished!\")\n",
    "print(f\"Ending shape of conjunctions : {CLEANED_CONJUNCTIONS.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stage 4, Create datasets used for training, testing, etc\n",
    "\n",
    "VERSION = \"v1a\"\n",
    "FIELD_MODEL = \"T89\"\n",
    "MODEL_TYPE = \"UPPER_BAND\"\n",
    "\n",
    "\n",
    "CONJUNCTIONS_REFS = np.load(f\"./../processed_data/chorus_neural_network/STAGE_3/{VERSION}/CLEANED_CONJUNCTIONS_{VERSION}_{FIELD_MODEL}.npz\")\n",
    "\n",
    "CONJUNCTIONS = CONJUNCTIONS_REFS[\"CONJUNCTIONS\"]\n",
    "\n",
    "CONJUNCTIONS_REFS.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(882645, 21)\n",
      "Number of conjunctions between feb1 and apr1 2013: 16887\n",
      "(865758, 1)\n",
      "(865758, 1)\n",
      "(865758, 1)\n",
      "(865758, 1)\n",
      "(865758, 1)\n",
      "(865758, 1)\n",
      "(865758, 1)\n",
      "(865758, 1)\n",
      "(865758, 8)\n",
      "(865758, 1)\n",
      "(865758, 1)\n",
      "(865758, 1)\n",
      "(865758, 1)\n",
      "(865758, 1)\n",
      "(16887, 1)\n",
      "(16887, 1)\n",
      "(16887, 1)\n",
      "(16887, 1)\n",
      "(16887, 1)\n",
      "(16887, 1)\n",
      "(16887, 1)\n",
      "(16887, 1)\n",
      "(16887, 8)\n",
      "(16887, 1)\n",
      "(16887, 1)\n",
      "(16887, 1)\n",
      "(16887, 1)\n",
      "(16887, 1)\n"
     ]
    }
   ],
   "source": [
    "print(CONJUNCTIONS.shape)\n",
    "\n",
    "C_RBSP_TIME = CONJUNCTIONS[:, -10]\n",
    "\n",
    "jan1_unix = astropy.time.Time({\"year\":2016, \"month\":1, \"day\":1, \"hour\":0, \"minute\":0, \"second\":0}, format=\"ymdhms\", scale=\"utc\").unix\n",
    "apr1_unix = astropy.time.Time({\"year\":2016, \"month\":4, \"day\":1, \"hour\":0, \"minute\":0, \"second\":0}, format=\"ymdhms\", scale=\"utc\").unix\n",
    "\n",
    "where_between_feb1_apr1_2013 = (jan1_unix < C_RBSP_TIME) & (C_RBSP_TIME < apr1_unix)\n",
    "\n",
    "train_test_subset_selected = ~where_between_feb1_apr1_2013\n",
    "validation_subset_selected = where_between_feb1_apr1_2013\n",
    "\n",
    "print(f\"Number of conjunctions between feb1 and apr1 2013: {np.count_nonzero(where_between_feb1_apr1_2013)}\")\n",
    "\n",
    "C_POES_TIME = np.expand_dims(CONJUNCTIONS[train_test_subset_selected, 0], axis = 1)\n",
    "C_POES_LSTAR = np.expand_dims(CONJUNCTIONS[train_test_subset_selected, 1], axis = 1)\n",
    "C_POES_MLT = np.expand_dims(CONJUNCTIONS[train_test_subset_selected, 2], axis = 1)\n",
    "C_POES_FLUX = CONJUNCTIONS[train_test_subset_selected, 3:-10]\n",
    "C_RBSP_TIME = np.expand_dims(CONJUNCTIONS[train_test_subset_selected, -10], axis = 1)\n",
    "C_RBSP_LSTAR = np.expand_dims(CONJUNCTIONS[train_test_subset_selected, -9], axis = 1)\n",
    "C_RBSP_DEL_MLT = np.expand_dims(CONJUNCTIONS[train_test_subset_selected, -8], axis = 1)\n",
    "C_RBSP_UPPER_BAND = np.expand_dims(CONJUNCTIONS[train_test_subset_selected, -7], axis = 1)\n",
    "C_RBSP_LOWER_BAND = np.expand_dims(CONJUNCTIONS[train_test_subset_selected, -6], axis = 1)\n",
    "C_AVG_SME = np.expand_dims(CONJUNCTIONS[train_test_subset_selected, -5], axis = 1)\n",
    "C_AVG_AVG_B = np.expand_dims(CONJUNCTIONS[train_test_subset_selected, -4], axis = 1)\n",
    "C_AVG_FLOW_SPEED = np.expand_dims(CONJUNCTIONS[train_test_subset_selected, -3], axis = 1)\n",
    "C_AVG_PROTON_DENSITY = np.expand_dims(CONJUNCTIONS[train_test_subset_selected, -2], axis = 1)\n",
    "C_AVG_SYM_H = np.expand_dims(CONJUNCTIONS[train_test_subset_selected, -1], axis = 1)\n",
    "\n",
    "print(C_RBSP_TIME.shape)\n",
    "print(C_RBSP_LSTAR.shape)\n",
    "print(C_RBSP_UPPER_BAND.shape)\n",
    "print(C_RBSP_LOWER_BAND.shape)\n",
    "print(C_POES_TIME.shape)\n",
    "print(C_POES_LSTAR.shape)\n",
    "print(C_POES_MLT.shape)\n",
    "print(C_RBSP_DEL_MLT.shape)\n",
    "print(C_POES_FLUX.shape)\n",
    "print(C_AVG_SME.shape)\n",
    "print(C_AVG_AVG_B.shape)\n",
    "print(C_AVG_FLOW_SPEED.shape)\n",
    "print(C_AVG_PROTON_DENSITY.shape)\n",
    "print(C_AVG_SYM_H.shape)\n",
    "\n",
    "mean_LSTAR = np.nanmean(C_POES_LSTAR)\n",
    "std_LSTAR = np.std(C_POES_LSTAR)\n",
    "\n",
    "mean_fluxes = np.expand_dims(np.nanmean(np.log(C_POES_FLUX), axis = 0), axis=0)\n",
    "std_fluxes = np.expand_dims(np.nanstd(np.log(C_POES_FLUX), axis = 0), axis = 0)\n",
    "\n",
    "mean_sme = np.nanmean(C_AVG_SME)\n",
    "std_sme = np.std(C_AVG_SME)\n",
    "\n",
    "mean_avg_b = np.nanmean(C_AVG_AVG_B)\n",
    "std_avg_b = np.std(C_AVG_AVG_B)\n",
    "\n",
    "mean_flow_speed = np.nanmean(C_AVG_FLOW_SPEED)\n",
    "std_flow_speed = np.std(C_AVG_FLOW_SPEED)\n",
    "\n",
    "mean_avg_proton_density = np.nanmean(C_AVG_PROTON_DENSITY)\n",
    "std_avg_proton_density = np.std(C_AVG_PROTON_DENSITY)\n",
    "\n",
    "mean_avg_sym_h = np.nanmean(C_AVG_SYM_H)\n",
    "std_avg_sym_h = np.std(C_AVG_SYM_H)\n",
    "\n",
    "FEATURES = np.hstack(((C_POES_LSTAR - mean_LSTAR) / std_LSTAR, \n",
    "                      np.sin((C_POES_MLT * 2 * np.pi) / 24.0), \n",
    "                      np.cos((C_POES_MLT * 2 * np.pi) / 24.0),\n",
    "                      ((np.log(C_POES_FLUX) - mean_fluxes) / std_fluxes)[:, [0, -1]],\n",
    "                      (C_AVG_SME - mean_sme)  / std_sme,\n",
    "                      (C_AVG_AVG_B - mean_avg_b) / std_avg_b,\n",
    "                      (C_AVG_FLOW_SPEED - mean_flow_speed) / std_flow_speed,\n",
    "                      (C_AVG_PROTON_DENSITY - mean_avg_proton_density) / std_avg_proton_density,\n",
    "                      (C_AVG_SYM_H - mean_avg_sym_h) / std_avg_sym_h))\n",
    "\n",
    "\n",
    "#SMALL VALIDATION SET:\n",
    "C_POES_TIME_V = np.expand_dims(CONJUNCTIONS[validation_subset_selected, 0], axis = 1)\n",
    "C_POES_L_V = np.expand_dims(CONJUNCTIONS[validation_subset_selected, 1], axis = 1)\n",
    "C_POES_MLT_V = np.expand_dims(CONJUNCTIONS[validation_subset_selected, 2], axis = 1)\n",
    "C_POES_FLUX_V = CONJUNCTIONS[validation_subset_selected, 3:-10]\n",
    "C_RBSP_TIME_V = np.expand_dims(CONJUNCTIONS[validation_subset_selected, -10], axis = 1)\n",
    "C_RBSP_L_V = np.expand_dims(CONJUNCTIONS[validation_subset_selected, -9], axis = 1)\n",
    "C_RBSP_DEL_MLT_V = np.expand_dims(CONJUNCTIONS[validation_subset_selected, -8], axis = 1)\n",
    "C_RBSP_UPPER_BAND_V = np.expand_dims(CONJUNCTIONS[validation_subset_selected, -7], axis = 1)\n",
    "C_RBSP_LOWER_BAND_V = np.expand_dims(CONJUNCTIONS[validation_subset_selected, -6], axis = 1)\n",
    "C_AVG_SME_V = np.expand_dims(CONJUNCTIONS[validation_subset_selected, -5], axis = 1)\n",
    "C_AVG_AVG_B_V = np.expand_dims(CONJUNCTIONS[validation_subset_selected, -4], axis = 1)\n",
    "C_AVG_FLOW_SPEED_V = np.expand_dims(CONJUNCTIONS[validation_subset_selected, -3], axis = 1)\n",
    "C_AVG_PROTON_DENSITY_V = np.expand_dims(CONJUNCTIONS[validation_subset_selected, -2], axis = 1)\n",
    "C_AVG_SYM_H_V = np.expand_dims(CONJUNCTIONS[validation_subset_selected, -1], axis = 1)\n",
    "\n",
    "print(C_RBSP_TIME_V.shape)\n",
    "print(C_RBSP_L_V.shape)\n",
    "print(C_RBSP_UPPER_BAND_V.shape)\n",
    "print(C_RBSP_LOWER_BAND_V.shape)\n",
    "print(C_POES_TIME_V.shape)\n",
    "print(C_POES_L_V.shape)\n",
    "print(C_POES_MLT_V.shape)\n",
    "print(C_RBSP_DEL_MLT_V.shape)\n",
    "print(C_POES_FLUX_V.shape)\n",
    "print(C_AVG_SME_V.shape)\n",
    "print(C_AVG_AVG_B_V.shape)\n",
    "print(C_AVG_FLOW_SPEED_V.shape)\n",
    "print(C_AVG_PROTON_DENSITY_V.shape)\n",
    "print(C_AVG_SYM_H_V.shape)\n",
    "\n",
    "\n",
    "VALIDATION_FEATURES = np.hstack(((C_POES_L_V - mean_LSTAR) / std_LSTAR, \n",
    "                                np.sin((C_POES_MLT_V * 2 * np.pi) / 24.0), \n",
    "                                np.cos((C_POES_MLT_V * 2 * np.pi) / 24.0),\n",
    "                                ((np.log(C_POES_FLUX_V) - mean_fluxes) / std_fluxes)[:, [0, -1]],\n",
    "                                (C_AVG_SME_V - mean_sme) / std_sme,\n",
    "                                (C_AVG_AVG_B_V - mean_avg_b) / std_avg_b,\n",
    "                                (C_AVG_FLOW_SPEED_V - mean_flow_speed) / std_flow_speed,\n",
    "                                (C_AVG_PROTON_DENSITY_V - mean_avg_proton_density) / std_avg_proton_density,\n",
    "                                (C_AVG_SYM_H_V - mean_avg_sym_h) / std_avg_sym_h))\n",
    "        \n",
    "if MODEL_TYPE == \"UPPER_BAND\":\n",
    "        MODEL_LABELS = C_RBSP_UPPER_BAND\n",
    "        MODEL_LABELS_V = C_RBSP_UPPER_BAND_V\n",
    "elif MODEL_TYPE == \"LOWER_BAND\":\n",
    "        MODEL_LABELS = C_RBSP_LOWER_BAND\n",
    "        MODEL_LABELS_V = C_RBSP_LOWER_BAND_V\n",
    "\n",
    "np.savez(f\"./../processed_data/chorus_neural_network/STAGE_4/{VERSION}/MODEL_READY_DATA_{VERSION}_{FIELD_MODEL}_{MODEL_TYPE}.npz\",\n",
    "        FEATURES = FEATURES,\n",
    "        LABELS = MODEL_LABELS,\n",
    "        VALIDATION_FEATURES = VALIDATION_FEATURES,\n",
    "        VALIDATION_LABELS = MODEL_LABELS_V,\n",
    "        TRAINING_MLT = C_POES_MLT,\n",
    "        MEAN_FLUXES = mean_fluxes,\n",
    "        STD_FLUXES = std_fluxes,\n",
    "        MEAN_SME = mean_sme,\n",
    "        STD_SME = std_sme,\n",
    "        MEAN_AVG_B = mean_avg_b,\n",
    "        STD_AVG_B = std_avg_b,\n",
    "        MEAN_FLOW_SPEED = mean_flow_speed,\n",
    "        STD_FLOW_SPEED = std_flow_speed,\n",
    "        MEAN_AVG_PROTON_DENSITY = mean_avg_proton_density,\n",
    "        STD_AVG_PROTON_DENSITY = std_avg_proton_density,\n",
    "        MEAN_AVG_SYM_H = mean_avg_sym_h,\n",
    "        STD_AVG_SYM_H = std_avg_sym_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ResearchPy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
