{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# caution: path[0] is reserved for script path (or '' in REPL).\n",
    "sys.path.insert(1, os.path.abspath(\"./../src\"))\n",
    "\n",
    "\n",
    "import datetime\n",
    "import importlib\n",
    "\n",
    "import astropy.time\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "from cdflib.epochs_astropy import CDFAstropy as cdfepoch\n",
    "from dateutil import rrule\n",
    "import seaborn as sns\n",
    "\n",
    "import data_loader\n",
    "import rbsp_chorus_tool\n",
    "\n",
    "importlib.reload(data_loader)\n",
    "importlib.reload(rbsp_chorus_tool)\n",
    "\n",
    "pdata_folder = os.path.abspath(r\"./../processed_data/chorus_neural_network/\")\n",
    "\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAGE 0 DATA VERIFICATION FOR POES LSTAR CALCULATIONS\n",
    "\n",
    "mpe_folder = os.path.join(pdata_folder, \"STAGE_0\", \"MPE_DATA_PREPROCESSED_WITH_LSTAR\")\n",
    "\n",
    "year = 2012\n",
    "SATID = \"m02\"\n",
    "\n",
    "refs = np.load(\n",
    "    file=os.path.join(\n",
    "        mpe_folder,\n",
    "        rf\"MPE_PREPROCESSED_DATA_T89_{year}.npz\",\n",
    "    ),\n",
    "    allow_pickle=True,\n",
    ")\n",
    "\n",
    "DATA = refs[\"DATA\"].flatten()[0]\n",
    "SAT = DATA[SATID]\n",
    "\n",
    "dt_for_all = np.array([datetime.datetime.fromtimestamp(t) for t in SAT[\"UNIX_TIME\"]])\n",
    "\n",
    "plt.plot(dt_for_all, SAT[\"Lstar\"], label=\"L*\", color=\"red\", marker=\"*\")\n",
    "plt.plot(dt_for_all, SAT[\"L\"], label=\"IGRF Lm\", color=\"black\", marker=\"*\")\n",
    "plt.ylabel(\"|L|\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.title(f\"Some Orbits for {SATID} in {year}\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA VERIFICATION RBSP L-STAR DATA CALCULATIONS\n",
    "\n",
    "lstar_folder = os.path.join(pdata_folder, \"STAGE_1\", \"Lstar\")\n",
    "\n",
    "year = 2012\n",
    "sat = \"a\"\n",
    "refs = np.load(\n",
    "    file=os.path.join(lstar_folder, rf\"RBSP_{sat.upper()}_T89_{year}.npz\"),\n",
    "    allow_pickle=True,\n",
    ")\n",
    "\n",
    "\n",
    "dates = np.array([datetime.datetime.fromtimestamp(t) for t in refs[\"UNIX_TIME\"]])\n",
    "\n",
    "\n",
    "#plt.plot(dates, refs[\"Lstar\"], label=\"L* at EQ\")\n",
    "#plt.plot(dates, refs[\"LSTAR_LOCAL\"], label=\"L* Local\")\n",
    "#plt.xlabel(\"Time (UTC)\")\n",
    "#plt.ylabel(\"L*\")\n",
    "#plt.legend()\n",
    "\n",
    "plt.plot(dates, refs[\"MLAT\"], label=\"MLAT\")\n",
    "plt.xlabel(\"Time (UTC)\")\n",
    "plt.ylabel(\"MLAT\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolate POES data cause I forgot to interpolate it before with the nans included\n",
    "\n",
    "for _year in range(2012, 2021):\n",
    "\n",
    "    POES = {}\n",
    "\n",
    "    refs = np.load(\n",
    "        rf\"./../processed_data/chorus_neural_network/STAGE_0/MPE_DATA_PREPROCESSED_WITH_LSTAR/MPE_PREPROCESSED_DATA_T89_{_year}.npz\",\n",
    "        allow_pickle=True,\n",
    "    )\n",
    "    POES_DATA = refs[\"DATA\"].flatten()[0]\n",
    "\n",
    "    for SATID in POES_DATA:\n",
    "\n",
    "        SAT = POES_DATA[SATID]\n",
    "\n",
    "        UNIX_TIME = []\n",
    "        L = []\n",
    "        MLT = []\n",
    "        BLC_FLUX_0 = []\n",
    "        BLC_FLUX_1 = []\n",
    "        BLC_FLUX_2 = []\n",
    "        BLC_FLUX_3 = []\n",
    "        BLC_FLUX_4 = []\n",
    "        BLC_FLUX_5 = []\n",
    "        BLC_FLUX_6 = []\n",
    "        BLC_FLUX_7 = []\n",
    "\n",
    "        for p in tqdm.tqdm(range(len(SAT[\"UNIX_TIME\"]) - 1)):\n",
    "\n",
    "            t1 = SAT[\"UNIX_TIME\"][p]\n",
    "            t2 = SAT[\"UNIX_TIME\"][p + 1]\n",
    "\n",
    "            if t2 - t1 < 30.0:\n",
    "\n",
    "                t_points = np.arange(t1, t2 + 1, step=1, dtype=np.float64)\n",
    "\n",
    "                UNIX_TIME.append(t_points)\n",
    "                L.append(\n",
    "                    np.interp(\n",
    "                        x=t_points,\n",
    "                        xp=[t1, t2],\n",
    "                        fp=[SAT[\"L\"][p], SAT[\"L\"][p + 1]],\n",
    "                        left=np.nan,\n",
    "                        right=np.nan,\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                X_INTERPOLATED = np.interp(\n",
    "                    t_points,\n",
    "                    xp=[t1, t2],\n",
    "                    fp=[\n",
    "                        np.cos(SAT[\"MLT\"][p] * 2 * np.pi / 24.0),\n",
    "                        np.cos(SAT[\"MLT\"][p + 1] * 2 * np.pi / 24.0),\n",
    "                    ],\n",
    "                    left=np.nan,\n",
    "                    right=np.nan,\n",
    "                )\n",
    "                Y_INTERPOLATED = np.interp(\n",
    "                    t_points,\n",
    "                    xp=[t1, t2],\n",
    "                    fp=[\n",
    "                        np.sin(SAT[\"MLT\"][p] * 2 * np.pi / 24.0),\n",
    "                        np.sin(SAT[\"MLT\"][p + 1] * 2 * np.pi / 24.0),\n",
    "                    ],\n",
    "                    left=np.nan,\n",
    "                    right=np.nan,\n",
    "                )\n",
    "                ANGLE_IN_RADIANS = np.mod(\n",
    "                    np.arctan2(Y_INTERPOLATED, X_INTERPOLATED) + 2 * np.pi, 2 * np.pi\n",
    "                )\n",
    "\n",
    "                MLT.append((ANGLE_IN_RADIANS * 24.0) / (2 * np.pi))\n",
    "\n",
    "                BLC_FLUX_0.append(\n",
    "                    np.interp(\n",
    "                        x=t_points,\n",
    "                        xp=[t1, t2],\n",
    "                        fp=[SAT[\"BLC_Flux\"][p, 0], SAT[\"BLC_Flux\"][p + 1, 0]],\n",
    "                        left=np.nan,\n",
    "                        right=np.nan,\n",
    "                    )\n",
    "                )\n",
    "                BLC_FLUX_1.append(\n",
    "                    np.interp(\n",
    "                        x=t_points,\n",
    "                        xp=[t1, t2],\n",
    "                        fp=[SAT[\"BLC_Flux\"][p, 1], SAT[\"BLC_Flux\"][p + 1, 1]],\n",
    "                        left=np.nan,\n",
    "                        right=np.nan,\n",
    "                    )\n",
    "                )\n",
    "                BLC_FLUX_2.append(\n",
    "                    np.interp(\n",
    "                        x=t_points,\n",
    "                        xp=[t1, t2],\n",
    "                        fp=[SAT[\"BLC_Flux\"][p, 2], SAT[\"BLC_Flux\"][p + 1, 2]],\n",
    "                        left=np.nan,\n",
    "                        right=np.nan,\n",
    "                    )\n",
    "                )\n",
    "                BLC_FLUX_3.append(\n",
    "                    np.interp(\n",
    "                        x=t_points,\n",
    "                        xp=[t1, t2],\n",
    "                        fp=[SAT[\"BLC_Flux\"][p, 3], SAT[\"BLC_Flux\"][p + 1, 3]],\n",
    "                        left=np.nan,\n",
    "                        right=np.nan,\n",
    "                    )\n",
    "                )\n",
    "                BLC_FLUX_4.append(\n",
    "                    np.interp(\n",
    "                        x=t_points,\n",
    "                        xp=[t1, t2],\n",
    "                        fp=[SAT[\"BLC_Flux\"][p, 4], SAT[\"BLC_Flux\"][p + 1, 4]],\n",
    "                        left=np.nan,\n",
    "                        right=np.nan,\n",
    "                    )\n",
    "                )\n",
    "                BLC_FLUX_5.append(\n",
    "                    np.interp(\n",
    "                        x=t_points,\n",
    "                        xp=[t1, t2],\n",
    "                        fp=[SAT[\"BLC_Flux\"][p, 5], SAT[\"BLC_Flux\"][p + 1, 5]],\n",
    "                        left=np.nan,\n",
    "                        right=np.nan,\n",
    "                    )\n",
    "                )\n",
    "                BLC_FLUX_6.append(\n",
    "                    np.interp(\n",
    "                        x=t_points,\n",
    "                        xp=[t1, t2],\n",
    "                        fp=[SAT[\"BLC_Flux\"][p, 6], SAT[\"BLC_Flux\"][p + 1, 6]],\n",
    "                        left=np.nan,\n",
    "                        right=np.nan,\n",
    "                    )\n",
    "                )\n",
    "                BLC_FLUX_7.append(\n",
    "                    np.interp(\n",
    "                        x=t_points,\n",
    "                        xp=[t1, t2],\n",
    "                        fp=[SAT[\"BLC_Flux\"][p, 7], SAT[\"BLC_Flux\"][p + 1, 7]],\n",
    "                        left=np.nan,\n",
    "                        right=np.nan,\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        UNIX_TIME = np.hstack(UNIX_TIME)\n",
    "        L = np.hstack(L)\n",
    "        MLT = np.hstack(MLT)\n",
    "        BLC_FLUX_0 = np.hstack(BLC_FLUX_0)\n",
    "        BLC_FLUX_1 = np.hstack(BLC_FLUX_1)\n",
    "        BLC_FLUX_2 = np.hstack(BLC_FLUX_2)\n",
    "        BLC_FLUX_3 = np.hstack(BLC_FLUX_3)\n",
    "        BLC_FLUX_4 = np.hstack(BLC_FLUX_4)\n",
    "        BLC_FLUX_5 = np.hstack(BLC_FLUX_5)\n",
    "        BLC_FLUX_6 = np.hstack(BLC_FLUX_6)\n",
    "        BLC_FLUX_7 = np.hstack(BLC_FLUX_7)\n",
    "        BLC_FLUX = np.hstack(\n",
    "            [\n",
    "                np.expand_dims(BLC_FLUX_0, axis=1),\n",
    "                np.expand_dims(BLC_FLUX_1, axis=1),\n",
    "                np.expand_dims(BLC_FLUX_2, axis=1),\n",
    "                np.expand_dims(BLC_FLUX_3, axis=1),\n",
    "                np.expand_dims(BLC_FLUX_4, axis=1),\n",
    "                np.expand_dims(BLC_FLUX_5, axis=1),\n",
    "                np.expand_dims(BLC_FLUX_6, axis=1),\n",
    "                np.expand_dims(BLC_FLUX_7, axis=1),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        POES[SATID] = {\n",
    "            \"UNIX_TIME\": UNIX_TIME,\n",
    "            \"MLT\": MLT,\n",
    "            \"BLC_Flux\": BLC_FLUX,\n",
    "            \"L\": L,\n",
    "        }\n",
    "\n",
    "    if not POES:\n",
    "        print(f\"No POES satellite coverage found for year : {_year}\")\n",
    "        print(f\"SKIPPING YEAR : {_year}\")\n",
    "        continue\n",
    "\n",
    "    refs.close()\n",
    "\n",
    "    np.savez(\n",
    "        file=os.path.abspath(\n",
    "            f\"./../processed_data/chorus_neural_network/STAGE_0/MPE_DATA_PREPROCESSED_WITH_LSTAR/MPE_PREPROCESSED_DATA_T89_{_year}_interpolated.npz\"\n",
    "        ),\n",
    "        DATA=POES,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25.7 s, sys: 38.6 s, total: 1min 4s\n",
      "Wall time: 2min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Stage 1 RBSP Chorus Preprocessing, Obtains clean chorus amplitudes\n",
    "\n",
    "year = 2019\n",
    "\n",
    "pdata_folder = os.path.abspath(\"./../processed_data/chorus_neural_network/\")\n",
    "rbsp_density_folder = os.path.join(pdata_folder, \"STAGE_0\", \"ELECTRON_DENSITY_DATA_PREPROCESSED\")\n",
    "output_folder = os.path.join(pdata_folder, \"STAGE_1\", \"DENSITY_AND_CHORUS\")\n",
    "\n",
    "start = datetime.datetime(year=year, month=1, day=1, tzinfo=datetime.UTC)\n",
    "end = datetime.datetime(year=year+1, month=1, day=1, tzinfo=datetime.UTC)\n",
    "\n",
    "evenly_spaced_seconds = np.arange(start.timestamp(), end.timestamp() + 1, step=1)\n",
    "\n",
    "WNA_A = data_loader.load_raw_data_from_config(\n",
    "    id=[\"RBSP\", \"EMFISIS\", \"L4\", \"WNA_SURVEY\"],\n",
    "    start=start,\n",
    "    end=end,\n",
    "    satellite=\"a\",\n",
    "    root_data_dir=\"/project/rbsp/data/\",\n",
    "    use_config_keys_in_subdir=False,\n",
    ")\n",
    "\n",
    "WNA_B = data_loader.load_raw_data_from_config(\n",
    "    id=[\"RBSP\", \"EMFISIS\", \"L4\", \"WNA_SURVEY\"],\n",
    "    start=start,\n",
    "    end=end,\n",
    "    satellite=\"b\",\n",
    "    root_data_dir=\"/project/rbsp/data/\",\n",
    "    use_config_keys_in_subdir=False,\n",
    ")\n",
    "\n",
    "density_refs_A = np.load(\n",
    "    file=os.path.join(rbsp_density_folder, rf\"RBSP_A_OBSERVED_DENSITY_{year}.npz\"),\n",
    "    allow_pickle=True,\n",
    ")\n",
    "\n",
    "DENSITY_TIME_A = density_refs_A[\"UNIX_TIME\"]\n",
    "DENSITY_A = density_refs_A[\"DENSITY\"]\n",
    "\n",
    "density_refs_A.close()\n",
    "\n",
    "density_refs_B = np.load(\n",
    "    file=os.path.join(rbsp_density_folder, rf\"RBSP_B_OBSERVED_DENSITY_{year}.npz\"),\n",
    "    allow_pickle=True,\n",
    ")\n",
    "\n",
    "DENSITY_TIME_B = density_refs_B[\"UNIX_TIME\"]\n",
    "DENSITY_B = density_refs_B[\"DENSITY\"]\n",
    "\n",
    "density_refs_B.close()\n",
    "\n",
    "\n",
    "THRUSTER_EVENTS_DF_A = pd.read_csv(os.path.join(pdata_folder, \"THRUSTER_EVENTS_RBSPA.csv\"))\n",
    "THRUSTER_EVENTS_DF_B = pd.read_csv(os.path.join(pdata_folder, \"THRUSTER_EVENTS_RBSPB.csv\"))\n",
    "\n",
    "THRUSTER_START_TIMES_A = pd.to_datetime(THRUSTER_EVENTS_DF_A[\"Start Time\"], utc=True, format=\"ISO8601\").astype(np.int64) // 10**9\n",
    "THRUSTER_END_TIMES_A = pd.to_datetime(THRUSTER_EVENTS_DF_A[\"End Time\"], utc=True, format=\"ISO8601\").astype(np.int64) // 10**9\n",
    "\n",
    "THRUSTER_START_TIMES_B = pd.to_datetime(THRUSTER_EVENTS_DF_B[\"Start Time\"], utc=True, format=\"ISO8601\").astype(np.int64) // 10**9\n",
    "THRUSTER_END_TIMES_B = pd.to_datetime(THRUSTER_EVENTS_DF_B[\"End Time\"], utc=True, format=\"ISO8601\").astype(np.int64) // 10**9\n",
    "\n",
    "RBSP_A = {\n",
    "\n",
    "    \"WNA\" : WNA_A,\n",
    "    \"DENSITY_TIME\" : DENSITY_TIME_A,\n",
    "    \"DENSITY\" : DENSITY_A,\n",
    "    \"THRUSTER_START_TIMES\" : THRUSTER_START_TIMES_A,\n",
    "    \"THRUSTER_END_TIMES\" : THRUSTER_END_TIMES_A,\n",
    "    \"SATID\" : \"A\"\n",
    "}\n",
    "\n",
    "RBSP_B = {\n",
    "\n",
    "    \"WNA\" : WNA_B,\n",
    "    \"DENSITY_TIME\" : DENSITY_TIME_B,\n",
    "    \"DENSITY\" : DENSITY_B,\n",
    "    \"THRUSTER_START_TIMES\" : THRUSTER_START_TIMES_B,\n",
    "    \"THRUSTER_END_TIMES\" : THRUSTER_END_TIMES_B,\n",
    "    \"SATID\" : \"B\"\n",
    "}\n",
    "\n",
    "RBSP = [RBSP_A, RBSP_B]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         2.1\n",
      "1         4.3\n",
      "2         6.4\n",
      "3         8.5\n",
      "4        10.7\n",
      "       ...   \n",
      "60     7079.5\n",
      "61     7943.3\n",
      "62     8912.6\n",
      "63    10000.3\n",
      "64    11257.4\n",
      "Name: f_l, Length: 65, dtype: float64\n",
      "0        2.1\n",
      "1        2.1\n",
      "2        2.1\n",
      "3        2.1\n",
      "4        2.1\n",
      "       ...  \n",
      "60     816.0\n",
      "61     914.3\n",
      "62    1027.5\n",
      "63    1151.4\n",
      "64    1371.5\n",
      "Name: del_l, Length: 65, dtype: float64\n",
      "0         2.1\n",
      "1         4.3\n",
      "2         6.4\n",
      "3         8.5\n",
      "4        10.7\n",
      "       ...   \n",
      "60     7079.5\n",
      "61     7943.3\n",
      "62     8912.6\n",
      "63    10000.3\n",
      "64    11257.4\n",
      "Name: f_l, Length: 65, dtype: float64\n",
      "0        2.1\n",
      "1        2.1\n",
      "2        2.1\n",
      "3        2.1\n",
      "4        2.1\n",
      "       ...  \n",
      "60     816.0\n",
      "61     914.3\n",
      "62    1027.5\n",
      "63    1151.4\n",
      "64    1371.5\n",
      "Name: del_l, Length: 65, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4118380/4118380 [01:58<00:00, 34751.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shapes before cleaning thruster events and removing NaNs:\n",
      "(32152351,)\n",
      "(32152351,)\n",
      "(32152351,)\n",
      "(32152351,)\n",
      "(32152351,)\n",
      "(32152351,)\n",
      "Number of points in thruster events : 253219\n",
      "Number of LOWER BAND CHORUS that were NAN: 6492256\n",
      "Number of UPPER BAND CHORUS that were NAN: 12110426\n",
      "\n",
      "Shapes after cleaning thruster events and removing NaNs:\n",
      "\n",
      "Lower:\n",
      "(25439279,)\n",
      "(25439279,)\n",
      "(25439279,)\n",
      "(25439279,)\n",
      "(25439279,)\n",
      "\n",
      "Upper:\n",
      "(19837479,)\n",
      "(19837479,)\n",
      "(19837479,)\n",
      "(19837479,)\n",
      "(19837479,)\n",
      "\n",
      "\n",
      "0         2.1\n",
      "1         4.3\n",
      "2         6.4\n",
      "3         8.5\n",
      "4        10.7\n",
      "       ...   \n",
      "60     7079.5\n",
      "61     7943.3\n",
      "62     8912.6\n",
      "63    10000.3\n",
      "64    11257.4\n",
      "Name: f_l, Length: 65, dtype: float64\n",
      "0        2.1\n",
      "1        2.1\n",
      "2        2.1\n",
      "3        2.1\n",
      "4        2.1\n",
      "       ...  \n",
      "60     816.0\n",
      "61     914.3\n",
      "62    1027.5\n",
      "63    1151.4\n",
      "64    1371.5\n",
      "Name: del_l, Length: 65, dtype: float64\n",
      "0         2.1\n",
      "1         4.3\n",
      "2         6.4\n",
      "3         8.5\n",
      "4        10.7\n",
      "       ...   \n",
      "60     7079.5\n",
      "61     7943.3\n",
      "62     8912.6\n",
      "63    10000.3\n",
      "64    11257.4\n",
      "Name: f_l, Length: 65, dtype: float64\n",
      "0        2.1\n",
      "1        2.1\n",
      "2        2.1\n",
      "3        2.1\n",
      "4        2.1\n",
      "       ...  \n",
      "60     816.0\n",
      "61     914.3\n",
      "62    1027.5\n",
      "63    1151.4\n",
      "64    1371.5\n",
      "Name: del_l, Length: 65, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2829323/2829323 [01:21<00:00, 34886.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shapes before cleaning thruster events and removing NaNs:\n",
      "(20571149,)\n",
      "(20571149,)\n",
      "(20571149,)\n",
      "(20571149,)\n",
      "(20571149,)\n",
      "(20571149,)\n",
      "Number of points in thruster events : 185041\n",
      "Number of LOWER BAND CHORUS that were NAN: 4259556\n",
      "Number of UPPER BAND CHORUS that were NAN: 7771477\n",
      "\n",
      "Shapes after cleaning thruster events and removing NaNs:\n",
      "\n",
      "Lower:\n",
      "(16151999,)\n",
      "(16151999,)\n",
      "(16151999,)\n",
      "(16151999,)\n",
      "(16151999,)\n",
      "\n",
      "Upper:\n",
      "(12651899,)\n",
      "(12651899,)\n",
      "(12651899,)\n",
      "(12651899,)\n",
      "(12651899,)\n",
      "\n",
      "\n",
      "CPU times: user 52min 14s, sys: 23 s, total: 52min 37s\n",
      "Wall time: 52min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for PROBE in RBSP:\n",
    "    \n",
    "    MLT = PROBE[\"WNA\"][\"MLT\"]\n",
    "    MLAT = PROBE[\"WNA\"][\"MagLat\"]\n",
    "    L = PROBE[\"WNA\"][\"L\"]\n",
    "    EPOCH = PROBE[\"WNA\"][\"Epoch\"]\n",
    "    PLANARITY = PROBE[\"WNA\"][\"plansvd\"]\n",
    "    ELLIPTICITY = PROBE[\"WNA\"][\"ellsvd\"]\n",
    "    #DENSITY_TIME = PROBE[\"DENSITY_TIME\"]\n",
    "    #DENSITY = PROBE[\"DENSITY\"]\n",
    "    THRUSTER_START_TIMES = PROBE[\"THRUSTER_START_TIMES\"]\n",
    "    THRUSTER_END_TIMES = PROBE[\"THRUSTER_END_TIMES\"]\n",
    "    SATID = PROBE[\"SATID\"]\n",
    "    \n",
    "    TIME = cdfepoch.unixtime(EPOCH)\n",
    "    \n",
    "    LOWER_CHORUS = np.asarray(rbsp_chorus_tool.calculate_chorus_power(\n",
    "        WNA_survey=PROBE[\"WNA\"], Magnetic_Planarity=PLANARITY, Magnetic_Ellipticity=ELLIPTICITY, lower=True\n",
    "    ))\n",
    "    \n",
    "    UPPER_CHORUS = np.asarray(rbsp_chorus_tool.calculate_chorus_power(\n",
    "        WNA_survey=PROBE[\"WNA\"], Magnetic_Planarity=PLANARITY, Magnetic_Ellipticity=ELLIPTICITY, lower=False\n",
    "    ))\n",
    "    \n",
    "    within_epoch_range = (start.timestamp() < TIME) & (TIME < end.timestamp())\n",
    "    all_valid_coordinates = (EPOCH > 0) & (0 <= MLT) & (MLT <= 24) & (0 < L) & (L < 10) & (-90 <= MLAT) & (MLAT <= 90)\n",
    "    \n",
    "    MLT[~(within_epoch_range & all_valid_coordinates)] = np.nan\n",
    "    MLAT[~(within_epoch_range & all_valid_coordinates)] = np.nan\n",
    "    L[~(within_epoch_range & all_valid_coordinates)] = np.nan\n",
    "    LOWER_CHORUS[~(within_epoch_range & all_valid_coordinates)] = np.nan\n",
    "    UPPER_CHORUS[~(within_epoch_range & all_valid_coordinates)] = np.nan\n",
    "    \n",
    "    TIME_INTERPOLATED = []\n",
    "    L_INTERPOLATED = []\n",
    "    MLT_INTERPOLATED = []\n",
    "    MLAT_INTERPOLATED = []\n",
    "    LOWER_CHORUS_INTERPOLATED = []\n",
    "    UPPER_CHORUS_INTERPOLATED = []\n",
    "    \n",
    "    for p in tqdm.tqdm(range(len(TIME) - 1)):\n",
    "    \n",
    "        t1 = TIME[p]\n",
    "        t2 = TIME[p + 1]\n",
    "    \n",
    "        if t2 - t1 < 60.0:\n",
    "    \n",
    "            t_points = np.arange(t1, t2 + 1, step=1, dtype=np.float64)\n",
    "    \n",
    "            TIME_INTERPOLATED.extend(t_points)\n",
    "            L_INTERPOLATED.extend(\n",
    "                np.interp(\n",
    "                    x=t_points,\n",
    "                    xp=[t1, t2],\n",
    "                    fp=[L[p], L[p + 1]],\n",
    "                    left=np.nan,\n",
    "                    right=np.nan,\n",
    "                )\n",
    "            )\n",
    "    \n",
    "            x_int = np.interp(\n",
    "                t_points,\n",
    "                xp=[t1, t2],\n",
    "                fp=[np.cos(MLT[p] * 2 * np.pi / 24.0), np.cos(MLT[p+1] * 2 * np.pi / 24.0)],\n",
    "                left=np.nan,\n",
    "                right=np.nan,\n",
    "            )\n",
    "            \n",
    "            y_int = np.interp(\n",
    "                t_points,\n",
    "                xp=[t1, t2],\n",
    "                fp=[np.sin(MLT[p] * 2 * np.pi / 24.0), np.sin(MLT[p+1] * 2 * np.pi / 24.0)],\n",
    "                left=np.nan,\n",
    "                right=np.nan,\n",
    "            )\n",
    "            \n",
    "            angle = np.mod(np.arctan2(y_int, x_int) + 2 * np.pi, 2 * np.pi)\n",
    "            MLT_INTERPOLATED.extend((angle * 24) / (2 * np.pi))\n",
    "    \n",
    "            MLAT_INTERPOLATED.extend(\n",
    "                np.interp(\n",
    "                    x=t_points,\n",
    "                    xp=[t1, t2],\n",
    "                    fp=[MLAT[p], MLAT[p + 1]],\n",
    "                    left=np.nan,\n",
    "                    right=np.nan,\n",
    "                )\n",
    "            )\n",
    "    \n",
    "            LOWER_CHORUS_INTERPOLATED.extend(\n",
    "                np.interp(\n",
    "                    x=t_points,\n",
    "                    xp=[t1, t2],\n",
    "                    fp=[LOWER_CHORUS[p], LOWER_CHORUS[p + 1]],\n",
    "                    left=np.nan,\n",
    "                    right=np.nan,\n",
    "                )\n",
    "            )\n",
    "    \n",
    "            UPPER_CHORUS_INTERPOLATED.extend(\n",
    "                np.interp(\n",
    "                    x=t_points,\n",
    "                    xp=[t1, t2],\n",
    "                    fp=[UPPER_CHORUS[p], UPPER_CHORUS[p + 1]],\n",
    "                    left=np.nan,\n",
    "                    right=np.nan,\n",
    "                )\n",
    "            )\n",
    "\n",
    "    TIME = np.array(TIME_INTERPOLATED)\n",
    "    L = np.array(L_INTERPOLATED)\n",
    "    MLT = np.array(MLT_INTERPOLATED)\n",
    "    MLAT = np.array(MLAT_INTERPOLATED)\n",
    "    LOWER_CHORUS = np.array(LOWER_CHORUS_INTERPOLATED)\n",
    "    UPPER_CHORUS = np.array(UPPER_CHORUS_INTERPOLATED)\n",
    "    #DENSITY = np.interp(x = TIME, xp = DENSITY_TIME, fp = DENSITY)\n",
    "\n",
    "    print(\"\\nShapes before cleaning thruster events and removing NaNs:\")\n",
    "    print(TIME.shape)\n",
    "    print(L.shape)\n",
    "    print(MLT.shape)\n",
    "    print(MLAT.shape)\n",
    "    print(LOWER_CHORUS.shape)\n",
    "    print(UPPER_CHORUS.shape)\n",
    "    #print(DENSITY.shape)\n",
    "\n",
    "    NUM_IN_THRUSTER_EVENTS = 0\n",
    "    for START_TIME, END_TIME in zip(THRUSTER_START_TIMES, THRUSTER_END_TIMES):\n",
    "        NUM_IN_THRUSTER_EVENTS += np.sum((START_TIME <= TIME) & (TIME <= END_TIME))\n",
    "        TIME[(START_TIME <= TIME) & (TIME <= END_TIME)] = np.nan\n",
    "    \n",
    "    NOT_NAN_LOWER = (\n",
    "        np.isfinite(TIME)\n",
    "        & np.isfinite(L)\n",
    "        & np.isfinite(MLT)\n",
    "        & np.isfinite(MLAT)\n",
    "        & np.isfinite(LOWER_CHORUS)\n",
    "        #& np.isfinite(DENSITY)\n",
    "    )\n",
    "\n",
    "    NOT_NAN_UPPER = (\n",
    "        np.isfinite(TIME)\n",
    "        & np.isfinite(L)\n",
    "        & np.isfinite(MLT)\n",
    "        & np.isfinite(MLAT)\n",
    "        & np.isfinite(UPPER_CHORUS)\n",
    "        #& np.isfinite(DENSITY)\n",
    "    )\n",
    "\n",
    "    print(f\"Number of points in thruster events : {np.sum(np.isnan(TIME))}\")\n",
    "    print(f\"Number of LOWER BAND CHORUS that were NAN: {np.sum(np.isnan(LOWER_CHORUS))}\")\n",
    "    print(f\"Number of UPPER BAND CHORUS that were NAN: {np.sum(np.isnan(UPPER_CHORUS))}\")\n",
    "    \n",
    "    TIME_LOWER = TIME[NOT_NAN_LOWER]\n",
    "    L_LOWER = L[NOT_NAN_LOWER]\n",
    "    MLT_LOWER = MLT[NOT_NAN_LOWER]\n",
    "    MLAT_LOWER = MLAT[NOT_NAN_LOWER]\n",
    "    CHORUS_LOWER = LOWER_CHORUS[NOT_NAN_LOWER]\n",
    "    #DENSITY_LOWER = DENSITY[NOT_NAN_LOWER]\n",
    "\n",
    "    TIME_UPPER = TIME[NOT_NAN_UPPER]\n",
    "    L_UPPER = L[NOT_NAN_UPPER]\n",
    "    MLT_UPPER = MLT[NOT_NAN_UPPER]\n",
    "    MLAT_UPPER = MLAT[NOT_NAN_UPPER]\n",
    "    CHORUS_UPPER = UPPER_CHORUS[NOT_NAN_UPPER]\n",
    "    #DENSITY_UPPER = DENSITY[NOT_NAN_UPPER]\n",
    "\n",
    "    print(\"\\nShapes after cleaning thruster events and removing NaNs:\\n\")\n",
    "    print(\"Lower:\")\n",
    "    print(TIME_LOWER.shape)\n",
    "    print(L_LOWER.shape)\n",
    "    print(MLT_LOWER.shape)\n",
    "    print(MLAT_LOWER.shape)\n",
    "    print(CHORUS_LOWER.shape)\n",
    "    #print(DENSITY_LOWER.shape)\n",
    "\n",
    "    print(\"\\nUpper:\")\n",
    "\n",
    "    print(TIME_UPPER.shape)\n",
    "    print(L_UPPER.shape)\n",
    "    print(MLT_UPPER.shape)\n",
    "    print(MLAT_UPPER.shape)\n",
    "    print(CHORUS_UPPER.shape)\n",
    "    #print(DENSITY_UPPER.shape)\n",
    "    \n",
    "    print(\"\\n\")\n",
    "\n",
    "    np.savez(\n",
    "        file=os.path.abspath(os.path.join(output_folder, f\"RBSP_EMFISIS_CHORUS_AND_DENSITY_{year}_{SATID}_LOWER_BAND.npz\")),\n",
    "        UNIX_TIME=TIME_LOWER,\n",
    "        MLT=MLT_LOWER,\n",
    "        MLAT=MLAT_LOWER,\n",
    "        L=L_LOWER,\n",
    "        CHORUS=CHORUS_LOWER,\n",
    "        #DENSITY=DENSITY_LOWER\n",
    "    )\n",
    "\n",
    "    np.savez(\n",
    "        file=os.path.abspath(os.path.join(output_folder, f\"RBSP_EMFISIS_CHORUS_AND_DENSITY_{year}_{SATID}_UPPER_BAND.npz\")),\n",
    "        UNIX_TIME=TIME_UPPER,\n",
    "        MLT=MLT_UPPER,\n",
    "        MLAT=MLAT_UPPER,\n",
    "        L=L_UPPER,\n",
    "        CHORUS=CHORUS_UPPER,\n",
    "        #DENSITY=DENSITY_UPPER\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(CHORUS_LOWER == 0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 2, clean then combine RBSP, OMNI, and POES Data and find conjunctions between RBSP and POES See bin_before_finding_conjunctions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 3 Continued, Removing solar proton events!\n",
    "\n",
    "VERSION = \"v4\"\n",
    "FIELD_MODEL = \"T89\"\n",
    "MODEL_TYPE = \"LOWER_BAND\"\n",
    "\n",
    "\n",
    "pdata_folder = os.path.abspath(r\"./../processed_data/chorus_neural_network/\")\n",
    "\n",
    "STAGE_2_folder = os.path.join(pdata_folder, \"STAGE_2\", VERSION)\n",
    "STAGE_3_folder = os.path.join(pdata_folder, \"STAGE_3\", VERSION)\n",
    "\n",
    "\n",
    "CONJUNCTIONS_REFS = np.load(\n",
    "    os.path.join(STAGE_2_folder, rf\"CONJUNCTIONS_{VERSION}_{FIELD_MODEL}_{MODEL_TYPE}.npz\")\n",
    ")\n",
    "\n",
    "CONJUNCTIONS = CONJUNCTIONS_REFS[\"CONJUNCTIONS\"]\n",
    "\n",
    "CONJUNCTIONS_REFS.close()\n",
    "\n",
    "SOLAR_PROTON_EVENT_LIST = pd.read_csv(\n",
    "    os.path.join(pdata_folder, r\"SOLAR_PROTON_EVENT_LIST_1976_2024.csv\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting shape of conjunctions list: (160847, 23)\n",
      "Removing high energy solar proton events!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 309/309 [00:10<00:00, 28.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished removing high energy solar proton events!\n",
      "Saving!\n",
      "Creating documentation of dataset!\n",
      "Finished!\n",
      "Ending shape of conjunctions : (159520, 23)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"CONJUNCTION = [\n",
    "    CHUNK_TIME + (T_SIZE / 2.0),\n",
    "    AVG_L_POES[x_bin, y_bin],\n",
    "    AVG_MLT_POES[x_bin, y_bin],\n",
    "    AVG_FLUX_0[x_bin, y_bin],\n",
    "    AVG_FLUX_1[x_bin, y_bin],\n",
    "    AVG_FLUX_2[x_bin, y_bin],\n",
    "    AVG_FLUX_3[x_bin, y_bin],\n",
    "    AVG_FLUX_4[x_bin, y_bin],\n",
    "    AVG_FLUX_5[x_bin, y_bin],\n",
    "    AVG_FLUX_6[x_bin, y_bin],\n",
    "    AVG_FLUX_7[x_bin, y_bin],\n",
    "    CHUNK_TIME + (T_SIZE / 2.0),\n",
    "    AVG_L_RBSP[x_bin, y_bin, z_bin],  # LSTAR OF RBSP POINT CHOSEN\n",
    "    AVG_MLT_RBSP[x_bin, y_bin, z_bin],  # DIFFERENCE IN MLT FOUND\n",
    "    AVG_MLAT_RBSP[x_bin, y_bin, z_bin],\n",
    "    AVG_CHORUS[x_bin, y_bin, z_bin],  # CHORUS OBSERVED\n",
    "    AVG_DENSITY_RBSP[x_bin, y_bin, z_bin],\n",
    "    SME_MEAN,\n",
    "    SME_VARIATION,\n",
    "    OMNI[\"AVG_B\"],\n",
    "    OMNI[\"FLOW_SPEED\"],\n",
    "    OMNI[\"PROTON_DENSITY\"],\n",
    "    OMNI[\"SYM_H\"]]\"\"\"\n",
    "\n",
    "order_to_sort_conjunctions = np.argsort(\n",
    "    CONJUNCTIONS[:, 0]\n",
    ")  # Sorted based on POES Conjunction time!\n",
    "SORTED_CONJUNCTIONS = CONJUNCTIONS[order_to_sort_conjunctions, :]\n",
    "\n",
    "print(f\"Starting shape of conjunctions list: {SORTED_CONJUNCTIONS.shape}\")\n",
    "\n",
    "SORTED_POES_CONJUNCTION_TIMES = SORTED_CONJUNCTIONS[:, 0]\n",
    "\n",
    "START_OF_SEP_EVENTS_UTC = SOLAR_PROTON_EVENT_LIST[\"START\"]\n",
    "END_OF_SEP_EVENTS_UTC = SOLAR_PROTON_EVENT_LIST[\"END\"]\n",
    "ZIPPED_EVENTS = list(zip(START_OF_SEP_EVENTS_UTC, END_OF_SEP_EVENTS_UTC))\n",
    "\n",
    "print(\"Removing high energy solar proton events!\")\n",
    "\n",
    "for SEP_EVENT in tqdm.tqdm(range(len(ZIPPED_EVENTS))):\n",
    "\n",
    "    START = ZIPPED_EVENTS[SEP_EVENT][0].strip()\n",
    "    END = ZIPPED_EVENTS[SEP_EVENT][1].strip()\n",
    "\n",
    "    START_YMDHMS = {\n",
    "        \"year\": int(START[0:4]),\n",
    "        \"month\": int(START[5:7]),\n",
    "        \"day\": int(START[8:10]),\n",
    "        \"hour\": int(START[11:13]),\n",
    "        \"minute\": int(START[13:15]),\n",
    "        \"second\": 0,\n",
    "    }\n",
    "    END_YMDHMS = {\n",
    "        \"year\": int(END[0:4]),\n",
    "        \"month\": int(END[5:7]),\n",
    "        \"day\": int(END[8:10]),\n",
    "        \"hour\": int(END[11:13]),\n",
    "        \"minute\": int(END[13:15]),\n",
    "        \"second\": 0,\n",
    "    }\n",
    "\n",
    "    START_UNIX = astropy.time.Time(START_YMDHMS, format=\"ymdhms\", scale=\"utc\").unix\n",
    "    END_UNIX = astropy.time.Time(END_YMDHMS, format=\"ymdhms\", scale=\"utc\").unix\n",
    "\n",
    "    RANGE_TO_REMOVE = np.searchsorted(a=SORTED_POES_CONJUNCTION_TIMES, v=[START_UNIX, END_UNIX])\n",
    "\n",
    "    SORTED_CONJUNCTIONS = np.vstack(\n",
    "        (\n",
    "            SORTED_CONJUNCTIONS[0 : RANGE_TO_REMOVE[0], :],\n",
    "            SORTED_CONJUNCTIONS[RANGE_TO_REMOVE[1] :, :],\n",
    "        )\n",
    "    )\n",
    "\n",
    "print(\"Finished removing high energy solar proton events!\")\n",
    "\n",
    "print(\"Saving!\")\n",
    "\n",
    "CLEANED_CONJUNCTIONS = SORTED_CONJUNCTIONS  # Should be cleaned by now!\n",
    "\n",
    "np.savez(\n",
    "    file=os.path.join(STAGE_3_folder, rf\"CLEANED_CONJUNCTIONS_{VERSION}_{FIELD_MODEL}_{MODEL_TYPE}.npz\"),\n",
    "    CONJUNCTIONS=CLEANED_CONJUNCTIONS,\n",
    ")\n",
    "\n",
    "C_POES_TIME = CLEANED_CONJUNCTIONS[:, 0]\n",
    "C_POES_LSTAR = CLEANED_CONJUNCTIONS[:, 1]\n",
    "C_POES_MLT = CLEANED_CONJUNCTIONS[:, 2]\n",
    "C_POES_FLUX = CLEANED_CONJUNCTIONS[:, 3:-12]\n",
    "C_RBSP_TIME = CLEANED_CONJUNCTIONS[:, -12]\n",
    "C_RBSP_LSTAR = CLEANED_CONJUNCTIONS[:, -11]\n",
    "C_RBSP_MLT = CLEANED_CONJUNCTIONS[:, -10]\n",
    "C_RBSP_MLAT = CLEANED_CONJUNCTIONS[:, -9]\n",
    "C_RBSP_CHORUS = CLEANED_CONJUNCTIONS[:, -8]\n",
    "C_RBSP_DENSITY = CLEANED_CONJUNCTIONS[:, -7]\n",
    "C_AVG_SME = CLEANED_CONJUNCTIONS[:, -6]\n",
    "C_VAR_SME = CLEANED_CONJUNCTIONS[:, -5]\n",
    "C_AVG_AVG_B = CLEANED_CONJUNCTIONS[:, -4]\n",
    "C_AVG_FLOW_SPEED = CLEANED_CONJUNCTIONS[:, -3]\n",
    "C_AVG_PROTON_DENSITY = CLEANED_CONJUNCTIONS[:, -2]\n",
    "C_AVG_SYM_H = CLEANED_CONJUNCTIONS[:, -1]\n",
    "\n",
    "print(\"Creating documentation of dataset!\")\n",
    "\n",
    "\n",
    "with open(\n",
    "    os.path.join(STAGE_3_folder, rf\"CLEANED_CONJUNCTIONS_{VERSION}_{FIELD_MODEL}_{MODEL_TYPE}.txt\"),\n",
    "    \"w\",\n",
    ") as f:\n",
    "\n",
    "    f.write(\"\\nConjunctions:\\n\")\n",
    "    f.write(f\"Number of conjunctions: {CLEANED_CONJUNCTIONS.shape[0]} [#]\\n\")\n",
    "    f.write(\n",
    "        f\"Number lost from cleaning solar proton events: {CONJUNCTIONS.shape[0] - CLEANED_CONJUNCTIONS.shape[0]} [#]\\n\"\n",
    "    )\n",
    "    f.write(f\"Minimum RBSP Time: {np.min(C_RBSP_TIME)} [seconds since unix epoch]\\n\")\n",
    "    f.write(f\"Maximum RBSP Time: {np.max(C_RBSP_TIME)} [seconds since unix epoch]\\n\")\n",
    "    f.write(f\"Minimum POES Time: {np.min(C_POES_TIME)} [seconds since unix epoch]\\n\")\n",
    "    f.write(f\"Maximum POES Time: {np.max(C_POES_TIME)} [seconds since unix epoch]\\n\")\n",
    "\n",
    "    f.write(\"\\nL:\\n\")\n",
    "    f.write(f\"Mean Difference: {np.mean(C_POES_LSTAR - C_RBSP_LSTAR)} [L]\\n\")\n",
    "    f.write(f\"Standard deviation of Difference {np.std(C_POES_LSTAR - C_RBSP_LSTAR)} [L]\\n\")\n",
    "    f.write(f\"Minimum Absolute Difference : {np.min(np.abs(C_POES_LSTAR - C_RBSP_LSTAR))} [L]\\n\")\n",
    "    f.write(f\"Maximum Absolute Difference : {np.max(np.abs(C_POES_LSTAR - C_RBSP_LSTAR))} [L]\\n\")\n",
    "\n",
    "    f.write(\"\\nMLT: \\n\")\n",
    "    f.write(f\"Mean Absolute Difference: {np.mean(C_POES_MLT - C_RBSP_MLT)} [MLT]\\n\")\n",
    "    f.write(f\"Standard deviation of Absolute Difference {np.std(C_POES_MLT - C_RBSP_MLT)} [MLT]\\n\")\n",
    "    f.write(f\"Minimum Absolute Difference : {np.min(np.abs(C_POES_MLT - C_RBSP_MLT))} [MLT]\\n\")\n",
    "    f.write(f\"Maximum Absolute Difference : {np.max(np.abs(C_POES_MLT - C_RBSP_MLT))} [MLT]\\n\")\n",
    "\n",
    "    f.write(\"\\nMLAT: \\n\")\n",
    "    f.write(f\"Mean: {np.mean(C_RBSP_MLAT)} [degrees]\\n\")\n",
    "    f.write(f\"Standard Deviation: {np.std(C_RBSP_MLAT)} [degrees]\\n\")\n",
    "    f.write(f\"Minimum: {np.min(C_RBSP_MLAT)} [degrees]\\n\")\n",
    "    f.write(f\"Maximum: {np.max(C_RBSP_MLAT)} [degrees]\\n\")\n",
    "\n",
    "    f.write(\"\\nTime: \\n\")\n",
    "    f.write(f\"Mean Difference: {np.mean(C_POES_TIME - C_RBSP_TIME)} [s]\\n\")\n",
    "    f.write(f\"Standard deviation of Difference {np.std(C_POES_TIME - C_RBSP_TIME)} [s]\\n\")\n",
    "    f.write(f\"Minimum Absolute Difference : {np.min(np.abs(C_POES_TIME - C_RBSP_TIME))} [s]\\n\")\n",
    "    f.write(f\"Maximum Absolute Difference : {np.max(np.abs(C_POES_TIME - C_RBSP_TIME))} [s]\\n\")\n",
    "\n",
    "    f.write(f\"\\n{MODEL_TYPE} Chorus: \\n\")\n",
    "    f.write(f\"Mean: {np.mean(C_RBSP_CHORUS)} [pT]\\n\")\n",
    "    f.write(f\"Standard Deviation: {np.std(C_RBSP_CHORUS)} [pT]\\n\")\n",
    "    f.write(f\"Minimum: {np.min(C_RBSP_CHORUS)} [pT]\\n\")\n",
    "    f.write(f\"Maximum: {np.max(C_RBSP_CHORUS)} [pT]\\n\")\n",
    "\n",
    "    f.write(\"\\nDensity: \\n\")\n",
    "    f.write(f\"Mean: {np.mean(C_RBSP_DENSITY)} [cm^-3]\\n\")\n",
    "    f.write(f\"Standard Deviation: {np.std(C_RBSP_DENSITY)} [cm^-3]\\n\")\n",
    "    f.write(f\"Minimum: {np.min(C_RBSP_DENSITY)} [cm^-3]\\n\")\n",
    "    f.write(f\"Maximum: {np.max(C_RBSP_DENSITY)} [cm^-3]\\n\")\n",
    "\n",
    "    f.write(\"\\nSME: \\n\")\n",
    "    f.write(f\"Mean: {np.mean(C_AVG_SME)} [nT]\\n\")\n",
    "    f.write(f\"Standard Deviation: {np.std(C_AVG_SME)} [nT]\\n\")\n",
    "    f.write(f\"Minimum: {np.min(C_AVG_SME)} [nT]\\n\")\n",
    "    f.write(f\"Maximum: {np.max(C_AVG_SME)} [nT]\\n\")\n",
    "\n",
    "    f.write(\"\\nSME STD: \\n\")\n",
    "    f.write(f\"Mean: {np.mean(np.sqrt(C_VAR_SME))} [nT]\\n\")\n",
    "    f.write(f\"Standard Deviation: {np.std(np.sqrt(C_VAR_SME))} [nT]\\n\")\n",
    "    f.write(f\"Minimum: {np.min(np.sqrt(C_VAR_SME))} [nT]\\n\")\n",
    "    f.write(f\"Maximum: {np.max(np.sqrt(C_VAR_SME))} [nT]\\n\")\n",
    "\n",
    "    f.write(\"\\nAVG_B: \\n\")\n",
    "    f.write(f\"Mean: {np.mean(C_AVG_AVG_B)} [nT]\\n\")\n",
    "    f.write(f\"Standard Deviation: {np.std(C_AVG_AVG_B)} [nT]\\n\")\n",
    "    f.write(f\"Minimum: {np.min(C_AVG_AVG_B)} [nT]\\n\")\n",
    "    f.write(f\"Maximum: {np.max(C_AVG_AVG_B)} [nT]\\n\")\n",
    "\n",
    "    f.write(\"\\nFlow Speed: \\n\")\n",
    "    f.write(f\"Mean: {np.mean(C_AVG_FLOW_SPEED)} [km/s]\\n\")\n",
    "    f.write(f\"Standard Deviation: {np.std(C_AVG_FLOW_SPEED)} [km/s]\\n\")\n",
    "    f.write(f\"Minimum: {np.min(C_AVG_FLOW_SPEED)} [km/s]\\n\")\n",
    "    f.write(f\"Maximum: {np.max(C_AVG_FLOW_SPEED)} [km/s]\\n\")\n",
    "\n",
    "    f.write(\"\\nProton Density: \\n\")\n",
    "    f.write(f\"Mean: {np.mean(C_AVG_PROTON_DENSITY)} [n/cc]\\n\")\n",
    "    f.write(f\"Standard Deviation: {np.std(C_AVG_PROTON_DENSITY)} [n/cc]\\n\")\n",
    "    f.write(f\"Minimum: {np.min(C_AVG_PROTON_DENSITY)} [n/cc]\\n\")\n",
    "    f.write(f\"Maximum: {np.max(C_AVG_PROTON_DENSITY)} [n/cc]\\n\")\n",
    "\n",
    "    f.write(\"\\nSYM_H: \\n\")\n",
    "    f.write(f\"Mean: {np.mean(C_AVG_SYM_H)} [nT]\\n\")\n",
    "    f.write(f\"Standard Deviation: {np.std(C_AVG_SYM_H)} [nT]\\n\")\n",
    "    f.write(f\"Minimum: {np.min(C_AVG_SYM_H)} [nT]\\n\")\n",
    "    f.write(f\"Maximum: {np.max(C_AVG_SYM_H)} [nT]\\n\")\n",
    "\n",
    "print(\"Finished!\")\n",
    "print(f\"Ending shape of conjunctions : {CLEANED_CONJUNCTIONS.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 4, Create datasets used for training, testing, etc\n",
    "\n",
    "VERSION = \"v4\"\n",
    "FIELD_MODEL = \"T89\"\n",
    "MODEL_TYPE = \"LOWER_BAND\"\n",
    "\n",
    "pdata_folder = os.path.abspath(r\"./../processed_data/chorus_neural_network/\")\n",
    "STAGE_3_folder = os.path.join(pdata_folder, \"STAGE_3\", VERSION)\n",
    "STAGE_4_folder = os.path.join(pdata_folder, \"STAGE_4\", VERSION)\n",
    "\n",
    "CONJUNCTIONS_REFS = np.load(\n",
    "    file=os.path.join(STAGE_3_folder, rf\"CLEANED_CONJUNCTIONS_{VERSION}_{FIELD_MODEL}_{MODEL_TYPE}.npz\")\n",
    ")\n",
    "\n",
    "CONJUNCTIONS = CONJUNCTIONS_REFS[\"CONJUNCTIONS\"]\n",
    "\n",
    "CONJUNCTIONS_REFS.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "POES = data_loader.load_raw_data_from_config(\n",
    "    id=[\"POES\", \"SEM\", \"MPE\"],\n",
    "    start=datetime.datetime(year=2000, month=1, day=1),\n",
    "    end=datetime.datetime(year=2000, month=1, day=2),\n",
    "    satellite=\"n15\",\n",
    ")\n",
    "\n",
    "ENERGIES = POES[\"energy\"][0]\n",
    "print(ENERGIES[2:8])\n",
    "print(ENERGIES[1:7])\n",
    "DIFF_E = ENERGIES[2:8] - ENERGIES[1:7]\n",
    "print(DIFF_E)\n",
    "print(len(DIFF_E))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(CONJUNCTIONS.shape)\n",
    "\n",
    "mission_start_date = datetime.datetime(year=2012, month=8, day=30, tzinfo=datetime.UTC)\n",
    "mission_end_date = datetime.datetime(year=2019, month=10, day=19, tzinfo=datetime.UTC)\n",
    "\n",
    "C_POES_TIME = CONJUNCTIONS[:, 0]\n",
    "\n",
    "validation_start_date = datetime.datetime(year=2016, month=2, day=1, tzinfo=datetime.UTC)\n",
    "validation_end_date = datetime.datetime(year=2016, month=3, day=1, tzinfo=datetime.UTC)\n",
    "validation_times = (validation_start_date.timestamp() < C_POES_TIME) & (C_POES_TIME < validation_end_date.timestamp())\n",
    "\n",
    "within_mission_time = (mission_start_date.timestamp() < C_POES_TIME) & (C_POES_TIME < mission_end_date.timestamp())\n",
    "\n",
    "train_test_subset_selected = ~validation_times & within_mission_time\n",
    "validation_subset_selected = validation_times & within_mission_time\n",
    "\n",
    "DAY = np.zeros(shape=(C_POES_TIME.shape[0]))\n",
    "print(\"Identifying Days of Data Points....\")\n",
    "for DAY_ID, dt in enumerate(rrule.rrule(rrule.DAILY, dtstart=mission_start_date, until=mission_end_date)):\n",
    "\n",
    "    within_day = (dt.timestamp() <= C_POES_TIME) & (C_POES_TIME < (dt + datetime.timedelta(days=1)).timestamp())\n",
    "    DAY[within_day] = DAY_ID\n",
    "\n",
    "print(f\"Min day: {np.min(DAY)}\")\n",
    "print(f\"Max day: {np.max(DAY)}\")\n",
    "\n",
    "print(f\"Number of conjunctions in validation set: {np.count_nonzero(validation_times)}\")\n",
    "\n",
    "C_POES_TIME = np.expand_dims(CONJUNCTIONS[:, 0], axis=1)\n",
    "C_POES_LSTAR = np.expand_dims(CONJUNCTIONS[:, 1], axis=1)\n",
    "C_POES_MLT = np.expand_dims(CONJUNCTIONS[:, 2], axis=1)\n",
    "\n",
    "C_POES_FLUX = CONJUNCTIONS[:, 3:-12][:, 1:7]\n",
    "C_POES_FLUX_INTEGRATED = np.expand_dims(np.sum(C_POES_FLUX * DIFF_E, axis=1), axis=1)\n",
    "\n",
    "C_RBSP_TIME = np.expand_dims(CONJUNCTIONS[:, -12], axis=1)\n",
    "C_RBSP_LSTAR = np.expand_dims(CONJUNCTIONS[:, -11], axis=1)\n",
    "C_RBSP_MLT = np.expand_dims(CONJUNCTIONS[:, -10], axis=1)\n",
    "C_RBSP_MLAT = np.expand_dims(CONJUNCTIONS[:, -9], axis=1)\n",
    "C_RBSP_CHORUS = np.expand_dims(CONJUNCTIONS[:, -8], axis=1)\n",
    "C_RBSP_DENSITY = np.expand_dims(CONJUNCTIONS[:, -7], axis=1)\n",
    "C_AVG_SME = np.expand_dims(CONJUNCTIONS[:, -6], axis=1)\n",
    "C_VAR_SME = np.expand_dims(CONJUNCTIONS[:, -5], axis=1)\n",
    "C_AVG_AVG_B = np.expand_dims(CONJUNCTIONS[:, -4], axis=1)\n",
    "C_AVG_FLOW_SPEED = np.expand_dims(CONJUNCTIONS[:, -3], axis=1)\n",
    "C_AVG_PROTON_DENSITY = np.expand_dims(CONJUNCTIONS[:, -2], axis=1)\n",
    "C_AVG_SYM_H = np.expand_dims(CONJUNCTIONS[:, -1], axis=1)\n",
    "\n",
    "print(C_RBSP_TIME.shape)\n",
    "print(C_RBSP_LSTAR.shape)\n",
    "print(C_RBSP_CHORUS.shape)\n",
    "print(C_RBSP_DENSITY.shape)\n",
    "print(C_RBSP_MLAT.shape)\n",
    "print(C_POES_TIME.shape)\n",
    "print(C_POES_LSTAR.shape)\n",
    "print(C_POES_MLT.shape)\n",
    "print(C_RBSP_MLT.shape)\n",
    "print(C_POES_FLUX_INTEGRATED.shape)\n",
    "print(C_AVG_SME.shape)\n",
    "print(C_VAR_SME.shape)\n",
    "print(C_AVG_AVG_B.shape)\n",
    "print(C_AVG_FLOW_SPEED.shape)\n",
    "print(C_AVG_PROTON_DENSITY.shape)\n",
    "print(C_AVG_SYM_H.shape)\n",
    "\n",
    "mean_LSTAR = np.nanmean(C_POES_LSTAR)\n",
    "std_LSTAR = np.std(C_POES_LSTAR)\n",
    "\n",
    "mean_MLAT = np.nanmean(C_RBSP_MLAT)\n",
    "std_MLAT = np.std(C_RBSP_MLAT)\n",
    "\n",
    "mean_fluxes = np.log10(np.nanmean(C_POES_FLUX))\n",
    "std_fluxes = np.log10(np.nanstd(C_POES_FLUX))\n",
    "\n",
    "mean_density = np.nanmean(C_RBSP_DENSITY)\n",
    "std_density = np.nanstd(C_RBSP_DENSITY)\n",
    "\n",
    "mean_sme = np.log10(np.nanmean(C_AVG_SME))\n",
    "std_sme = np.log10(np.std(C_AVG_SME))\n",
    "\n",
    "mean_avg_b = np.nanmean(C_AVG_AVG_B)\n",
    "std_avg_b = np.std(C_AVG_AVG_B)\n",
    "\n",
    "mean_flow_speed = np.nanmean(C_AVG_FLOW_SPEED)\n",
    "std_flow_speed = np.std(C_AVG_FLOW_SPEED)\n",
    "\n",
    "mean_avg_proton_density = np.nanmean(C_AVG_PROTON_DENSITY)\n",
    "std_avg_proton_density = np.std(C_AVG_PROTON_DENSITY)\n",
    "\n",
    "mean_avg_sym_h = np.nanmean(C_AVG_SYM_H)\n",
    "std_avg_sym_h = np.std(C_AVG_SYM_H)\n",
    "\n",
    "\n",
    "L_MAX = 9\n",
    "\n",
    "FEATURES = np.hstack(\n",
    "    (\n",
    "        C_POES_LSTAR,\n",
    "        C_POES_LSTAR * np.cos((C_POES_MLT * 2 * np.pi) / 24.0),\n",
    "        C_POES_LSTAR * np.sin((C_POES_MLT * 2 * np.pi) / 24.0),\n",
    "        C_RBSP_MLAT,\n",
    "        C_RBSP_DENSITY,\n",
    "        C_POES_FLUX_INTEGRATED,\n",
    "        C_AVG_SME,\n",
    "        C_VAR_SME,\n",
    "        C_AVG_AVG_B\n",
    "    )\n",
    ")\n",
    "\n",
    "chorus_greater_than_p1_pT = (1e-1 < C_RBSP_CHORUS.flatten())\n",
    "poes_greater_than_1000 = (100 < C_POES_FLUX_INTEGRATED.flatten())\n",
    "FEATURES_T = FEATURES[train_test_subset_selected & chorus_greater_than_p1_pT & poes_greater_than_1000, :]\n",
    "FEATURES_V = FEATURES[validation_subset_selected & chorus_greater_than_p1_pT & poes_greater_than_1000, :]\n",
    "\n",
    "MODEL_LABELS = C_RBSP_CHORUS[train_test_subset_selected & chorus_greater_than_p1_pT & poes_greater_than_1000]\n",
    "MODEL_LABELS_V = C_RBSP_CHORUS[validation_subset_selected & chorus_greater_than_p1_pT & poes_greater_than_1000]\n",
    "\n",
    "DAY_T = DAY[train_test_subset_selected & chorus_greater_than_p1_pT & poes_greater_than_1000]\n",
    "DAY_V = DAY[validation_subset_selected & chorus_greater_than_p1_pT & poes_greater_than_1000]\n",
    "\n",
    "print(FEATURES_T.shape)\n",
    "print(MODEL_LABELS.shape)\n",
    "print(FEATURES_V.shape)\n",
    "print(MODEL_LABELS_V.shape)\n",
    "\n",
    "np.savez(\n",
    "    file=os.path.join(STAGE_4_folder, f\"MODEL_READY_DATA_{VERSION}_{FIELD_MODEL}_{MODEL_TYPE}.npz\"),\n",
    "    FEATURES=FEATURES_T,\n",
    "    LABELS=MODEL_LABELS,\n",
    "    VALIDATION_FEATURES=FEATURES_V,\n",
    "    VALIDATION_LABELS=MODEL_LABELS_V,\n",
    "    TRAINING_DAY_IDS=DAY_T,\n",
    "    VALIDATION_DAY_IDS=DAY_V,\n",
    "    TRAINING_MLT=C_POES_MLT,\n",
    "    MEAN_L=mean_LSTAR,\n",
    "    STD_L=std_LSTAR,\n",
    "    MEAN_MLAT=mean_MLAT,\n",
    "    STD_MLAT=std_MLAT,\n",
    "    MEAN_DENSITY=mean_density,\n",
    "    STD_DENSITY=std_density,\n",
    "    MEAN_FLUXES=mean_fluxes,\n",
    "    STD_FLUXES=std_fluxes,\n",
    "    MEAN_SME=mean_sme,\n",
    "    STD_SME=std_sme,\n",
    "    MEAN_AVG_B=mean_avg_b,\n",
    "    STD_AVG_B=std_avg_b,\n",
    "    MEAN_FLOW_SPEED=mean_flow_speed,\n",
    "    STD_FLOW_SPEED=std_flow_speed,\n",
    "    MEAN_AVG_PROTON_DENSITY=mean_avg_proton_density,\n",
    "    STD_AVG_PROTON_DENSITY=std_avg_proton_density,\n",
    "    MEAN_AVG_SYM_H=mean_avg_sym_h,\n",
    "    STD_AVG_SYM_H=std_avg_sym_h,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.scatter(x=FEATURES_T[:, -4], y=MODEL_LABELS, c=FEATURES_T[:, -3], s=1.0, norm=matplotlib.colors.LogNorm(vmin=10, vmax=1000))\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(\n",
    "    {\"SME\": C_VAR_SME.flatten(), \"CHORUS\": C_RBSP_CHORUS.flatten(), \"DENSITY\" : C_RBSP_DENSITY.flatten()},\n",
    "    bins=50,\n",
    "    x=\"SME\",\n",
    "    y=\"CHORUS\",\n",
    "    log_scale=(True, True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.scatter(x=np.sqrt(C_VAR_SME), y=C_RBSP_CHORUS, c = C_RBSP_DENSITY, s=0.5, norm=matplotlib.colors.LogNorm(vmin=1, vmax=100))\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
