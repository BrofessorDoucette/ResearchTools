{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa1ac27c-22dc-4e7e-a30a-feed0d21a109",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pynndescent\n",
    "\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1cf9ce6-b95b-4491-bae2-1d57b3e3f80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: ((684250, 8), (684250,))\n",
      "Validation set shape: ((21435, 8), (21435,))\n"
     ]
    }
   ],
   "source": [
    "VERSION = \"v2\"\n",
    "FIELD_MODEL = \"T89\"\n",
    "MODEL_TYPE = \"LOWER_BAND\"\n",
    "pdata_folder = os.path.abspath(r\"./../processed_data/chorus_neural_network/\")\n",
    "STAGE_4_folder = os.path.join(pdata_folder, \"STAGE_4\", VERSION)\n",
    "CONJUNCTIONS_REFS = np.load(\n",
    "    file=os.path.join(STAGE_4_folder, f\"MODEL_READY_DATA_{VERSION}_{FIELD_MODEL}_{MODEL_TYPE}.npz\")\n",
    ")\n",
    "\n",
    "TRAINING_FEATURES = CONJUNCTIONS_REFS[\"FEATURES\"]\n",
    "TRAINING_LABELS = CONJUNCTIONS_REFS[\"LABELS\"].flatten()\n",
    "TRAINING_DAY_IDS = CONJUNCTIONS_REFS[\"TRAINING_DAY_IDS\"].flatten()\n",
    "\n",
    "TRAINING_MLT = CONJUNCTIONS_REFS[\"TRAINING_MLT\"]\n",
    "MEAN_L = CONJUNCTIONS_REFS[\"MEAN_L\"]\n",
    "STD_L = CONJUNCTIONS_REFS[\"STD_L\"]\n",
    "\n",
    "VALIDATION_FEATURES = CONJUNCTIONS_REFS[\"VALIDATION_FEATURES\"]\n",
    "VALIDATION_LABELS = CONJUNCTIONS_REFS[\"VALIDATION_LABELS\"].flatten()\n",
    "VALIDATION_DAY_IDS = CONJUNCTIONS_REFS[\"VALIDATION_DAY_IDS\"].flatten()\n",
    "\n",
    "CONJUNCTIONS_REFS.close()\n",
    "\n",
    "print(f\"Training set shape: {TRAINING_FEATURES.shape, TRAINING_LABELS.shape}\")\n",
    "print(f\"Validation set shape: {VALIDATION_FEATURES.shape, VALIDATION_LABELS.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c460b38-3b48-40f0-90f4-f042273b6776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Relative Sizes in fold : 0\n",
      "Training: \n",
      "30615 437412 79814 959\n",
      "\n",
      "Relative Sizes in fold : 1\n",
      "Training: \n",
      "31123 435519 80506 1004\n",
      "\n",
      "Relative Sizes in fold : 2\n",
      "Training: \n",
      "31018 436522 79145 948\n",
      "\n",
      "Relative Sizes in fold : 3\n",
      "Training: \n",
      "29565 436828 80339 1000\n",
      "\n",
      "Relative Sizes in fold : 4\n",
      "Training: \n",
      "30507 432811 80300 1037\n",
      "\n",
      "Weights for each category\n",
      "0.055838349826012094 0.7961689049065901 0.14618490799321293 0.0018078372741847555\n",
      "\n",
      "Size of resampled Training Features: \n",
      "(2179092, 8) (2179092,)\n",
      "\n",
      "Folds\n",
      "(array([630306,  99618, 162356, ..., 240148, 251754, 141974]), array([324929, 111737, 260037, ..., 155944, 140797, 247473]))\n",
      "(array([105461, 264271, 183962, ...,   9577,   6799,  31357]), array([474409, 244073, 429581, ...,  17979,  26998, 283801]))\n",
      "(array([ 41230,  17155,  21417, ..., 107782, 313005,  23017]), array([280002,  98227, 512039, ..., 549737, 119475, 460161]))\n",
      "(array([ 60837,  12847, 237217, ..., 385834, 683542,  61651]), array([268048, 268057, 501432, ..., 625014, 308867, 134281]))\n",
      "(array([236785, 581464, 239769, ..., 425294, 216338,  80075]), array([614428, 472209, 102195, ..., 243053, 582681, 109094]))\n"
     ]
    }
   ],
   "source": [
    "num_folds = 5\n",
    "\n",
    "kfold_gen = sklearn.model_selection.GroupKFold(n_splits=num_folds, shuffle=True)\n",
    "folds_separating_days = list(\n",
    "    kfold_gen.split(TRAINING_FEATURES, TRAINING_LABELS, groups=TRAINING_DAY_IDS)\n",
    ")\n",
    "\n",
    "folds = []\n",
    "\n",
    "for fold in range(num_folds):\n",
    "\n",
    "    train = folds_separating_days[fold][0]\n",
    "\n",
    "    train_b_p1_1 = np.nonzero((0.1 <= TRAINING_LABELS[train]) & (TRAINING_LABELS[train] < 1))[0]\n",
    "    train_b_1_10 = np.nonzero((1 <= TRAINING_LABELS[train]) & (TRAINING_LABELS[train] < 10))[0]\n",
    "    train_b_10_100 = np.nonzero((10 <= TRAINING_LABELS[train]) & (TRAINING_LABELS[train] < 100))[0]\n",
    "    train_g_100 = np.nonzero(100 <= TRAINING_LABELS[train])[0]\n",
    "\n",
    "    test = folds_separating_days[fold][1]\n",
    "\n",
    "    print(f\"\\nRelative Sizes in fold : {fold}\")\n",
    "    print(\"Training: \")\n",
    "    print(\n",
    "        len(train_b_p1_1),\n",
    "        len(train_b_1_10),\n",
    "        len(train_b_10_100),\n",
    "        len(train_g_100),\n",
    "    )\n",
    "\n",
    "    largest_size_training = max(\n",
    "        len(train_b_p1_1),\n",
    "        len(train_b_1_10),\n",
    "        len(train_b_10_100),\n",
    "        len(train_g_100),\n",
    "    )\n",
    "\n",
    "    train_p1_1_resampled = sklearn.utils.resample(train[train_b_p1_1], n_samples=largest_size_training)\n",
    "    train_1_10_resampled = sklearn.utils.resample(train[train_b_1_10], n_samples=largest_size_training)\n",
    "    train_10_100_resampled = sklearn.utils.resample(train[train_b_10_100], n_samples=largest_size_training)\n",
    "    train_g_100_resampled = sklearn.utils.resample(train[train_g_100], n_samples=largest_size_training)\n",
    "\n",
    "    train_for_fold = np.hstack(\n",
    "        (train_p1_1_resampled, train_1_10_resampled, train_10_100_resampled, train_g_100_resampled)\n",
    "    )\n",
    "\n",
    "    np.random.shuffle(train_for_fold)\n",
    "    np.random.shuffle(test)\n",
    "\n",
    "    folds.append((train_for_fold, test))\n",
    "\n",
    "b_p1_1 = np.nonzero((0.1 <= TRAINING_LABELS) & (TRAINING_LABELS < 1))[0]\n",
    "b_1_10 = np.nonzero((1 <= TRAINING_LABELS) & (TRAINING_LABELS < 10))[0]\n",
    "b_10_100 = np.nonzero((10 <= TRAINING_LABELS) & (TRAINING_LABELS < 100))[0]\n",
    "g_100 = np.nonzero(100 <= TRAINING_LABELS)[0]\n",
    "\n",
    "largest_size_training_full = max(len(b_p1_1), len(b_1_10), len(b_10_100), len(g_100))\n",
    "\n",
    "full_p1_1_resampled = sklearn.utils.resample(b_p1_1, n_samples=largest_size_training_full)\n",
    "full_1_10_resampled = sklearn.utils.resample(b_1_10, n_samples=largest_size_training_full)\n",
    "full_10_100_resampled = sklearn.utils.resample(b_10_100, n_samples=largest_size_training_full)\n",
    "full_g_100_resampled = sklearn.utils.resample(g_100, n_samples=largest_size_training_full)\n",
    "\n",
    "RESAMPLED_TRAINING_FEATURES = np.vstack(\n",
    "    [\n",
    "        TRAINING_FEATURES[full_p1_1_resampled, :],\n",
    "        TRAINING_FEATURES[full_1_10_resampled, :],\n",
    "        TRAINING_FEATURES[full_10_100_resampled, :],\n",
    "        TRAINING_FEATURES[full_g_100_resampled, :],\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "RESAMPLED_TRAINING_LABELS = np.hstack(\n",
    "    [\n",
    "        TRAINING_LABELS[full_p1_1_resampled],\n",
    "        TRAINING_LABELS[full_1_10_resampled],\n",
    "        TRAINING_LABELS[full_10_100_resampled],\n",
    "        TRAINING_LABELS[full_g_100_resampled],\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "indices_for_shuffle = np.arange(0, len(RESAMPLED_TRAINING_LABELS))\n",
    "np.random.shuffle(indices_for_shuffle)\n",
    "shuffled_indices = indices_for_shuffle.flatten()\n",
    "\n",
    "RESAMPLED_TRAINING_FEATURES = RESAMPLED_TRAINING_FEATURES[shuffled_indices, :]\n",
    "RESAMPLED_TRAINING_LABELS = RESAMPLED_TRAINING_LABELS[shuffled_indices]\n",
    "\n",
    "weight_for_p1_1 = len(b_p1_1) / largest_size_training_full\n",
    "weight_for_1_10 = len(b_1_10) / largest_size_training_full\n",
    "weight_for_10_100 = len(b_10_100) / largest_size_training_full\n",
    "weight_for_g_100 = len(g_100) / largest_size_training_full\n",
    "\n",
    "sum_weights = np.sum([weight_for_p1_1, weight_for_1_10, weight_for_10_100, weight_for_g_100])\n",
    "\n",
    "weight_for_p1_1 /= sum_weights\n",
    "weight_for_1_10 /= sum_weights\n",
    "weight_for_10_100 /= sum_weights\n",
    "weight_for_g_100 /= sum_weights\n",
    "\n",
    "print(\"\\nWeights for each category\")\n",
    "print(weight_for_p1_1, weight_for_1_10, weight_for_10_100, weight_for_g_100)\n",
    "\n",
    "weights = np.zeros_like(TRAINING_LABELS)\n",
    "weights[b_p1_1] = weight_for_p1_1\n",
    "weights[b_1_10] = weight_for_1_10\n",
    "weights[b_10_100] = weight_for_10_100\n",
    "weights[g_100] = weight_for_g_100\n",
    "\n",
    "weights_resampled = np.zeros_like(RESAMPLED_TRAINING_LABELS)\n",
    "weights_resampled[(0.1 <= RESAMPLED_TRAINING_LABELS) & (RESAMPLED_TRAINING_LABELS < 1)] = (\n",
    "    weight_for_p1_1\n",
    ")\n",
    "weights_resampled[(1 <= RESAMPLED_TRAINING_LABELS) & (RESAMPLED_TRAINING_LABELS < 10)] = (\n",
    "    weight_for_1_10\n",
    ")\n",
    "weights_resampled[(10 <= RESAMPLED_TRAINING_LABELS) & (RESAMPLED_TRAINING_LABELS < 100)] = (\n",
    "    weight_for_10_100\n",
    ")\n",
    "weights_resampled[(100 <= RESAMPLED_TRAINING_LABELS)] = weight_for_g_100\n",
    "\n",
    "print(\"\\nSize of resampled Training Features: \")\n",
    "print(RESAMPLED_TRAINING_FEATURES.shape, RESAMPLED_TRAINING_LABELS.shape)\n",
    "\n",
    "print(\"\\nFolds\")\n",
    "for fold in folds:\n",
    "    print(fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4798427-c380-461e-b4c9-83b51ae7c03c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5693.50982843 4839.4878028  3447.70528141]\n",
      "[[ 0.00177569  0.98861093  0.01122547  0.10243987 -0.0622544   0.08093784\n",
      "  -0.01283851  0.03786777]\n",
      " [ 0.99744499 -0.0118851   0.00207288  0.04019308 -0.0221341   0.0456874\n",
      "   0.01286489  0.0244886 ]\n",
      " [-0.06565463 -0.13969325  0.05540332  0.6114741  -0.55933932  0.49426991\n",
      "   0.19310677  0.06893274]]\n"
     ]
    }
   ],
   "source": [
    "pca = sklearn.decomposition.PCA(n_components=3)\n",
    "transformed_training_features = pca.fit_transform(RESAMPLED_TRAINING_FEATURES)\n",
    "\n",
    "print(pca.singular_values_)\n",
    "print(pca.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "703f4b30-1ef1-4a53-b99d-cf48e5fc0720",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_principal_components = 4\n",
    "pca = sklearn.decomposition.PCA(n_components=num_principal_components)\n",
    "transformed_training_features = pca.fit_transform(RESAMPLED_TRAINING_FEATURES)\n",
    "\n",
    "transformed_validation_features = pca.fit_transform(VALIDATION_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9d2a833d-917e-411c-8c4d-32c16803174d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 12min 20s\n",
      "Wall time: 4min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "knn = pynndescent.NNDescent(transformed_training_features, n_jobs=10, )\n",
    "knn.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7a09925b-c68b-4603-bbb5-fe306b33623b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 391 ms\n",
      "Wall time: 393 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "validation_prediction = knn.query(transformed_validation_features, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f83d46c0-5a8e-4608-a967-8060aec59352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(len(validation_prediction))\n",
    "predictions = []\n",
    "\n",
    "for neighbors, distances in zip(validation_prediction[0], validation_prediction[1]):\n",
    "\n",
    "    w = (1 / distances)\n",
    "    w = w / np.sum(w)\n",
    "    predictions.append(np.average(RESAMPLED_TRAINING_LABELS[neighbors], weights=w))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e4d99d82-95db-4b49-b2e3-60a08f89b9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(VALIDATION_LABELS, predictions, s=2.0)\n",
    "plt.plot(np.logspace(-2, 4), np.logspace(-2, 4), color=\"black\")\n",
    "plt.grid()\n",
    "plt.xlabel(\"RBSP OBSERVED CHORUS\")\n",
    "plt.ylabel(\"MODEL PREDICTED CHORUS\")\n",
    "plt.title(\"VALIDATION SET\")\n",
    "plt.xlim(1e-1, 1e3)\n",
    "plt.ylim(1e-1, 1e3)\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a259ba35-68e2-4a3c-b9fb-47ce132bb139",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
