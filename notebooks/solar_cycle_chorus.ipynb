{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# caution: path[0] is reserved for script path (or '' in REPL).\n",
    "sys.path.insert(1, os.path.abspath(\"./../src\"))\n",
    "\n",
    "import datetime\n",
    "import importlib\n",
    "\n",
    "import matplotlib.colors\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from dateutil import rrule\n",
    "\n",
    "import chorus_machine_learning_helper\n",
    "import data_loader\n",
    "import plot_tools\n",
    "\n",
    "importlib.reload(chorus_machine_learning_helper)\n",
    "importlib.reload(plot_tools)\n",
    "importlib.reload(data_loader)\n",
    "\n",
    "\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = xgb.Booster({\"nthread\": 8, \"device\": \"cuda\"})  # init model\n",
    "MODEL.load_model(\n",
    "    r\"./../processed_data_chorus_neural_network/TRAINED_MODELS/Weighted_L2/XG_BOOSTED_REGRESSION_MSE_WEIGHTED_ON_L_AND_AMPLITUDE.model\"\n",
    ")  # load model data\n",
    "DATASET_VERSION = \"v4a\"\n",
    "\n",
    "CHORUS_PREDICTED_TOTAL = []\n",
    "L_TOTAL = []\n",
    "MLT_TOTAL = []\n",
    "TIME_TOTAL = []\n",
    "\n",
    "for year in range(1998, 2024):\n",
    "\n",
    "    POES = chorus_machine_learning_helper.load_MPE_year(year)\n",
    "\n",
    "    SUPERMAG = chorus_machine_learning_helper.load_SUPERMAG_SME_year(year)\n",
    "\n",
    "    OMNI = chorus_machine_learning_helper.load_OMNI_year(year)\n",
    "\n",
    "    print(f\"Number of POES satellites loaded: {len(POES)}\")\n",
    "\n",
    "    FEATURE_REFS = chorus_machine_learning_helper.find_average_SUPERMAG_and_OMNI_values_for_each_POES_data_point(\n",
    "        POES, SUPERMAG, OMNI\n",
    "    )\n",
    "\n",
    "    POES_TIMES_OF_FEATURES = FEATURE_REFS[\"POES_TIMES_OF_FEATURES\"].flatten()\n",
    "    MLT_FEATURES_PREPROCESSING = FEATURE_REFS[\"MLT_FEATURES\"].flatten()\n",
    "    L_FEATURES_PREPROCESSING = FEATURE_REFS[\"L_FEATURES\"].flatten()\n",
    "\n",
    "    FEATURES_POST_PROCESSING = chorus_machine_learning_helper.normalize_features(\n",
    "        FEATURE_REFS, version=DATASET_VERSION\n",
    "    )\n",
    "\n",
    "    CHORUS_PREDICTED = MODEL.predict(xgb.DMatrix(FEATURES_POST_PROCESSING))\n",
    "\n",
    "    CHORUS_PREDICTED_TOTAL.append(CHORUS_PREDICTED)\n",
    "    L_TOTAL.append(L_FEATURES_PREPROCESSING)\n",
    "    MLT_TOTAL.append(MLT_FEATURES_PREPROCESSING)\n",
    "    TIME_TOTAL.append(POES_TIMES_OF_FEATURES)\n",
    "\n",
    "\n",
    "np.savez(\n",
    "    file=os.path.abspath(\n",
    "        r\"./../processed_data_chorus_neural_network/temp_chorus_dependence_on_solar_cycle_using_machine_learning_v4a_dataset.npz\"\n",
    "    ),\n",
    "    CHORUS=np.hstack(CHORUS_PREDICTED_TOTAL),\n",
    "    L=np.hstack(L_TOTAL),\n",
    "    MLT=np.hstack(MLT_TOTAL),\n",
    "    UNIX_TIME=np.hstack(TIME_TOTAL),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHORUS_REFS = np.load(\n",
    "    r\"./../processed_data_chorus_neural_network/temp_chorus_dependence_on_solar_cycle_using_machine_learning_v4a_dataset.npz\"\n",
    ")\n",
    "\n",
    "TIME_TOTAL = CHORUS_REFS[\"UNIX_TIME\"]\n",
    "CHORUS_PREDICTED_TOTAL = CHORUS_REFS[\"CHORUS\"]\n",
    "L_TOTAL = CHORUS_REFS[\"L\"]\n",
    "MLT_TOTAL = CHORUS_REFS[\"MLT\"]\n",
    "\n",
    "CHORUS_REFS.close()\n",
    "\n",
    "print(TIME_TOTAL.shape)\n",
    "print(CHORUS_PREDICTED_TOTAL.shape)\n",
    "print(L_TOTAL.shape)\n",
    "print(MLT_TOTAL.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.datetime(year=1998, month=1, day=1)\n",
    "end = datetime.datetime(year=2024, month=1, day=1)\n",
    "dt = 86400  # Seconds in day\n",
    "\n",
    "\n",
    "cumulative_chorus, num_points_in_each_epoch_L_bin = plot_tools.bin_3D_data(\n",
    "    xdata=TIME_TOTAL,\n",
    "    ydata=L_TOTAL,\n",
    "    zdata=CHORUS_PREDICTED_TOTAL,\n",
    "    xstart=start.timestamp(),\n",
    "    xend=end.timestamp(),\n",
    "    xstep=dt,\n",
    "    ystart=3,\n",
    "    yend=7,\n",
    "    ystep=0.1,\n",
    ")\n",
    "\n",
    "\n",
    "averaged_model_predictions = cumulative_chorus / num_points_in_each_epoch_L_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integrated_model_predictions = (\n",
    "    np.nansum(averaged_model_predictions, axis=1) * 0.1\n",
    ")  # Integrate with bin of 0.1 L\n",
    "\n",
    "integrated_model_predictions[integrated_model_predictions == 0] = np.nan\n",
    "\n",
    "integrated_prediction_times = np.array(\n",
    "    [\n",
    "        datetime.datetime.fromtimestamp(start.timestamp() + j * dt)\n",
    "        for j in range((int((end.timestamp() - start.timestamp()) / dt) + 1))\n",
    "    ][:-1]\n",
    ")\n",
    "\n",
    "print(integrated_prediction_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.sidc.be/SILSO/datafiles\n",
    "\n",
    "smoothed_sunspot_number_df = pd.read_csv(r\"./../sunspot_numbers/SN_ms_tot_V2.0.csv\")\n",
    "smoothed_sunspot_number_df.columns = [\n",
    "    \"year\",\n",
    "    \"month\",\n",
    "    \"decimal year\",\n",
    "    \"SNvalue\",\n",
    "    \"SNerror\",\n",
    "    \"Nb observations\",\n",
    "]\n",
    "smoothed_spotspot_numbers = smoothed_sunspot_number_df[\"SNvalue\"]\n",
    "smoothed_sunspot_times = []\n",
    "\n",
    "for r in range(len(smoothed_sunspot_number_df)):\n",
    "\n",
    "    date = datetime.datetime(\n",
    "        year=smoothed_sunspot_number_df[\"year\"][r],\n",
    "        month=smoothed_sunspot_number_df[\"month\"][r],\n",
    "        day=1,\n",
    "        hour=0,\n",
    "        minute=0,\n",
    "        second=0,\n",
    "    )\n",
    "    smoothed_sunspot_times.append(date)\n",
    "\n",
    "\n",
    "monthly_sunspot_number_df = pd.read_csv(r\"./../sunspot_numbers/SN_m_tot_V2.0.csv\")\n",
    "monthly_sunspot_number_df.columns = [\n",
    "    \"year\",\n",
    "    \"month\",\n",
    "    \"decimal year\",\n",
    "    \"SNvalue\",\n",
    "    \"SNerror\",\n",
    "    \"Nb observations\",\n",
    "]\n",
    "monthly_spotspot_numbers = monthly_sunspot_number_df[\"SNvalue\"]\n",
    "monthly_sunspot_times = []\n",
    "\n",
    "for r in range(len(monthly_sunspot_number_df)):\n",
    "    date = datetime.datetime(\n",
    "        year=monthly_sunspot_number_df[\"year\"][r],\n",
    "        month=monthly_sunspot_number_df[\"month\"][r],\n",
    "        day=1,\n",
    "        hour=0,\n",
    "        minute=0,\n",
    "        second=0,\n",
    "    )\n",
    "    monthly_sunspot_times.append(date)\n",
    "\n",
    "\n",
    "print(monthly_sunspot_number_df)\n",
    "\n",
    "print(monthly_sunspot_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.sidc.be/SILSO/cyclesminmax\n",
    "\n",
    "min_max_solar_cycle_df = pd.read_csv(r\"./../sunspot_numbers/TableCyclesMiMa.csv\")\n",
    "\n",
    "year_of_minimums = min_max_solar_cycle_df[\"Min_Year\"]\n",
    "month_of_minimums = min_max_solar_cycle_df[\"Min_Month\"]\n",
    "num_solar_mins = len(year_of_minimums)\n",
    "\n",
    "year_of_maximums = min_max_solar_cycle_df[\"Max_Year\"][\n",
    "    :-1\n",
    "]  # REMOVED THE LAST ONE HERE CAUSE THERE IS NO MAXIMUM FOR SOLAR CYCLE 2025 YET\n",
    "month_of_maximums = min_max_solar_cycle_df[\"Max_Month\"][:-1]\n",
    "num_solar_maxs = len(year_of_maximums)\n",
    "\n",
    "dates_of_minimums = [\n",
    "    datetime.datetime(\n",
    "        year=int(year_of_minimums[d]),\n",
    "        month=int(month_of_minimums[d]),\n",
    "        day=1,\n",
    "        hour=0,\n",
    "        minute=0,\n",
    "        second=0,\n",
    "    )\n",
    "    for d in range(num_solar_mins)\n",
    "]\n",
    "dates_of_maximums = [\n",
    "    datetime.datetime(\n",
    "        year=int(year_of_maximums[d]),\n",
    "        month=int(month_of_maximums[d]),\n",
    "        day=1,\n",
    "        hour=0,\n",
    "        minute=0,\n",
    "        second=0,\n",
    "    )\n",
    "    for d in range(num_solar_maxs)\n",
    "]\n",
    "\n",
    "total_dates = []\n",
    "total_dates.extend(dates_of_minimums)\n",
    "total_dates.extend(dates_of_maximums)\n",
    "ordered_dates_of_mins_and_maxs = sorted(total_dates)\n",
    "\n",
    "relevant_minimums_and_maximums = [\n",
    "    ordered_dates_of_mins_and_maxs[-5] + (ordered_dates_of_mins_and_maxs[-4] - ordered_dates_of_mins_and_maxs[-5]) / 2,\n",
    "    ordered_dates_of_mins_and_maxs[-4],\n",
    "    ordered_dates_of_mins_and_maxs[-4] + (ordered_dates_of_mins_and_maxs[-3] - ordered_dates_of_mins_and_maxs[-4]) / 2,\n",
    "    ordered_dates_of_mins_and_maxs[-3],\n",
    "    ordered_dates_of_mins_and_maxs[-3] + (ordered_dates_of_mins_and_maxs[-2] - ordered_dates_of_mins_and_maxs[-3]) / 2,\n",
    "    ordered_dates_of_mins_and_maxs[-2],\n",
    "    ordered_dates_of_mins_and_maxs[-2] + (ordered_dates_of_mins_and_maxs[-1] - ordered_dates_of_mins_and_maxs[-2]) / 2,\n",
    "    ordered_dates_of_mins_and_maxs[-1],\n",
    "    ordered_dates_of_mins_and_maxs[-1] + (datetime.datetime(year=2025, month=7, day=1) - ordered_dates_of_mins_and_maxs[-1]) / 2,\n",
    "]\n",
    "print(relevant_minimums_and_maximums)\n",
    "\n",
    "relevant_minimums_and_maximums_labels = [\n",
    "    \"Up 23\",\n",
    "    \"Max 23\",\n",
    "    \"Down 23\",\n",
    "    \"Min 24\",\n",
    "    \"Up 24\",\n",
    "    \"Max 24\",\n",
    "    \"Down 24\",\n",
    "    \"Min 25\",\n",
    "    \"* Up 25\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 1, figsize=(16, 9), sharex=True)\n",
    "\n",
    "\n",
    "ax[0].set_title(\"Daily Sunspot Number\")\n",
    "ax[0].set_ylabel(\"Daily Sunspot Number\")\n",
    "\n",
    "ax[0].plot(monthly_sunspot_times, monthly_spotspot_numbers, color=\"black\", label=\"Montly Data\")\n",
    "ax[0].plot(\n",
    "    smoothed_sunspot_times, smoothed_spotspot_numbers, color=\"red\", label=\"13-Month Averaged\"\n",
    ")\n",
    "\n",
    "for i, min_or_max in enumerate(relevant_minimums_and_maximums):\n",
    "    ax[0].axvline(x=min_or_max, color=\"black\", linestyle=\"--\", linewidth=2)\n",
    "    ax[0].text(\n",
    "        min_or_max,\n",
    "        np.nanmax(monthly_spotspot_numbers) - np.std(monthly_spotspot_numbers),\n",
    "        relevant_minimums_and_maximums_labels[i],\n",
    "        rotation=270,\n",
    "        verticalalignment=\"center\",\n",
    "    )\n",
    "\n",
    "ax[0].set_xlim(start, end)\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(\n",
    "    integrated_prediction_times, integrated_model_predictions, color=\"black\", label=\"Original Data\"\n",
    ")\n",
    "ax[1].set_title(\"Integrated Model Predictions (Over all L)\")\n",
    "\n",
    "chorus_prediction_df = pd.Series(integrated_model_predictions, index=integrated_prediction_times)\n",
    "smoothed_chorus_df = chorus_prediction_df.rolling(\"30d\", center=True).mean()\n",
    "\n",
    "ax[1].plot(\n",
    "    smoothed_chorus_df.index,\n",
    "    smoothed_chorus_df,\n",
    "    label=\"30-Day Rolling Average\",\n",
    "    color=\"red\",\n",
    "    linewidth=3,\n",
    ")\n",
    "ax[1].set_ylabel(\"Chorus Amplitude (pT)\")\n",
    "\n",
    "ax[1].legend()\n",
    "\n",
    "\n",
    "for i, min_or_max in enumerate(relevant_minimums_and_maximums):\n",
    "    ax[1].axvline(x=min_or_max, color=\"black\", linestyle=\"--\", linewidth=2)\n",
    "\n",
    "image = ax[2].imshow(\n",
    "    averaged_model_predictions.T,\n",
    "    origin=\"lower\",\n",
    "    extent=[start, end, 3, 7],\n",
    "    norm=matplotlib.colors.LogNorm(vmin=1, vmax=10),\n",
    "    aspect=\"auto\",\n",
    "    interpolation=\"none\",\n",
    ")\n",
    "\n",
    "image.cmap.set_under(\"black\")\n",
    "\n",
    "for i, min_or_max in enumerate(relevant_minimums_and_maximums):\n",
    "    ax[2].axvline(x=min_or_max, color=\"black\", linestyle=\"--\", linewidth=2)\n",
    "\n",
    "ax[2].set_title(\"Model Predicted Chorus (Averaged over MLT)\")\n",
    "ax[2].set_ylabel(\"L\")\n",
    "ax[2].set_xlabel(\"Time\")\n",
    "\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "\n",
    "axins = inset_axes(\n",
    "    ax[2],\n",
    "    width=\"1%\",  # width: 5% of parent_bbox width\n",
    "    height=\"100%\",  # height: 50%\n",
    "    loc=\"lower left\",\n",
    "    bbox_to_anchor=(1.01, 0, 1, 1),\n",
    "    bbox_transform=ax[2].transAxes,\n",
    "    borderpad=0,\n",
    ")\n",
    "\n",
    "cbar = fig.colorbar(image, cax=axins, pad=0.01)\n",
    "\n",
    "cbar.set_label(\"Chorus Bw (pT)\\n\", loc=\"center\", labelpad=15, rotation=270)\n",
    "\n",
    "# Set the locator to control the tick spacing\n",
    "locator = (\n",
    "    mdates.YearLocator()\n",
    ")  # Set to DayLocator, HourLocator, etc. based on your desired frequency\n",
    "ax[2].xaxis.set_major_locator(locator)\n",
    "\n",
    "# Set the formatter to control the tick label format\n",
    "formatter = mdates.DateFormatter(\"%Y-%m-%d\")  # Customize the format as needed\n",
    "ax[2].xaxis.set_major_formatter(formatter)\n",
    "\n",
    "# Rotate tick labels if necessary\n",
    "ax[2].tick_params(labelrotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar Plot of Chorus vs Months\n",
    "\n",
    "start_of_months_between_start_and_end = np.array(\n",
    "    [\n",
    "        _dt\n",
    "        for _dt in rrule.rrule(\n",
    "            rrule.MONTHLY,\n",
    "            dtstart=datetime.datetime(year=start.year, month=start.month, day=1),\n",
    "            until=end,\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "cum_chorus_included_in_study = []\n",
    "months_included_in_study = []\n",
    "cum_chorus_per_month_over_all_regions = {i: [] for i in range(12)}\n",
    "\n",
    "for _dt in range(len(start_of_months_between_start_and_end) - 1):\n",
    "\n",
    "    start_of_month = start_of_months_between_start_and_end[_dt]\n",
    "    end_of_month = start_of_months_between_start_and_end[_dt + 1]\n",
    "\n",
    "    times_between_start_and_end_of_month = (start_of_month <= integrated_prediction_times) & (\n",
    "        integrated_prediction_times < end_of_month\n",
    "    )\n",
    "    cum_chorus_for_dt = np.nansum(\n",
    "        integrated_model_predictions[times_between_start_and_end_of_month]\n",
    "    )\n",
    "\n",
    "    if (cum_chorus_for_dt > 0) and (np.sum(times_between_start_and_end_of_month) > 10):\n",
    "\n",
    "        months_included_in_study.append(_dt)\n",
    "        cum_chorus_included_in_study.append(cum_chorus_for_dt)\n",
    "\n",
    "        cum_chorus_per_month_over_all_regions[start_of_month.month - 1].append(cum_chorus_for_dt)\n",
    "\n",
    "start_of_months_between_start_and_end = start_of_months_between_start_and_end[\n",
    "    np.asarray(months_included_in_study)\n",
    "]\n",
    "\n",
    "plt.plot(start_of_months_between_start_and_end, cum_chorus_included_in_study)\n",
    "plt.show()\n",
    "\n",
    "avg_cum_chorus_per_month_over_all_regions = np.array(\n",
    "    [np.nanmean(cum_chorus_per_month_over_all_regions[i]) for i in range(12)]\n",
    ")\n",
    "std_cum_chorus_per_month_over_all_regions = np.array(\n",
    "    [np.nanstd(cum_chorus_per_month_over_all_regions[i], ddof=1) for i in range(12)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_regions = 4\n",
    "\n",
    "regions = {}\n",
    "\n",
    "for r in range(num_regions):\n",
    "    regions[r] = (np.zeros(shape=(12)), np.zeros(shape=(12)))\n",
    "\n",
    "for d, _dt in enumerate(start_of_months_between_start_and_end[:-1]):\n",
    "\n",
    "    selected_region = None\n",
    "    if _dt < relevant_minimums_and_maximums[0]:\n",
    "        selected_region = 0\n",
    "    elif (relevant_minimums_and_maximums[0] <= _dt) and (_dt < relevant_minimums_and_maximums[1]):\n",
    "        selected_region = 1\n",
    "    elif (relevant_minimums_and_maximums[1] <= _dt) and (_dt < relevant_minimums_and_maximums[2]):\n",
    "        selected_region = 2\n",
    "    elif (relevant_minimums_and_maximums[2] <= _dt) and (_dt < relevant_minimums_and_maximums[3]):\n",
    "        selected_region = 3\n",
    "    elif (relevant_minimums_and_maximums[3] <= _dt) and (_dt < relevant_minimums_and_maximums[4]):\n",
    "        selected_region = 0\n",
    "    elif (relevant_minimums_and_maximums[4] <= _dt) and (_dt < relevant_minimums_and_maximums[5]):\n",
    "        selected_region = 1\n",
    "    elif (relevant_minimums_and_maximums[5] <= _dt) and (_dt < relevant_minimums_and_maximums[6]):\n",
    "        selected_region = 2\n",
    "    elif (relevant_minimums_and_maximums[6] <= _dt) and (_dt < relevant_minimums_and_maximums[7]):\n",
    "        selected_region = 3\n",
    "    elif (relevant_minimums_and_maximums[7] <= _dt) and (_dt < relevant_minimums_and_maximums[8]):\n",
    "        selected_region = 0\n",
    "    elif relevant_minimums_and_maximums[8] <= _dt:\n",
    "        selected_region = 1\n",
    "\n",
    "    for m in range(1, 13):\n",
    "\n",
    "        if _dt.month == m:\n",
    "\n",
    "            regions[selected_region][0][m - 1] += cum_chorus_included_in_study[d]\n",
    "            regions[selected_region][1][m - 1] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(num_regions, 1, figsize=(16, 9), sharex=True, sharey=True)\n",
    "\n",
    "ax[0].grid(True, linestyle=\"--\", linewidth=0.5)\n",
    "ax[1].grid(True, linestyle=\"--\", linewidth=0.5)\n",
    "ax[2].grid(True, linestyle=\"--\", linewidth=0.5)\n",
    "ax[3].grid(True, linestyle=\"--\", linewidth=0.5)\n",
    "\n",
    "for r in range(num_regions):\n",
    "    avg_cum_chorus_per_month_in_region = regions[r][0] / regions[r][1]\n",
    "    sigma = (\n",
    "        avg_cum_chorus_per_month_in_region - avg_cum_chorus_per_month_over_all_regions\n",
    "    ) / std_cum_chorus_per_month_over_all_regions\n",
    "\n",
    "    ax[r].bar(\n",
    "        [\n",
    "            \"Jan.\",\n",
    "            \"Feb.\",\n",
    "            \"Mar.\",\n",
    "            \"Apr.\",\n",
    "            \"May.\",\n",
    "            \"June\",\n",
    "            \"July\",\n",
    "            \"Aug.\",\n",
    "            \"Sept.\",\n",
    "            \"Oct.\",\n",
    "            \"Nov.\",\n",
    "            \"Dec.\",\n",
    "        ],\n",
    "        sigma,\n",
    "        color=\"grey\",\n",
    "        edgecolor=\"black\",\n",
    "        linewidth=2,\n",
    "    )\n",
    "    ax[r].set_ylabel(\"std. from mean\")\n",
    "\n",
    "ax[0].set_title(f\"Ascending From Minimum ({int(np.sum(regions[0][1]))})\")\n",
    "ax[1].set_title(f\"Ascending To Maximum ({int(np.sum(regions[1][1]))})\")\n",
    "ax[2].set_title(f\"Descending From Maximum ({int(np.sum(regions[2][1]))})\")\n",
    "ax[3].set_title(f\"Descending To Minimum ({int(np.sum(regions[3][1]))})\")\n",
    "ax[0].axhline(y=0, color=\"black\", linestyle=\"--\", linewidth=3)\n",
    "ax[1].axhline(y=0, color=\"black\", linestyle=\"--\", linewidth=3)\n",
    "ax[2].axhline(y=0, color=\"black\", linestyle=\"--\", linewidth=3)\n",
    "ax[3].axhline(y=0, color=\"black\", linestyle=\"--\", linewidth=3)\n",
    "\n",
    "ax[0].axhline(y=1, color=\"black\", linestyle=\"--\", linewidth=1)\n",
    "ax[1].axhline(y=1, color=\"black\", linestyle=\"--\", linewidth=1)\n",
    "ax[2].axhline(y=1, color=\"black\", linestyle=\"--\", linewidth=1)\n",
    "ax[3].axhline(y=1, color=\"black\", linestyle=\"--\", linewidth=1)\n",
    "\n",
    "ax[0].axhline(y=-1, color=\"black\", linestyle=\"--\", linewidth=1)\n",
    "ax[1].axhline(y=-1, color=\"black\", linestyle=\"--\", linewidth=1)\n",
    "ax[2].axhline(y=-1, color=\"black\", linestyle=\"--\", linewidth=1)\n",
    "ax[3].axhline(y=-1, color=\"black\", linestyle=\"--\", linewidth=1)\n",
    "\n",
    "ax[0].set_ylim(-1.25, 1.25)\n",
    "ax[1].set_ylim(-1.25, 1.25)\n",
    "ax[2].set_ylim(-1.25, 1.25)\n",
    "ax[3].set_ylim(-1.25, 1.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(num_regions, 1, figsize=(16, 9), sharex=True, sharey=True)\n",
    "\n",
    "ax[0].grid(True, linestyle=\"--\", linewidth=0.5)\n",
    "ax[1].grid(True, linestyle=\"--\", linewidth=0.5)\n",
    "ax[2].grid(True, linestyle=\"--\", linewidth=0.5)\n",
    "ax[3].grid(True, linestyle=\"--\", linewidth=0.5)\n",
    "\n",
    "for r in range(num_regions):\n",
    "    avg_cum_chorus_per_month_in_region = regions[r][0] / regions[r][1]\n",
    "\n",
    "    ax[r].bar(\n",
    "        [\n",
    "            \"Jan.\",\n",
    "            \"Feb.\",\n",
    "            \"Mar.\",\n",
    "            \"Apr.\",\n",
    "            \"May.\",\n",
    "            \"June\",\n",
    "            \"July\",\n",
    "            \"Aug.\",\n",
    "            \"Sept.\",\n",
    "            \"Oct.\",\n",
    "            \"Nov.\",\n",
    "            \"Dec.\",\n",
    "        ],\n",
    "        avg_cum_chorus_per_month_in_region,\n",
    "        color=\"grey\",\n",
    "        edgecolor=\"black\",\n",
    "        linewidth=2,\n",
    "    )\n",
    "    ax[r].set_ylabel(\"Avg. Cumulative Chorus (pT)\")\n",
    "\n",
    "    ax[r].errorbar(\n",
    "        [\n",
    "            \"Jan.\",\n",
    "            \"Feb.\",\n",
    "            \"Mar.\",\n",
    "            \"Apr.\",\n",
    "            \"May.\",\n",
    "            \"June\",\n",
    "            \"July\",\n",
    "            \"Aug.\",\n",
    "            \"Sept.\",\n",
    "            \"Oct.\",\n",
    "            \"Nov.\",\n",
    "            \"Dec.\",\n",
    "        ],\n",
    "        avg_cum_chorus_per_month_over_all_regions,\n",
    "        std_cum_chorus_per_month_over_all_regions,\n",
    "        fmt=\"o\",\n",
    "        color=\"black\",\n",
    "        capsize=3,\n",
    "    )\n",
    "\n",
    "\n",
    "ax[0].set_title(f\"Ascending From Minimum ({int(np.sum(regions[0][1]))})\")\n",
    "ax[1].set_title(f\"Ascending To Maximum ({int(np.sum(regions[1][1]))})\")\n",
    "ax[2].set_title(f\"Descending From Maximum ({int(np.sum(regions[2][1]))})\")\n",
    "ax[3].set_title(f\"Descending To Minimum ({int(np.sum(regions[3][1]))})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
