{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b13c7d2-d5c0-46f2-b629-8bad975496af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# caution: path[0] is reserved for script path (or '' in REPL).\n",
    "sys.path.insert(1, os.path.abspath(\"./../src\"))\n",
    "\n",
    "import datetime\n",
    "import importlib\n",
    "\n",
    "import numpy as np\n",
    "import wgan_regression\n",
    "\n",
    "importlib.reload(wgan_regression)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a67a93d-231b-4d64-a540-8c0312151e3e",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Dev\\\\Research\\\\Research_Tools\\\\processed_data\\\\chorus_neural_network\\\\models\\\\v1\\\\total_dataset_v1_LOWER_BAND.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      5\u001b[39m rbsp_chorus_folder = os.path.join(pdata_folder, \u001b[33m\"\u001b[39m\u001b[33mobserved_chorus\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m output_folder = os.path.join(pdata_folder, \u001b[33m\"\u001b[39m\u001b[33mmodels\u001b[39m\u001b[33m\"\u001b[39m, VERSION)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m dataset = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m=\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43mrf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtotal_dataset_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mVERSION\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mMODEL_TYPE\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m.npz\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m X_conditional = dataset[\u001b[33m\"\u001b[39m\u001b[33mX_conditional\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     14\u001b[39m X_convolutional = dataset[\u001b[33m\"\u001b[39m\u001b[33mX_convolutional\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Dev\\Research\\Research_Tools\\ResearchPy\\Lib\\site-packages\\numpy\\lib\\_npyio_impl.py:459\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[39m\n\u001b[32m    457\u001b[39m     own_fid = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    458\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m459\u001b[39m     fid = stack.enter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[32m    460\u001b[39m     own_fid = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    462\u001b[39m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'C:\\\\Dev\\\\Research\\\\Research_Tools\\\\processed_data\\\\chorus_neural_network\\\\models\\\\v1\\\\total_dataset_v1_LOWER_BAND.npz'"
     ]
    }
   ],
   "source": [
    "VERSION = \"v1\"\n",
    "MODEL_TYPE = \"LOWER_BAND\"\n",
    "\n",
    "pdata_folder = os.path.abspath(\"./../processed_data/chorus_neural_network/\")\n",
    "rbsp_chorus_folder = os.path.join(pdata_folder, \"observed_chorus\")\n",
    "output_folder = os.path.join(pdata_folder, \"models\", VERSION)\n",
    "\n",
    "\n",
    "dataset = np.load(\n",
    "    file=os.path.join(output_folder, rf\"total_dataset_{VERSION}_{MODEL_TYPE}.npz\")\n",
    ")\n",
    "\n",
    "X_conditional = dataset[\"X_conditional\"]\n",
    "X_convolutional = dataset[\"X_convolutional\"]\n",
    "y = dataset[\"y\"]\n",
    "\n",
    "t_data = X_conditional[:, -1]\n",
    "X_cond = X_conditional[:, :-1]\n",
    "\n",
    "dataset.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2db8bdb0-445f-445f-835e-ea4a21d5ca97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9304643\n",
      "(9852471,)\n",
      "547828\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(y == 0))\n",
    "print(y.shape)\n",
    "\n",
    "print(y.shape[0] - np.sum(y == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9f32ba8-ddf9-495d-940e-fda43832abf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9852471, 7)\n",
      "(9852471, 6)\n",
      "(9852471, 512)\n",
      "(9852471,)\n",
      "(9852471,)\n"
     ]
    }
   ],
   "source": [
    "print(X_conditional.shape)\n",
    "print(X_cond.shape)\n",
    "print(X_convolutional.shape)\n",
    "print(t_data.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2563726c-0e78-42a5-8cc5-79f2086b8678",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def days_since_timestamp(timestamp):\n",
    "  \"\"\"Calculates the number of days since a Unix timestamp.\n",
    "\n",
    "    Args:\n",
    "        timestamp: The Unix timestamp (in seconds).\n",
    "\n",
    "    Returns:\n",
    "        The number of days since the timestamp as an integer.\n",
    "  \"\"\"\n",
    "  dt_object = datetime.datetime.fromtimestamp(timestamp)\n",
    "  today = datetime.datetime.now()\n",
    "  time_difference = today - dt_object\n",
    "  return time_difference.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40eb8b2f-0e88-4206-8319-52d8ac45ef20",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_ref = datetime.datetime(year = 2012, month = 1, day = 1)\n",
    "num_days = []\n",
    "for t in t_data:\n",
    "\n",
    "    dt = datetime.datetime.fromtimestamp(t)\n",
    "    del_t = dt - t_ref\n",
    "    num_days.append(int(del_t.days))\n",
    "\n",
    "num_days = np.asarray(num_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d822e2c9-7771-4db6-89c3-2b7a9a4de6c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m device = torch.device(\u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Initialize models\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m generator = \u001b[43mGenerator\u001b[49m(noise_dim, condition_dim, output_dim, hidden_dim, num_vectors).to(device)\n\u001b[32m     13\u001b[39m critic = Critic(output_dim, condition_dim, hidden_dim, num_vectors).to(device)\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Dummy dataset (replace with your data)\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'Generator' is not defined"
     ]
    }
   ],
   "source": [
    "noise_dim = 4  # Noise dimension\n",
    "condition_dim = 6  # Number of conditional coordinates\n",
    "output_dim = 1  # Regression output dimension\n",
    "hidden_dim = 128\n",
    "num_vectors = 1  # Number of time series vectors\n",
    "time_steps = 512  # Length of each time series\n",
    "batch_size = 32\n",
    "num_epochs = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize models\n",
    "generator = wgan_regression.Generator(noise_dim, condition_dim, output_dim, hidden_dim, num_vectors).to(device)\n",
    "critic = wgan_regression.Critic(output_dim, condition_dim, hidden_dim, num_vectors).to(device)\n",
    "\n",
    "# Dummy dataset (replace with your data)\n",
    "time_series_data = X_convolutional\n",
    "coordinates =  X_cond\n",
    "targets = y\n",
    "dataset = wgan_regression.TimeSeriesDataset(time_series_data, coordinates, targets)\n",
    "dataloader = wgan_regression.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Train the model\n",
    "wgan_regression.train_wgan_gp(generator, critic, dataloader, noise_dim, condition_dim, num_epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90ff2a3-495c-48d7-b3d3-910633ad5fc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
