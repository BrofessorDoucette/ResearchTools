{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b4d3d6d-2ab1-4bb4-ab02-fa77a59cdc62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/uxlfoundation/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "# caution: path[0] is reserved for script path (or '' in REPL).\n",
    "sys.path.insert(1, os.path.abspath(\"./../src\"))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import gan_regression\n",
    "\n",
    "import importlib\n",
    "importlib.reload(gan_regression)\n",
    "\n",
    "plt.rcdefaults()\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28c82c99-97ec-4e57-b744-9c3c0a2daef7",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Dev\\\\Research\\\\Research_Tools\\\\processed_data\\\\chorus_neural_network\\\\models\\\\v1\\\\MODEL_READY_dataset_v1_LOWER_BAND.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m pdata_folder = os.path.abspath(\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m./../processed_data/chorus_neural_network/\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m STAGE_4_folder = os.path.join(pdata_folder, \u001b[33m\"\u001b[39m\u001b[33mmodels\u001b[39m\u001b[33m\"\u001b[39m, VERSION)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m CONJUNCTIONS_REFS = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m=\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSTAGE_4_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mMODEL_READY_dataset_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mVERSION\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mMODEL_TYPE\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m.npz\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m X_train = CONJUNCTIONS_REFS[\u001b[33m\"\u001b[39m\u001b[33mFEATURES\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     10\u001b[39m y_train = CONJUNCTIONS_REFS[\u001b[33m\"\u001b[39m\u001b[33mLABELS\u001b[39m\u001b[33m\"\u001b[39m].flatten()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Dev\\Research\\Research_Tools\\ResearchPy\\Lib\\site-packages\\numpy\\lib\\_npyio_impl.py:459\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[39m\n\u001b[32m    457\u001b[39m     own_fid = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    458\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m459\u001b[39m     fid = stack.enter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[32m    460\u001b[39m     own_fid = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    462\u001b[39m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'C:\\\\Dev\\\\Research\\\\Research_Tools\\\\processed_data\\\\chorus_neural_network\\\\models\\\\v1\\\\MODEL_READY_dataset_v1_LOWER_BAND.npz'"
     ]
    }
   ],
   "source": [
    "VERSION = \"v1\"\n",
    "MODEL_TYPE = \"LOWER_BAND\"\n",
    "pdata_folder = os.path.abspath(r\"./../processed_data/chorus_neural_network/\")\n",
    "STAGE_4_folder = os.path.join(pdata_folder, \"models\", VERSION)\n",
    "CONJUNCTIONS_REFS = np.load(\n",
    "    file=os.path.join(STAGE_4_folder, f\"MODEL_READY_dataset_{VERSION}_{MODEL_TYPE}.npz\")\n",
    ")\n",
    "\n",
    "X_train = CONJUNCTIONS_REFS[\"FEATURES\"]\n",
    "y_train = CONJUNCTIONS_REFS[\"LABELS\"].flatten()\n",
    "day_train = CONJUNCTIONS_REFS[\"TRAINING_DAY_IDS\"].flatten()\n",
    "\n",
    "X_valid = CONJUNCTIONS_REFS[\"VALIDATION_FEATURES\"]\n",
    "y_valid = CONJUNCTIONS_REFS[\"VALIDATION_LABELS\"].flatten()\n",
    "\n",
    "CONJUNCTIONS_REFS.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9295809a-198f-4138-86b0-b5fbc9092b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training set shape: {X_train.shape, y_train.shape}\")\n",
    "print(f\"Validation set shape: {X_valid.shape, y_valid.shape}\")\n",
    "\n",
    "ax0 = sns.displot(y_train, log_scale=True)\n",
    "ax0.set(ylabel='N', xlabel='Chorus Power (pT^2)', title='Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fd5f79b8-7dc7-4a2a-b099-3bb00ce1061b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device : cuda\n",
      "Epoch [1 / 20] \n",
      "D Loss: (48.4190 +/- 1.5191) N Loss: (15073.6783 +/- 25858.5637) G Loss: (0.0127 +/- 0.0146)\n",
      "\n",
      "Epoch [2 / 20] \n",
      "D Loss: (48.1096 +/- 1.6624) N Loss: (15570.3511 +/- 25454.7962) G Loss: (0.0136 +/- 0.0158)\n",
      "\n",
      "Epoch [3 / 20] \n",
      "D Loss: (44.2774 +/- 7.6452) N Loss: (15311.2835 +/- 24757.1216) G Loss: (0.0500 +/- 0.4273)\n",
      "\n",
      "Epoch [4 / 20] \n",
      "D Loss: (0.1555 +/- 0.2124) N Loss: (10947.1443 +/- 18169.5769) G Loss: (14.8552 +/- 4.7658)\n",
      "\n",
      "Epoch [5 / 20] \n",
      "D Loss: (0.1426 +/- 0.0833) N Loss: (5075.7188 +/- 9342.7172) G Loss: (12.2447 +/- 4.7640)\n",
      "\n",
      "Epoch [6 / 20] \n",
      "D Loss: (3.1289 +/- 2.7516) N Loss: (1491.1475 +/- 2355.9409) G Loss: (2.9852 +/- 2.8579)\n",
      "\n",
      "Epoch [7 / 20] \n",
      "D Loss: (9.4187 +/- 2.8750) N Loss: (4872.7706 +/- 7837.1282) G Loss: (2.3769 +/- 1.9324)\n",
      "\n",
      "Epoch [8 / 20] \n",
      "D Loss: (13.9429 +/- 2.9067) N Loss: (9373.7020 +/- 15311.3544) G Loss: (2.7168 +/- 1.9944)\n",
      "\n",
      "Epoch [9 / 20] \n",
      "D Loss: (15.5220 +/- 2.8482) N Loss: (14080.6860 +/- 23078.6026) G Loss: (2.9600 +/- 2.0361)\n",
      "\n",
      "Epoch [10 / 20] \n",
      "D Loss: (11.8003 +/- 2.8559) N Loss: (18674.4160 +/- 32112.2445) G Loss: (2.4787 +/- 2.0399)\n",
      "\n",
      "Epoch [11 / 20] \n",
      "D Loss: (8.6955 +/- 2.4500) N Loss: (19321.3886 +/- 32951.6719) G Loss: (2.3445 +/- 2.0053)\n",
      "\n",
      "Epoch [12 / 20] \n",
      "D Loss: (7.2268 +/- 2.2620) N Loss: (15626.4021 +/- 25769.8431) G Loss: (2.3547 +/- 2.0480)\n",
      "\n",
      "Epoch [13 / 20] \n",
      "D Loss: (5.7773 +/- 2.0958) N Loss: (14772.7401 +/- 24945.8379) G Loss: (2.3436 +/- 2.0911)\n",
      "\n",
      "Epoch [14 / 20] \n",
      "D Loss: (4.7174 +/- 2.1581) N Loss: (14449.1392 +/- 23641.7703) G Loss: (0.9364 +/- 1.4110)\n",
      "\n",
      "Epoch [15 / 20] \n",
      "D Loss: (0.9251 +/- 0.9635) N Loss: (12558.9792 +/- 21008.4608) G Loss: (2.5188 +/- 2.1757)\n",
      "\n",
      "Epoch [16 / 20] \n",
      "D Loss: (0.5281 +/- 0.2790) N Loss: (7739.9747 +/- 12657.7542) G Loss: (3.8617 +/- 2.3727)\n",
      "\n",
      "Epoch [17 / 20] \n",
      "D Loss: (0.8056 +/- 0.5207) N Loss: (3022.4799 +/- 4861.6500) G Loss: (2.4280 +/- 1.8643)\n",
      "\n",
      "Epoch [18 / 20] \n",
      "D Loss: (2.8324 +/- 2.1012) N Loss: (1182.2436 +/- 2257.9620) G Loss: (0.9636 +/- 1.2792)\n",
      "\n",
      "Epoch [19 / 20] \n",
      "D Loss: (4.8465 +/- 2.9318) N Loss: (3911.6105 +/- 6794.9377) G Loss: (0.5410 +/- 0.8467)\n",
      "\n",
      "Epoch [20 / 20] \n",
      "D Loss: (1.5940 +/- 1.3217) N Loss: (1168.7904 +/- 1921.6111) G Loss: (1.4334 +/- 1.4170)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train model\n",
    "model = gan_regression.GANRegression(input_dim=6,\n",
    "                                     hidden_dim=128,\n",
    "                                     g_lr=2e-7,\n",
    "                                     d_lr=2e-7,\n",
    "                                     epochs_per_output=1)\n",
    "\n",
    "avg_d_losses, avg_numeric_losses, avg_g_losses = model.train(X_train, y_train, epochs=20, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "80ef7135-6a11-4a06-8e5d-8e2c8ae2fbaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1, 1000.0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = 0.0\n",
    "\n",
    "y_train_g = model.GENERATE(X_train)\n",
    "\n",
    "y_train_d = model.DISCRIM(X_train, y_train_g)\n",
    "\n",
    "passes_discriminator_test = y_train_d >= threshold\n",
    "plt.scatter(x=np.sqrt(y_train[passes_discriminator_test]), y=np.sqrt(y_train_g[passes_discriminator_test]), color=\"black\", s=1.0)\n",
    "\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "plt.xlim(1e-1, 1e3)\n",
    "plt.ylim(1e-1, 1e3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2108ede0-c955-4e11-bb01-69c697cfb100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1, 1000.0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid_g = model.GENERATE(X_valid)\n",
    "y_valid_d = model.DISCRIM(X_valid, y_valid_g)\n",
    "\n",
    "passes_discriminator_test = y_valid_d >= threshold\n",
    "plt.scatter(x=y_valid[passes_discriminator_test], y=y_valid_g[passes_discriminator_test], color=\"red\", s=1.0)\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "plt.xlim(1e-1, 1e3)\n",
    "\n",
    "\n",
    "plt.ylim(1e-1, 1e3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26367f9-0406-4a14-8808-3d24412e7a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train_g)\n",
    "print(np.log10(y_train_g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a82183a6-ae46-4895-bd4d-30844f93894d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11282530245189473\n"
     ]
    }
   ],
   "source": [
    "not_negative = y_train_g > 0\n",
    "passes_discriminator_test = y_train_d >= threshold\n",
    "passes_both_filters = not_negative & passes_discriminator_test\n",
    "\n",
    "a, b = np.polyfit(np.log10(y_train[passes_both_filters]), np.log10(y_train_g[passes_both_filters]), 1)\n",
    "\n",
    "x_fit = np.logspace(-1, 4, 1000)\n",
    "\n",
    "# Create the line of best fit\n",
    "y_fit = a * np.log10(x_fit) + b\n",
    "\n",
    "# Plot the line of best fit\n",
    "plt.plot(x_fit, 10**y_fit, color='red')\n",
    "plt.plot(x_fit, x_fit, color='green')\n",
    "\n",
    "\n",
    "print(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907dd34e-b209-4084-9159-21875748bc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_negative = y_valid_g > 0\n",
    "passes_discriminator_test = y_valid_d >= threshold\n",
    "passes_both_filters = not_negative & passes_discriminator_test\n",
    "\n",
    "a, b = np.polyfit(np.log10(y_valid[passes_both_filters]), np.log10(y_valid_g[passes_both_filters]), 1)\n",
    "\n",
    "x_fit = np.logspace(-1, 4, 1000)\n",
    "\n",
    "# Create the line of best fit\n",
    "y_fit = a * np.log10(x_fit) + b\n",
    "\n",
    "# Plot the line of best fit\n",
    "plt.plot(x_fit, 10**y_fit, color='red')\n",
    "plt.plot(x_fit, x_fit, color='green')\n",
    "\n",
    "\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729ef623-dc98-40a6-9711-2fb1207a2a68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
